{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO62fAlh4JC32tkHalXnmTC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Uditxarma/Coding-Part/blob/main/Fake_Image_Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GE2sPGj2oSJd",
        "outputId": "ec0e80c7-c2f0-40de-cf74-fadfe1b25ebe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch\n",
            "  Using cached pytorch-1.0.2.tar.gz (689 bytes)\n",
            "Building wheels for collected packages: pytorch\n",
            "  Building wheel for pytorch (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for pytorch\u001b[0m\n",
            "\u001b[?25h  Running setup.py clean for pytorch\n",
            "Failed to build pytorch\n",
            "Installing collected packages: pytorch\n",
            "    Running setup.py install for pytorch ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31mERROR: Command errored out with exit status 1: /usr/bin/python3 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-el_yq6db/pytorch_b67a9db4849c42278ed07f755e7b0787/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-el_yq6db/pytorch_b67a9db4849c42278ed07f755e7b0787/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-x5wotem_/install-record.txt --single-version-externally-managed --compile --install-headers /usr/local/include/python3.8/pytorch Check the logs for full command output.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJyokA52-MTI",
        "outputId": "ecd492ca-1e8a-4c97-f217-d9a5578b5273"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "file_name=\"/content/drive/My Drive/datagan.zip\""
      ],
      "metadata": {
        "id": "_CRmKyWeAXuE"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with ZipFile(file_name,'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('done')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlWbCO_jDc3t",
        "outputId": "88e5873a-53f1-4f25-f406-049df26a33b5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "from torch.autograd import Variable"
      ],
      "metadata": {
        "id": "piEXOC22DdmN"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting some hyperparameters\n",
        "batchSize = 64 # We set the size of the batch.\n",
        "imageSize = 64 # We set the size of the generated images (64x64)."
      ],
      "metadata": {
        "id": "AUDr0Ua6BSlz"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the transformations\n",
        "transform = transforms.Compose([transforms.Resize(imageSize), transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),]) "
      ],
      "metadata": {
        "id": "rx-tJM1TBZU3"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dset.CIFAR10(root = '/content/datagan', download = True, transform = transform)  #load dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38kb7sLJBxVQ",
        "outputId": "81714812-d9fb-4fc9-b3d8-36b85adc10c2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size = batchSize, shuffle = True, num_workers = 2)"
      ],
      "metadata": {
        "id": "3zESmc38CTuG"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        m.weight.data.normal_(0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        m.weight.data.normal_(1.0, 0.02)\n",
        "        m.bias.data.fill_(0)"
      ],
      "metadata": {
        "id": "K8eALOr5CxNN"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class G(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(G, self).__init__() # We inherit from the nn.Module tools.\n",
        "        self.main = nn.Sequential( \n",
        "            nn.ConvTranspose2d(100, 512, 4, 1, 0, bias = False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias = False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias = False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias = False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(True),\n",
        "            #Output as of 3 channel...\n",
        "            nn.ConvTranspose2d(64, 3, 4, 2, 1, bias = False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, input): \n",
        "        output = self.main(input) \n",
        "        return output # We return the output containing the generated images.\n"
      ],
      "metadata": {
        "id": "qvmxvqXnC6Kr"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the generator\n",
        "netG = G()\n",
        "netG.apply(weights_init)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWzzeluVEQ4d",
        "outputId": "43855bee-1f69-48dd-8d64-4a686aeea36b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "G(\n",
              "  (main): Sequential(\n",
              "    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (13): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class D(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(D, self).__init__() # We inherit from the nn.Module tools.\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 4, 2, 1, bias = False),\n",
        "            nn.LeakyReLU(0.2, inplace = True),\n",
        "            nn.Conv2d(64, 128, 4, 2, 1, bias = False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2, inplace = True),\n",
        "            nn.Conv2d(128, 256, 4, 2, 1, bias = False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2, inplace = True),\n",
        "            nn.Conv2d(256, 512, 4, 2, 1, bias = False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2, inplace = True),\n",
        "            nn.Conv2d(512, 1, 4, 1, 0, bias = False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = self.main(input)\n",
        "        return output.view(-1)"
      ],
      "metadata": {
        "id": "_EHyuEVqEYHf"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the discriminator\n",
        "netD = D()\n",
        "netD.apply(weights_init)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ta00XQFcFGcU",
        "outputId": "88ad9a28-9330-4158-e56e-d64df7e3adce"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "D(\n",
              "  (main): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
              "    (12): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the DCGANs\n",
        "criterion = nn.BCELoss()\n",
        "optimizerD = optim.Adam(netD.parameters(), lr = 0.0002, betas = (0.5, 0.999)) \n",
        "optimizerG = optim.Adam(netG.parameters(), lr = 0.0002, betas = (0.5, 0.999)) \n",
        "\n",
        "for epoch in range(25):\n",
        "    for i, data in enumerate(dataloader, 0):\n",
        "        #Firstly, updating the weights of the neural network of the discriminator\n",
        "        netD.zero_grad()\n",
        "        # Training the discriminator with a real image of the dataset\n",
        "        real, _ = data\n",
        "        input = Variable(real)\n",
        "        target = Variable(torch.ones(input.size()[0]))\n",
        "        output = netD(input)\n",
        "        errD_real = criterion(output, target)\n",
        "  \n",
        "        # Training the discriminator with a fake image generated by the generator\n",
        "        noise = Variable(torch.randn(input.size()[0], 100, 1, 1))\n",
        "        fake = netG(noise)\n",
        "        target = Variable(torch.zeros(input.size()[0]))\n",
        "        output = netD(fake.detach())\n",
        "        errD_fake = criterion(output, target)\n",
        "        \n",
        "        # Backpropagating the total error\n",
        "        errD = errD_real + errD_fake\n",
        "        errD.backward()\n",
        "        optimizerD.step()\n",
        "\n",
        "        #Secondly, Updating the weights of the neural network of the generator\n",
        "\n",
        "        netG.zero_grad()\n",
        "        target = Variable(torch.ones(input.size()[0]))\n",
        "        output = netD(fake)\n",
        "        errG = criterion(output, target)\n",
        "        errG.backward()\n",
        "        optimizerG.step()\n",
        "        \n",
        "        # Third, printing the losses and saving the real images and the generated images of the minibatch every 100 steps\n",
        "\n",
        "        print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f' % (epoch, 25, i, len(dataloader), errD.data, errG.data))\n",
        "        if i % 100 == 0:\n",
        "            vutils.save_image(real, '%s/real_samples.png' % \"/content/datagan/Result\", normalize = True)\n",
        "            fake = netG(noise)\n",
        "            vutils.save_image(fake.data, '%s/fake_samples_epoch_%03d.png' % (\"/content/datagan/Result\", epoch), normalize = True)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Jea08lsFO1S",
        "outputId": "0995b92c-c028-4ac3-80a2-312ba016128c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0/25][0/782] Loss_D: 1.4072 Loss_G: 6.7885\n",
            "[0/25][1/782] Loss_D: 0.8232 Loss_G: 5.3695\n",
            "[0/25][2/782] Loss_D: 0.9103 Loss_G: 6.9988\n",
            "[0/25][3/782] Loss_D: 0.6422 Loss_G: 5.9843\n",
            "[0/25][4/782] Loss_D: 1.2171 Loss_G: 6.9750\n",
            "[0/25][5/782] Loss_D: 0.6156 Loss_G: 8.1422\n",
            "[0/25][6/782] Loss_D: 0.5814 Loss_G: 7.1860\n",
            "[0/25][7/782] Loss_D: 0.7804 Loss_G: 9.2319\n",
            "[0/25][8/782] Loss_D: 0.4691 Loss_G: 8.0817\n",
            "[0/25][9/782] Loss_D: 0.7614 Loss_G: 9.6159\n",
            "[0/25][10/782] Loss_D: 0.3969 Loss_G: 8.8655\n",
            "[0/25][11/782] Loss_D: 0.7098 Loss_G: 10.2934\n",
            "[0/25][12/782] Loss_D: 0.3886 Loss_G: 9.3059\n",
            "[0/25][13/782] Loss_D: 0.5371 Loss_G: 12.5656\n",
            "[0/25][14/782] Loss_D: 0.1328 Loss_G: 9.7075\n",
            "[0/25][15/782] Loss_D: 0.3969 Loss_G: 8.7835\n",
            "[0/25][16/782] Loss_D: 0.5460 Loss_G: 14.0667\n",
            "[0/25][17/782] Loss_D: 0.3470 Loss_G: 11.1524\n",
            "[0/25][18/782] Loss_D: 0.3991 Loss_G: 8.8277\n",
            "[0/25][19/782] Loss_D: 1.1014 Loss_G: 18.2426\n",
            "[0/25][20/782] Loss_D: 0.3271 Loss_G: 17.4326\n",
            "[0/25][21/782] Loss_D: 0.1619 Loss_G: 10.8031\n",
            "[0/25][22/782] Loss_D: 0.8526 Loss_G: 16.2280\n",
            "[0/25][23/782] Loss_D: 0.2250 Loss_G: 14.5770\n",
            "[0/25][24/782] Loss_D: 0.1218 Loss_G: 7.9607\n",
            "[0/25][25/782] Loss_D: 2.5809 Loss_G: 20.5684\n",
            "[0/25][26/782] Loss_D: 0.3278 Loss_G: 22.6577\n",
            "[0/25][27/782] Loss_D: 0.2663 Loss_G: 18.4906\n",
            "[0/25][28/782] Loss_D: 0.2181 Loss_G: 9.5771\n",
            "[0/25][29/782] Loss_D: 1.1900 Loss_G: 18.8806\n",
            "[0/25][30/782] Loss_D: 0.2572 Loss_G: 19.8366\n",
            "[0/25][31/782] Loss_D: 0.2557 Loss_G: 15.3678\n",
            "[0/25][32/782] Loss_D: 0.0503 Loss_G: 6.6476\n",
            "[0/25][33/782] Loss_D: 3.9170 Loss_G: 22.5529\n",
            "[0/25][34/782] Loss_D: 0.6840 Loss_G: 25.4390\n",
            "[0/25][35/782] Loss_D: 0.3162 Loss_G: 22.4237\n",
            "[0/25][36/782] Loss_D: 0.1109 Loss_G: 14.7507\n",
            "[0/25][37/782] Loss_D: 0.0700 Loss_G: 5.4095\n",
            "[0/25][38/782] Loss_D: 3.6833 Loss_G: 22.5442\n",
            "[0/25][39/782] Loss_D: 0.0758 Loss_G: 26.8522\n",
            "[0/25][40/782] Loss_D: 0.4154 Loss_G: 26.3289\n",
            "[0/25][41/782] Loss_D: 0.1921 Loss_G: 22.9551\n",
            "[0/25][42/782] Loss_D: 0.0435 Loss_G: 17.0720\n",
            "[0/25][43/782] Loss_D: 0.0436 Loss_G: 9.0846\n",
            "[0/25][44/782] Loss_D: 0.4602 Loss_G: 13.3580\n",
            "[0/25][45/782] Loss_D: 0.0324 Loss_G: 13.0034\n",
            "[0/25][46/782] Loss_D: 0.1008 Loss_G: 8.7454\n",
            "[0/25][47/782] Loss_D: 0.3044 Loss_G: 12.8672\n",
            "[0/25][48/782] Loss_D: 0.1953 Loss_G: 11.4279\n",
            "[0/25][49/782] Loss_D: 0.1633 Loss_G: 7.0659\n",
            "[0/25][50/782] Loss_D: 0.7991 Loss_G: 22.2197\n",
            "[0/25][51/782] Loss_D: 0.2657 Loss_G: 25.3477\n",
            "[0/25][52/782] Loss_D: 0.1822 Loss_G: 23.0317\n",
            "[0/25][53/782] Loss_D: 0.0726 Loss_G: 16.2226\n",
            "[0/25][54/782] Loss_D: 0.0737 Loss_G: 6.7789\n",
            "[0/25][55/782] Loss_D: 2.3970 Loss_G: 26.8368\n",
            "[0/25][56/782] Loss_D: 0.8104 Loss_G: 30.7547\n",
            "[0/25][57/782] Loss_D: 0.1841 Loss_G: 31.6363\n",
            "[0/25][58/782] Loss_D: 0.2392 Loss_G: 31.3332\n",
            "[0/25][59/782] Loss_D: 0.0393 Loss_G: 30.8409\n",
            "[0/25][60/782] Loss_D: 0.0216 Loss_G: 29.9162\n",
            "[0/25][61/782] Loss_D: 0.0147 Loss_G: 28.5441\n",
            "[0/25][62/782] Loss_D: 0.0110 Loss_G: 26.2536\n",
            "[0/25][63/782] Loss_D: 0.0159 Loss_G: 20.9738\n",
            "[0/25][64/782] Loss_D: 0.0185 Loss_G: 13.6202\n",
            "[0/25][65/782] Loss_D: 0.0194 Loss_G: 5.5552\n",
            "[0/25][66/782] Loss_D: 2.2098 Loss_G: 25.9013\n",
            "[0/25][67/782] Loss_D: 0.3731 Loss_G: 30.6691\n",
            "[0/25][68/782] Loss_D: 0.5312 Loss_G: 31.3114\n",
            "[0/25][69/782] Loss_D: 0.5179 Loss_G: 29.9440\n",
            "[0/25][70/782] Loss_D: 0.0398 Loss_G: 28.4214\n",
            "[0/25][71/782] Loss_D: 0.0463 Loss_G: 25.6910\n",
            "[0/25][72/782] Loss_D: 0.0176 Loss_G: 19.9195\n",
            "[0/25][73/782] Loss_D: 0.0080 Loss_G: 11.5615\n",
            "[0/25][74/782] Loss_D: 0.1040 Loss_G: 6.9972\n",
            "[0/25][75/782] Loss_D: 1.4001 Loss_G: 27.3311\n",
            "[0/25][76/782] Loss_D: 1.1297 Loss_G: 30.8174\n",
            "[0/25][77/782] Loss_D: 0.7124 Loss_G: 30.4175\n",
            "[0/25][78/782] Loss_D: 0.1856 Loss_G: 29.0248\n",
            "[0/25][79/782] Loss_D: 0.1558 Loss_G: 25.7817\n",
            "[0/25][80/782] Loss_D: 0.0145 Loss_G: 18.6308\n",
            "[0/25][81/782] Loss_D: 0.0327 Loss_G: 8.1319\n",
            "[0/25][82/782] Loss_D: 1.7965 Loss_G: 25.9967\n",
            "[0/25][83/782] Loss_D: 0.4680 Loss_G: 29.4165\n",
            "[0/25][84/782] Loss_D: 0.5013 Loss_G: 28.6652\n",
            "[0/25][85/782] Loss_D: 0.6137 Loss_G: 25.4814\n",
            "[0/25][86/782] Loss_D: 0.0842 Loss_G: 19.6296\n",
            "[0/25][87/782] Loss_D: 0.0221 Loss_G: 11.9687\n",
            "[0/25][88/782] Loss_D: 0.0574 Loss_G: 5.0571\n",
            "[0/25][89/782] Loss_D: 1.8070 Loss_G: 24.3737\n",
            "[0/25][90/782] Loss_D: 0.7476 Loss_G: 27.6740\n",
            "[0/25][91/782] Loss_D: 0.8013 Loss_G: 26.0407\n",
            "[0/25][92/782] Loss_D: 0.3038 Loss_G: 22.8395\n",
            "[0/25][93/782] Loss_D: 0.0945 Loss_G: 18.6487\n",
            "[0/25][94/782] Loss_D: 0.0092 Loss_G: 12.8843\n",
            "[0/25][95/782] Loss_D: 0.0448 Loss_G: 6.0430\n",
            "[0/25][96/782] Loss_D: 1.1588 Loss_G: 20.4152\n",
            "[0/25][97/782] Loss_D: 0.1433 Loss_G: 24.4181\n",
            "[0/25][98/782] Loss_D: 0.4145 Loss_G: 22.5865\n",
            "[0/25][99/782] Loss_D: 0.0720 Loss_G: 19.7640\n",
            "[0/25][100/782] Loss_D: 0.1009 Loss_G: 14.6951\n",
            "[0/25][101/782] Loss_D: 0.0311 Loss_G: 8.8237\n",
            "[0/25][102/782] Loss_D: 0.0999 Loss_G: 5.7707\n",
            "[0/25][103/782] Loss_D: 1.0210 Loss_G: 21.0774\n",
            "[0/25][104/782] Loss_D: 0.0839 Loss_G: 24.1530\n",
            "[0/25][105/782] Loss_D: 0.1942 Loss_G: 23.0381\n",
            "[0/25][106/782] Loss_D: 0.1649 Loss_G: 18.7722\n",
            "[0/25][107/782] Loss_D: 0.1229 Loss_G: 12.6944\n",
            "[0/25][108/782] Loss_D: 0.0606 Loss_G: 5.5976\n",
            "[0/25][109/782] Loss_D: 2.3207 Loss_G: 27.0591\n",
            "[0/25][110/782] Loss_D: 0.6341 Loss_G: 31.9482\n",
            "[0/25][111/782] Loss_D: 0.3073 Loss_G: 32.7103\n",
            "[0/25][112/782] Loss_D: 0.2218 Loss_G: 32.6361\n",
            "[0/25][113/782] Loss_D: 0.1206 Loss_G: 32.0662\n",
            "[0/25][114/782] Loss_D: 0.0604 Loss_G: 31.3783\n",
            "[0/25][115/782] Loss_D: 0.0783 Loss_G: 31.0535\n",
            "[0/25][116/782] Loss_D: 0.0136 Loss_G: 29.0887\n",
            "[0/25][117/782] Loss_D: 0.0068 Loss_G: 26.8135\n",
            "[0/25][118/782] Loss_D: 0.0140 Loss_G: 21.5315\n",
            "[0/25][119/782] Loss_D: 0.0131 Loss_G: 13.9339\n",
            "[0/25][120/782] Loss_D: 0.0279 Loss_G: 5.1165\n",
            "[0/25][121/782] Loss_D: 2.4168 Loss_G: 24.4136\n",
            "[0/25][122/782] Loss_D: 0.8279 Loss_G: 26.5308\n",
            "[0/25][123/782] Loss_D: 0.6532 Loss_G: 23.8214\n",
            "[0/25][124/782] Loss_D: 0.0628 Loss_G: 17.1823\n",
            "[0/25][125/782] Loss_D: 0.1567 Loss_G: 8.1451\n",
            "[0/25][126/782] Loss_D: 1.2494 Loss_G: 13.9497\n",
            "[0/25][127/782] Loss_D: 0.4247 Loss_G: 13.7491\n",
            "[0/25][128/782] Loss_D: 0.2530 Loss_G: 9.2249\n",
            "[0/25][129/782] Loss_D: 0.1214 Loss_G: 5.6616\n",
            "[0/25][130/782] Loss_D: 0.4521 Loss_G: 6.7823\n",
            "[0/25][131/782] Loss_D: 0.2491 Loss_G: 6.6800\n",
            "[0/25][132/782] Loss_D: 0.2521 Loss_G: 6.1813\n",
            "[0/25][133/782] Loss_D: 0.2946 Loss_G: 5.4549\n",
            "[0/25][134/782] Loss_D: 0.4770 Loss_G: 9.3328\n",
            "[0/25][135/782] Loss_D: 0.5207 Loss_G: 6.4448\n",
            "[0/25][136/782] Loss_D: 0.3141 Loss_G: 5.0358\n",
            "[0/25][137/782] Loss_D: 0.2449 Loss_G: 6.9313\n",
            "[0/25][138/782] Loss_D: 0.2870 Loss_G: 5.4159\n",
            "[0/25][139/782] Loss_D: 0.2852 Loss_G: 5.6327\n",
            "[0/25][140/782] Loss_D: 0.3107 Loss_G: 5.7017\n",
            "[0/25][141/782] Loss_D: 0.2264 Loss_G: 5.4242\n",
            "[0/25][142/782] Loss_D: 0.3269 Loss_G: 7.0601\n",
            "[0/25][143/782] Loss_D: 0.8686 Loss_G: 2.6121\n",
            "[0/25][144/782] Loss_D: 1.1608 Loss_G: 11.5333\n",
            "[0/25][145/782] Loss_D: 1.2296 Loss_G: 9.3031\n",
            "[0/25][146/782] Loss_D: 0.1609 Loss_G: 5.8843\n",
            "[0/25][147/782] Loss_D: 0.1779 Loss_G: 3.6742\n",
            "[0/25][148/782] Loss_D: 0.8187 Loss_G: 9.6880\n",
            "[0/25][149/782] Loss_D: 0.3942 Loss_G: 9.8904\n",
            "[0/25][150/782] Loss_D: 0.5311 Loss_G: 6.0940\n",
            "[0/25][151/782] Loss_D: 0.1905 Loss_G: 4.1692\n",
            "[0/25][152/782] Loss_D: 0.5411 Loss_G: 8.2115\n",
            "[0/25][153/782] Loss_D: 0.6187 Loss_G: 6.7228\n",
            "[0/25][154/782] Loss_D: 0.0632 Loss_G: 4.2578\n",
            "[0/25][155/782] Loss_D: 0.3360 Loss_G: 5.3924\n",
            "[0/25][156/782] Loss_D: 0.2029 Loss_G: 5.2876\n",
            "[0/25][157/782] Loss_D: 0.2754 Loss_G: 4.7026\n",
            "[0/25][158/782] Loss_D: 0.3514 Loss_G: 4.2909\n",
            "[0/25][159/782] Loss_D: 0.2422 Loss_G: 5.3018\n",
            "[0/25][160/782] Loss_D: 0.2317 Loss_G: 4.8920\n",
            "[0/25][161/782] Loss_D: 0.2715 Loss_G: 5.6695\n",
            "[0/25][162/782] Loss_D: 0.2035 Loss_G: 4.6841\n",
            "[0/25][163/782] Loss_D: 0.6558 Loss_G: 10.3274\n",
            "[0/25][164/782] Loss_D: 1.8340 Loss_G: 0.3360\n",
            "[0/25][165/782] Loss_D: 3.7359 Loss_G: 9.4473\n",
            "[0/25][166/782] Loss_D: 3.1268 Loss_G: 7.1448\n",
            "[0/25][167/782] Loss_D: 0.4913 Loss_G: 3.5803\n",
            "[0/25][168/782] Loss_D: 0.6670 Loss_G: 3.7967\n",
            "[0/25][169/782] Loss_D: 0.6117 Loss_G: 5.5683\n",
            "[0/25][170/782] Loss_D: 0.3963 Loss_G: 4.3573\n",
            "[0/25][171/782] Loss_D: 0.6027 Loss_G: 2.0736\n",
            "[0/25][172/782] Loss_D: 1.7480 Loss_G: 7.9778\n",
            "[0/25][173/782] Loss_D: 1.8884 Loss_G: 6.3040\n",
            "[0/25][174/782] Loss_D: 0.6634 Loss_G: 1.7636\n",
            "[0/25][175/782] Loss_D: 1.2044 Loss_G: 4.5765\n",
            "[0/25][176/782] Loss_D: 0.3928 Loss_G: 4.7589\n",
            "[0/25][177/782] Loss_D: 0.4330 Loss_G: 3.1000\n",
            "[0/25][178/782] Loss_D: 0.9872 Loss_G: 3.1244\n",
            "[0/25][179/782] Loss_D: 0.7390 Loss_G: 4.0404\n",
            "[0/25][180/782] Loss_D: 1.0217 Loss_G: 2.1415\n",
            "[0/25][181/782] Loss_D: 0.8134 Loss_G: 4.8394\n",
            "[0/25][182/782] Loss_D: 0.6200 Loss_G: 3.3290\n",
            "[0/25][183/782] Loss_D: 0.4374 Loss_G: 3.3042\n",
            "[0/25][184/782] Loss_D: 0.5887 Loss_G: 3.5438\n",
            "[0/25][185/782] Loss_D: 0.7181 Loss_G: 2.5688\n",
            "[0/25][186/782] Loss_D: 0.7413 Loss_G: 4.9900\n",
            "[0/25][187/782] Loss_D: 1.0723 Loss_G: 1.2183\n",
            "[0/25][188/782] Loss_D: 0.8745 Loss_G: 4.7574\n",
            "[0/25][189/782] Loss_D: 0.4901 Loss_G: 3.6711\n",
            "[0/25][190/782] Loss_D: 0.5057 Loss_G: 2.2427\n",
            "[0/25][191/782] Loss_D: 0.6479 Loss_G: 4.9944\n",
            "[0/25][192/782] Loss_D: 0.6540 Loss_G: 2.6668\n",
            "[0/25][193/782] Loss_D: 0.4491 Loss_G: 3.0742\n",
            "[0/25][194/782] Loss_D: 0.4563 Loss_G: 4.0069\n",
            "[0/25][195/782] Loss_D: 0.3655 Loss_G: 3.5328\n",
            "[0/25][196/782] Loss_D: 0.4747 Loss_G: 2.4038\n",
            "[0/25][197/782] Loss_D: 0.6569 Loss_G: 5.2671\n",
            "[0/25][198/782] Loss_D: 0.9763 Loss_G: 2.0157\n",
            "[0/25][199/782] Loss_D: 0.6002 Loss_G: 4.7513\n",
            "[0/25][200/782] Loss_D: 0.3468 Loss_G: 4.1392\n",
            "[0/25][201/782] Loss_D: 0.5637 Loss_G: 2.1128\n",
            "[0/25][202/782] Loss_D: 0.6821 Loss_G: 5.8644\n",
            "[0/25][203/782] Loss_D: 0.8058 Loss_G: 3.5434\n",
            "[0/25][204/782] Loss_D: 0.2987 Loss_G: 3.2976\n",
            "[0/25][205/782] Loss_D: 0.4040 Loss_G: 4.7258\n",
            "[0/25][206/782] Loss_D: 0.5371 Loss_G: 2.7782\n",
            "[0/25][207/782] Loss_D: 0.5128 Loss_G: 6.5577\n",
            "[0/25][208/782] Loss_D: 0.6077 Loss_G: 2.7882\n",
            "[0/25][209/782] Loss_D: 0.7851 Loss_G: 7.6674\n",
            "[0/25][210/782] Loss_D: 0.7827 Loss_G: 2.9218\n",
            "[0/25][211/782] Loss_D: 0.7803 Loss_G: 7.3410\n",
            "[0/25][212/782] Loss_D: 1.5049 Loss_G: 2.9870\n",
            "[0/25][213/782] Loss_D: 0.7431 Loss_G: 4.3798\n",
            "[0/25][214/782] Loss_D: 1.3801 Loss_G: 4.3121\n",
            "[0/25][215/782] Loss_D: 0.7688 Loss_G: 3.7630\n",
            "[0/25][216/782] Loss_D: 0.5360 Loss_G: 5.2743\n",
            "[0/25][217/782] Loss_D: 0.6242 Loss_G: 3.4165\n",
            "[0/25][218/782] Loss_D: 0.4974 Loss_G: 4.7891\n",
            "[0/25][219/782] Loss_D: 0.4209 Loss_G: 4.1461\n",
            "[0/25][220/782] Loss_D: 0.3689 Loss_G: 3.7985\n",
            "[0/25][221/782] Loss_D: 0.4888 Loss_G: 6.0494\n",
            "[0/25][222/782] Loss_D: 0.8794 Loss_G: 1.5311\n",
            "[0/25][223/782] Loss_D: 1.6210 Loss_G: 9.8600\n",
            "[0/25][224/782] Loss_D: 2.4964 Loss_G: 5.8816\n",
            "[0/25][225/782] Loss_D: 0.5684 Loss_G: 1.5167\n",
            "[0/25][226/782] Loss_D: 1.4976 Loss_G: 7.0002\n",
            "[0/25][227/782] Loss_D: 1.0734 Loss_G: 4.1526\n",
            "[0/25][228/782] Loss_D: 0.5620 Loss_G: 2.4622\n",
            "[0/25][229/782] Loss_D: 0.8424 Loss_G: 5.4727\n",
            "[0/25][230/782] Loss_D: 0.8452 Loss_G: 2.9567\n",
            "[0/25][231/782] Loss_D: 0.9855 Loss_G: 5.3475\n",
            "[0/25][232/782] Loss_D: 0.6810 Loss_G: 3.6192\n",
            "[0/25][233/782] Loss_D: 0.5523 Loss_G: 3.6014\n",
            "[0/25][234/782] Loss_D: 0.7574 Loss_G: 5.5449\n",
            "[0/25][235/782] Loss_D: 0.8168 Loss_G: 3.0630\n",
            "[0/25][236/782] Loss_D: 0.7371 Loss_G: 6.0191\n",
            "[0/25][237/782] Loss_D: 0.6880 Loss_G: 3.5126\n",
            "[0/25][238/782] Loss_D: 0.5021 Loss_G: 6.2447\n",
            "[0/25][239/782] Loss_D: 0.4582 Loss_G: 4.2618\n",
            "[0/25][240/782] Loss_D: 0.4015 Loss_G: 5.1327\n",
            "[0/25][241/782] Loss_D: 0.3445 Loss_G: 4.6056\n",
            "[0/25][242/782] Loss_D: 0.4887 Loss_G: 3.9386\n",
            "[0/25][243/782] Loss_D: 0.5984 Loss_G: 5.7177\n",
            "[0/25][244/782] Loss_D: 0.8623 Loss_G: 2.4798\n",
            "[0/25][245/782] Loss_D: 0.9963 Loss_G: 7.6627\n",
            "[0/25][246/782] Loss_D: 0.6849 Loss_G: 5.1185\n",
            "[0/25][247/782] Loss_D: 0.2197 Loss_G: 3.6589\n",
            "[0/25][248/782] Loss_D: 0.7916 Loss_G: 7.6602\n",
            "[0/25][249/782] Loss_D: 0.6039 Loss_G: 5.2532\n",
            "[0/25][250/782] Loss_D: 0.2840 Loss_G: 4.2424\n",
            "[0/25][251/782] Loss_D: 0.4460 Loss_G: 6.4731\n",
            "[0/25][252/782] Loss_D: 0.4760 Loss_G: 4.3055\n",
            "[0/25][253/782] Loss_D: 0.7868 Loss_G: 6.7208\n",
            "[0/25][254/782] Loss_D: 0.4422 Loss_G: 4.3235\n",
            "[0/25][255/782] Loss_D: 0.6377 Loss_G: 7.1166\n",
            "[0/25][256/782] Loss_D: 0.4137 Loss_G: 4.4575\n",
            "[0/25][257/782] Loss_D: 0.4682 Loss_G: 5.3783\n",
            "[0/25][258/782] Loss_D: 0.4144 Loss_G: 5.6310\n",
            "[0/25][259/782] Loss_D: 0.2810 Loss_G: 4.4578\n",
            "[0/25][260/782] Loss_D: 0.4862 Loss_G: 6.9611\n",
            "[0/25][261/782] Loss_D: 0.6598 Loss_G: 2.1761\n",
            "[0/25][262/782] Loss_D: 1.2565 Loss_G: 11.1234\n",
            "[0/25][263/782] Loss_D: 2.1403 Loss_G: 6.7075\n",
            "[0/25][264/782] Loss_D: 0.1966 Loss_G: 4.3268\n",
            "[0/25][265/782] Loss_D: 0.3762 Loss_G: 5.6391\n",
            "[0/25][266/782] Loss_D: 0.3786 Loss_G: 4.1383\n",
            "[0/25][267/782] Loss_D: 0.3870 Loss_G: 6.0487\n",
            "[0/25][268/782] Loss_D: 0.1287 Loss_G: 5.7682\n",
            "[0/25][269/782] Loss_D: 0.2843 Loss_G: 3.8274\n",
            "[0/25][270/782] Loss_D: 0.3450 Loss_G: 6.2772\n",
            "[0/25][271/782] Loss_D: 0.2102 Loss_G: 5.1496\n",
            "[0/25][272/782] Loss_D: 0.1623 Loss_G: 4.1898\n",
            "[0/25][273/782] Loss_D: 0.2701 Loss_G: 5.5021\n",
            "[0/25][274/782] Loss_D: 0.2163 Loss_G: 4.8329\n",
            "[0/25][275/782] Loss_D: 0.3581 Loss_G: 3.4434\n",
            "[0/25][276/782] Loss_D: 0.5578 Loss_G: 7.6336\n",
            "[0/25][277/782] Loss_D: 0.2889 Loss_G: 6.6666\n",
            "[0/25][278/782] Loss_D: 0.1909 Loss_G: 3.9501\n",
            "[0/25][279/782] Loss_D: 0.3362 Loss_G: 5.9929\n",
            "[0/25][280/782] Loss_D: 0.1303 Loss_G: 5.8351\n",
            "[0/25][281/782] Loss_D: 0.2099 Loss_G: 3.5977\n",
            "[0/25][282/782] Loss_D: 0.5649 Loss_G: 9.6585\n",
            "[0/25][283/782] Loss_D: 0.7336 Loss_G: 7.6960\n",
            "[0/25][284/782] Loss_D: 0.1514 Loss_G: 4.4560\n",
            "[0/25][285/782] Loss_D: 0.3012 Loss_G: 5.9976\n",
            "[0/25][286/782] Loss_D: 0.1434 Loss_G: 6.2554\n",
            "[0/25][287/782] Loss_D: 0.1385 Loss_G: 5.9875\n",
            "[0/25][288/782] Loss_D: 0.1822 Loss_G: 6.0718\n",
            "[0/25][289/782] Loss_D: 0.2070 Loss_G: 5.4267\n",
            "[0/25][290/782] Loss_D: 0.2327 Loss_G: 7.3982\n",
            "[0/25][291/782] Loss_D: 0.2855 Loss_G: 5.1187\n",
            "[0/25][292/782] Loss_D: 0.2992 Loss_G: 7.4923\n",
            "[0/25][293/782] Loss_D: 0.2441 Loss_G: 6.4275\n",
            "[0/25][294/782] Loss_D: 0.2822 Loss_G: 7.8703\n",
            "[0/25][295/782] Loss_D: 0.1611 Loss_G: 6.2056\n",
            "[0/25][296/782] Loss_D: 0.2824 Loss_G: 7.2992\n",
            "[0/25][297/782] Loss_D: 0.3125 Loss_G: 4.6430\n",
            "[0/25][298/782] Loss_D: 0.3125 Loss_G: 9.5919\n",
            "[0/25][299/782] Loss_D: 0.2350 Loss_G: 7.3251\n",
            "[0/25][300/782] Loss_D: 0.0807 Loss_G: 4.4808\n",
            "[0/25][301/782] Loss_D: 0.3187 Loss_G: 10.0445\n",
            "[0/25][302/782] Loss_D: 0.1737 Loss_G: 9.5517\n",
            "[0/25][303/782] Loss_D: 0.1673 Loss_G: 5.7253\n",
            "[0/25][304/782] Loss_D: 0.0812 Loss_G: 5.1821\n",
            "[0/25][305/782] Loss_D: 0.1755 Loss_G: 6.4232\n",
            "[0/25][306/782] Loss_D: 0.0989 Loss_G: 6.1017\n",
            "[0/25][307/782] Loss_D: 0.1047 Loss_G: 5.2541\n",
            "[0/25][308/782] Loss_D: 0.1506 Loss_G: 6.6699\n",
            "[0/25][309/782] Loss_D: 0.1390 Loss_G: 5.2299\n",
            "[0/25][310/782] Loss_D: 0.1909 Loss_G: 6.4018\n",
            "[0/25][311/782] Loss_D: 0.5606 Loss_G: 4.0152\n",
            "[0/25][312/782] Loss_D: 0.5895 Loss_G: 13.4040\n",
            "[0/25][313/782] Loss_D: 1.0097 Loss_G: 9.8828\n",
            "[0/25][314/782] Loss_D: 0.0763 Loss_G: 5.3414\n",
            "[0/25][315/782] Loss_D: 0.5920 Loss_G: 9.6098\n",
            "[0/25][316/782] Loss_D: 0.1908 Loss_G: 7.7105\n",
            "[0/25][317/782] Loss_D: 0.2441 Loss_G: 5.8075\n",
            "[0/25][318/782] Loss_D: 0.6659 Loss_G: 13.9116\n",
            "[0/25][319/782] Loss_D: 0.7895 Loss_G: 10.0920\n",
            "[0/25][320/782] Loss_D: 0.0825 Loss_G: 5.8973\n",
            "[0/25][321/782] Loss_D: 0.6408 Loss_G: 13.9771\n",
            "[0/25][322/782] Loss_D: 0.9305 Loss_G: 11.1692\n",
            "[0/25][323/782] Loss_D: 0.0331 Loss_G: 7.1783\n",
            "[0/25][324/782] Loss_D: 0.3362 Loss_G: 8.7245\n",
            "[0/25][325/782] Loss_D: 0.0603 Loss_G: 7.5640\n",
            "[0/25][326/782] Loss_D: 0.2470 Loss_G: 4.5008\n",
            "[0/25][327/782] Loss_D: 0.3322 Loss_G: 9.1067\n",
            "[0/25][328/782] Loss_D: 0.0814 Loss_G: 9.0562\n",
            "[0/25][329/782] Loss_D: 0.2230 Loss_G: 6.0101\n",
            "[0/25][330/782] Loss_D: 0.3837 Loss_G: 6.6351\n",
            "[0/25][331/782] Loss_D: 0.2593 Loss_G: 8.2158\n",
            "[0/25][332/782] Loss_D: 0.4130 Loss_G: 5.3689\n",
            "[0/25][333/782] Loss_D: 0.4258 Loss_G: 9.8386\n",
            "[0/25][334/782] Loss_D: 0.6232 Loss_G: 5.9887\n",
            "[0/25][335/782] Loss_D: 0.1640 Loss_G: 5.3509\n",
            "[0/25][336/782] Loss_D: 0.3064 Loss_G: 9.8095\n",
            "[0/25][337/782] Loss_D: 0.1509 Loss_G: 8.5686\n",
            "[0/25][338/782] Loss_D: 0.4131 Loss_G: 2.7332\n",
            "[0/25][339/782] Loss_D: 2.2583 Loss_G: 17.2760\n",
            "[0/25][340/782] Loss_D: 5.2390 Loss_G: 12.7356\n",
            "[0/25][341/782] Loss_D: 1.1834 Loss_G: 4.6584\n",
            "[0/25][342/782] Loss_D: 2.1822 Loss_G: 8.4166\n",
            "[0/25][343/782] Loss_D: 0.7058 Loss_G: 6.3746\n",
            "[0/25][344/782] Loss_D: 0.2358 Loss_G: 4.5955\n",
            "[0/25][345/782] Loss_D: 0.3871 Loss_G: 4.0970\n",
            "[0/25][346/782] Loss_D: 0.5182 Loss_G: 4.8620\n",
            "[0/25][347/782] Loss_D: 0.4812 Loss_G: 3.6149\n",
            "[0/25][348/782] Loss_D: 0.4704 Loss_G: 4.9000\n",
            "[0/25][349/782] Loss_D: 0.4130 Loss_G: 3.8932\n",
            "[0/25][350/782] Loss_D: 0.3252 Loss_G: 3.9735\n",
            "[0/25][351/782] Loss_D: 0.2894 Loss_G: 3.6562\n",
            "[0/25][352/782] Loss_D: 0.3107 Loss_G: 3.6107\n",
            "[0/25][353/782] Loss_D: 0.3852 Loss_G: 4.1144\n",
            "[0/25][354/782] Loss_D: 0.4308 Loss_G: 2.6867\n",
            "[0/25][355/782] Loss_D: 0.3575 Loss_G: 5.0079\n",
            "[0/25][356/782] Loss_D: 0.5771 Loss_G: 2.5619\n",
            "[0/25][357/782] Loss_D: 0.3878 Loss_G: 4.2398\n",
            "[0/25][358/782] Loss_D: 0.2265 Loss_G: 4.1575\n",
            "[0/25][359/782] Loss_D: 0.3009 Loss_G: 2.9992\n",
            "[0/25][360/782] Loss_D: 0.3424 Loss_G: 3.6425\n",
            "[0/25][361/782] Loss_D: 0.2149 Loss_G: 4.1764\n",
            "[0/25][362/782] Loss_D: 0.2276 Loss_G: 3.6045\n",
            "[0/25][363/782] Loss_D: 0.3087 Loss_G: 3.1764\n",
            "[0/25][364/782] Loss_D: 0.2696 Loss_G: 4.0589\n",
            "[0/25][365/782] Loss_D: 0.2514 Loss_G: 3.9513\n",
            "[0/25][366/782] Loss_D: 0.2524 Loss_G: 3.4791\n",
            "[0/25][367/782] Loss_D: 0.4325 Loss_G: 3.8314\n",
            "[0/25][368/782] Loss_D: 0.2869 Loss_G: 4.1374\n",
            "[0/25][369/782] Loss_D: 0.2943 Loss_G: 3.3573\n",
            "[0/25][370/782] Loss_D: 0.2533 Loss_G: 4.5968\n",
            "[0/25][371/782] Loss_D: 0.2350 Loss_G: 4.0758\n",
            "[0/25][372/782] Loss_D: 0.1950 Loss_G: 4.1074\n",
            "[0/25][373/782] Loss_D: 0.1750 Loss_G: 4.1607\n",
            "[0/25][374/782] Loss_D: 0.2049 Loss_G: 4.5348\n",
            "[0/25][375/782] Loss_D: 0.3447 Loss_G: 3.0486\n",
            "[0/25][376/782] Loss_D: 0.3358 Loss_G: 5.4647\n",
            "[0/25][377/782] Loss_D: 0.2763 Loss_G: 4.1737\n",
            "[0/25][378/782] Loss_D: 0.2520 Loss_G: 3.6150\n",
            "[0/25][379/782] Loss_D: 0.1751 Loss_G: 4.7342\n",
            "[0/25][380/782] Loss_D: 0.2111 Loss_G: 4.8912\n",
            "[0/25][381/782] Loss_D: 0.4224 Loss_G: 2.3727\n",
            "[0/25][382/782] Loss_D: 0.6346 Loss_G: 9.5699\n",
            "[0/25][383/782] Loss_D: 0.4903 Loss_G: 7.2898\n",
            "[0/25][384/782] Loss_D: 0.2335 Loss_G: 3.9383\n",
            "[0/25][385/782] Loss_D: 0.6298 Loss_G: 6.5193\n",
            "[0/25][386/782] Loss_D: 0.3159 Loss_G: 5.7052\n",
            "[0/25][387/782] Loss_D: 0.3492 Loss_G: 3.7031\n",
            "[0/25][388/782] Loss_D: 0.7747 Loss_G: 3.7213\n",
            "[0/25][389/782] Loss_D: 0.4646 Loss_G: 5.5072\n",
            "[0/25][390/782] Loss_D: 0.4670 Loss_G: 2.3433\n",
            "[0/25][391/782] Loss_D: 0.6388 Loss_G: 9.7397\n",
            "[0/25][392/782] Loss_D: 0.7080 Loss_G: 6.4959\n",
            "[0/25][393/782] Loss_D: 0.0857 Loss_G: 3.9425\n",
            "[0/25][394/782] Loss_D: 0.2812 Loss_G: 5.8323\n",
            "[0/25][395/782] Loss_D: 0.2910 Loss_G: 4.5575\n",
            "[0/25][396/782] Loss_D: 0.3833 Loss_G: 3.9619\n",
            "[0/25][397/782] Loss_D: 0.6310 Loss_G: 5.2897\n",
            "[0/25][398/782] Loss_D: 1.3774 Loss_G: 1.0352\n",
            "[0/25][399/782] Loss_D: 1.9019 Loss_G: 9.1471\n",
            "[0/25][400/782] Loss_D: 2.8247 Loss_G: 4.9592\n",
            "[0/25][401/782] Loss_D: 0.3613 Loss_G: 2.6135\n",
            "[0/25][402/782] Loss_D: 0.9223 Loss_G: 5.5309\n",
            "[0/25][403/782] Loss_D: 1.1879 Loss_G: 1.8024\n",
            "[0/25][404/782] Loss_D: 1.7652 Loss_G: 6.0643\n",
            "[0/25][405/782] Loss_D: 1.1305 Loss_G: 2.7152\n",
            "[0/25][406/782] Loss_D: 0.7924 Loss_G: 4.2106\n",
            "[0/25][407/782] Loss_D: 0.9928 Loss_G: 3.0652\n",
            "[0/25][408/782] Loss_D: 1.1362 Loss_G: 2.9296\n",
            "[0/25][409/782] Loss_D: 0.7867 Loss_G: 4.4679\n",
            "[0/25][410/782] Loss_D: 0.5937 Loss_G: 3.1493\n",
            "[0/25][411/782] Loss_D: 0.4571 Loss_G: 5.4412\n",
            "[0/25][412/782] Loss_D: 0.6646 Loss_G: 2.9790\n",
            "[0/25][413/782] Loss_D: 0.4587 Loss_G: 4.7973\n",
            "[0/25][414/782] Loss_D: 0.4024 Loss_G: 4.9557\n",
            "[0/25][415/782] Loss_D: 0.6092 Loss_G: 2.2075\n",
            "[0/25][416/782] Loss_D: 0.7135 Loss_G: 5.5115\n",
            "[0/25][417/782] Loss_D: 0.6766 Loss_G: 3.0329\n",
            "[0/25][418/782] Loss_D: 0.7436 Loss_G: 5.9544\n",
            "[0/25][419/782] Loss_D: 0.9258 Loss_G: 2.4593\n",
            "[0/25][420/782] Loss_D: 1.0788 Loss_G: 6.8879\n",
            "[0/25][421/782] Loss_D: 0.7352 Loss_G: 4.5628\n",
            "[0/25][422/782] Loss_D: 0.4398 Loss_G: 3.9668\n",
            "[0/25][423/782] Loss_D: 0.4214 Loss_G: 3.3600\n",
            "[0/25][424/782] Loss_D: 0.4385 Loss_G: 4.3293\n",
            "[0/25][425/782] Loss_D: 0.4246 Loss_G: 4.2674\n",
            "[0/25][426/782] Loss_D: 0.4723 Loss_G: 3.3796\n",
            "[0/25][427/782] Loss_D: 0.7217 Loss_G: 3.7215\n",
            "[0/25][428/782] Loss_D: 0.5876 Loss_G: 4.5312\n",
            "[0/25][429/782] Loss_D: 0.4615 Loss_G: 3.6792\n",
            "[0/25][430/782] Loss_D: 0.4860 Loss_G: 3.4113\n",
            "[0/25][431/782] Loss_D: 0.6386 Loss_G: 6.8982\n",
            "[0/25][432/782] Loss_D: 0.6734 Loss_G: 2.0058\n",
            "[0/25][433/782] Loss_D: 1.1170 Loss_G: 9.2358\n",
            "[0/25][434/782] Loss_D: 1.2242 Loss_G: 2.6340\n",
            "[0/25][435/782] Loss_D: 0.8706 Loss_G: 6.0668\n",
            "[0/25][436/782] Loss_D: 0.3784 Loss_G: 4.3605\n",
            "[0/25][437/782] Loss_D: 0.5400 Loss_G: 6.0887\n",
            "[0/25][438/782] Loss_D: 1.2619 Loss_G: 1.3488\n",
            "[0/25][439/782] Loss_D: 1.3593 Loss_G: 7.7672\n",
            "[0/25][440/782] Loss_D: 1.5005 Loss_G: 2.8181\n",
            "[0/25][441/782] Loss_D: 0.8638 Loss_G: 4.7028\n",
            "[0/25][442/782] Loss_D: 0.5877 Loss_G: 5.7470\n",
            "[0/25][443/782] Loss_D: 0.7387 Loss_G: 3.1145\n",
            "[0/25][444/782] Loss_D: 1.0215 Loss_G: 6.3927\n",
            "[0/25][445/782] Loss_D: 0.6713 Loss_G: 3.8853\n",
            "[0/25][446/782] Loss_D: 0.7764 Loss_G: 6.1522\n",
            "[0/25][447/782] Loss_D: 0.7027 Loss_G: 3.7064\n",
            "[0/25][448/782] Loss_D: 0.8635 Loss_G: 7.0369\n",
            "[0/25][449/782] Loss_D: 1.3211 Loss_G: 3.1567\n",
            "[0/25][450/782] Loss_D: 0.8490 Loss_G: 4.7064\n",
            "[0/25][451/782] Loss_D: 0.4165 Loss_G: 4.3196\n",
            "[0/25][452/782] Loss_D: 0.3855 Loss_G: 3.5251\n",
            "[0/25][453/782] Loss_D: 0.3604 Loss_G: 4.3778\n",
            "[0/25][454/782] Loss_D: 0.3745 Loss_G: 3.9828\n",
            "[0/25][455/782] Loss_D: 0.2955 Loss_G: 3.9106\n",
            "[0/25][456/782] Loss_D: 0.3201 Loss_G: 4.2970\n",
            "[0/25][457/782] Loss_D: 0.5036 Loss_G: 3.0529\n",
            "[0/25][458/782] Loss_D: 0.6239 Loss_G: 4.5746\n",
            "[0/25][459/782] Loss_D: 0.3265 Loss_G: 4.1946\n",
            "[0/25][460/782] Loss_D: 0.4595 Loss_G: 2.5859\n",
            "[0/25][461/782] Loss_D: 0.9491 Loss_G: 6.1937\n",
            "[0/25][462/782] Loss_D: 0.8511 Loss_G: 3.3006\n",
            "[0/25][463/782] Loss_D: 0.4472 Loss_G: 2.8436\n",
            "[0/25][464/782] Loss_D: 0.6136 Loss_G: 5.0827\n",
            "[0/25][465/782] Loss_D: 0.6121 Loss_G: 2.8031\n",
            "[0/25][466/782] Loss_D: 0.6423 Loss_G: 4.7217\n",
            "[0/25][467/782] Loss_D: 0.6282 Loss_G: 3.2937\n",
            "[0/25][468/782] Loss_D: 0.9203 Loss_G: 6.7724\n",
            "[0/25][469/782] Loss_D: 1.0167 Loss_G: 3.4567\n",
            "[0/25][470/782] Loss_D: 0.4125 Loss_G: 3.4117\n",
            "[0/25][471/782] Loss_D: 0.3739 Loss_G: 4.7151\n",
            "[0/25][472/782] Loss_D: 0.5626 Loss_G: 2.9167\n",
            "[0/25][473/782] Loss_D: 0.5862 Loss_G: 4.4857\n",
            "[0/25][474/782] Loss_D: 0.4393 Loss_G: 4.3140\n",
            "[0/25][475/782] Loss_D: 0.4122 Loss_G: 2.8079\n",
            "[0/25][476/782] Loss_D: 1.1182 Loss_G: 8.7163\n",
            "[0/25][477/782] Loss_D: 1.0738 Loss_G: 4.7233\n",
            "[0/25][478/782] Loss_D: 0.2984 Loss_G: 2.8813\n",
            "[0/25][479/782] Loss_D: 0.5273 Loss_G: 5.7879\n",
            "[0/25][480/782] Loss_D: 0.4150 Loss_G: 3.8373\n",
            "[0/25][481/782] Loss_D: 0.2758 Loss_G: 3.7550\n",
            "[0/25][482/782] Loss_D: 0.2198 Loss_G: 4.3239\n",
            "[0/25][483/782] Loss_D: 0.1751 Loss_G: 4.1323\n",
            "[0/25][484/782] Loss_D: 0.2681 Loss_G: 3.7436\n",
            "[0/25][485/782] Loss_D: 0.3738 Loss_G: 3.2378\n",
            "[0/25][486/782] Loss_D: 0.3670 Loss_G: 4.3282\n",
            "[0/25][487/782] Loss_D: 0.3407 Loss_G: 3.6647\n",
            "[0/25][488/782] Loss_D: 0.3287 Loss_G: 4.0628\n",
            "[0/25][489/782] Loss_D: 0.2659 Loss_G: 4.1950\n",
            "[0/25][490/782] Loss_D: 0.3564 Loss_G: 2.9025\n",
            "[0/25][491/782] Loss_D: 0.4524 Loss_G: 6.6528\n",
            "[0/25][492/782] Loss_D: 0.5552 Loss_G: 3.2910\n",
            "[0/25][493/782] Loss_D: 0.3734 Loss_G: 4.7348\n",
            "[0/25][494/782] Loss_D: 0.2282 Loss_G: 4.6703\n",
            "[0/25][495/782] Loss_D: 0.2439 Loss_G: 4.7425\n",
            "[0/25][496/782] Loss_D: 0.3706 Loss_G: 4.1885\n",
            "[0/25][497/782] Loss_D: 0.3301 Loss_G: 3.4790\n",
            "[0/25][498/782] Loss_D: 0.5834 Loss_G: 8.2699\n",
            "[0/25][499/782] Loss_D: 1.1435 Loss_G: 1.8651\n",
            "[0/25][500/782] Loss_D: 1.2484 Loss_G: 10.5509\n",
            "[0/25][501/782] Loss_D: 1.3111 Loss_G: 5.6642\n",
            "[0/25][502/782] Loss_D: 0.3269 Loss_G: 5.4157\n",
            "[0/25][503/782] Loss_D: 0.2860 Loss_G: 4.7989\n",
            "[0/25][504/782] Loss_D: 0.4065 Loss_G: 4.4297\n",
            "[0/25][505/782] Loss_D: 0.5525 Loss_G: 8.3839\n",
            "[0/25][506/782] Loss_D: 0.9599 Loss_G: 3.2293\n",
            "[0/25][507/782] Loss_D: 0.6952 Loss_G: 9.3131\n",
            "[0/25][508/782] Loss_D: 0.2352 Loss_G: 8.4001\n",
            "[0/25][509/782] Loss_D: 0.2953 Loss_G: 5.4554\n",
            "[0/25][510/782] Loss_D: 0.3346 Loss_G: 6.1426\n",
            "[0/25][511/782] Loss_D: 0.5233 Loss_G: 5.9581\n",
            "[0/25][512/782] Loss_D: 0.5651 Loss_G: 6.8529\n",
            "[0/25][513/782] Loss_D: 0.5700 Loss_G: 4.6214\n",
            "[0/25][514/782] Loss_D: 0.8501 Loss_G: 7.6692\n",
            "[0/25][515/782] Loss_D: 0.3855 Loss_G: 5.7481\n",
            "[0/25][516/782] Loss_D: 0.2525 Loss_G: 4.4652\n",
            "[0/25][517/782] Loss_D: 0.5816 Loss_G: 7.1005\n",
            "[0/25][518/782] Loss_D: 0.6017 Loss_G: 5.3642\n",
            "[0/25][519/782] Loss_D: 0.3997 Loss_G: 3.9711\n",
            "[0/25][520/782] Loss_D: 0.5040 Loss_G: 5.2756\n",
            "[0/25][521/782] Loss_D: 0.2362 Loss_G: 5.2710\n",
            "[0/25][522/782] Loss_D: 0.2385 Loss_G: 4.4221\n",
            "[0/25][523/782] Loss_D: 0.3442 Loss_G: 6.0318\n",
            "[0/25][524/782] Loss_D: 0.5588 Loss_G: 3.1768\n",
            "[0/25][525/782] Loss_D: 0.4942 Loss_G: 7.2808\n",
            "[0/25][526/782] Loss_D: 0.1988 Loss_G: 6.6031\n",
            "[0/25][527/782] Loss_D: 0.1742 Loss_G: 3.8755\n",
            "[0/25][528/782] Loss_D: 0.5388 Loss_G: 8.2663\n",
            "[0/25][529/782] Loss_D: 0.5108 Loss_G: 4.5948\n",
            "[0/25][530/782] Loss_D: 0.3782 Loss_G: 4.4020\n",
            "[0/25][531/782] Loss_D: 0.6426 Loss_G: 6.0464\n",
            "[0/25][532/782] Loss_D: 0.5896 Loss_G: 3.8561\n",
            "[0/25][533/782] Loss_D: 0.6999 Loss_G: 8.1351\n",
            "[0/25][534/782] Loss_D: 1.0583 Loss_G: 2.7574\n",
            "[0/25][535/782] Loss_D: 0.8106 Loss_G: 9.5646\n",
            "[0/25][536/782] Loss_D: 0.7057 Loss_G: 7.2686\n",
            "[0/25][537/782] Loss_D: 0.0918 Loss_G: 4.5920\n",
            "[0/25][538/782] Loss_D: 0.5043 Loss_G: 7.8395\n",
            "[0/25][539/782] Loss_D: 0.5544 Loss_G: 4.7936\n",
            "[0/25][540/782] Loss_D: 0.6285 Loss_G: 6.9792\n",
            "[0/25][541/782] Loss_D: 0.2156 Loss_G: 6.2503\n",
            "[0/25][542/782] Loss_D: 0.1862 Loss_G: 4.6139\n",
            "[0/25][543/782] Loss_D: 0.3605 Loss_G: 6.6078\n",
            "[0/25][544/782] Loss_D: 0.2807 Loss_G: 4.8721\n",
            "[0/25][545/782] Loss_D: 0.6327 Loss_G: 6.5190\n",
            "[0/25][546/782] Loss_D: 0.2975 Loss_G: 3.5163\n",
            "[0/25][547/782] Loss_D: 0.6197 Loss_G: 9.7646\n",
            "[0/25][548/782] Loss_D: 1.3535 Loss_G: 3.3560\n",
            "[0/25][549/782] Loss_D: 0.5917 Loss_G: 6.8479\n",
            "[0/25][550/782] Loss_D: 0.1213 Loss_G: 6.8959\n",
            "[0/25][551/782] Loss_D: 0.3247 Loss_G: 4.2432\n",
            "[0/25][552/782] Loss_D: 0.5894 Loss_G: 6.8459\n",
            "[0/25][553/782] Loss_D: 0.1281 Loss_G: 6.8298\n",
            "[0/25][554/782] Loss_D: 0.3354 Loss_G: 4.3289\n",
            "[0/25][555/782] Loss_D: 0.3187 Loss_G: 5.0470\n",
            "[0/25][556/782] Loss_D: 0.3105 Loss_G: 5.5320\n",
            "[0/25][557/782] Loss_D: 0.2032 Loss_G: 4.8292\n",
            "[0/25][558/782] Loss_D: 0.2900 Loss_G: 4.4652\n",
            "[0/25][559/782] Loss_D: 0.3635 Loss_G: 4.2677\n",
            "[0/25][560/782] Loss_D: 0.3600 Loss_G: 6.9537\n",
            "[0/25][561/782] Loss_D: 0.1420 Loss_G: 5.8438\n",
            "[0/25][562/782] Loss_D: 0.1956 Loss_G: 3.9360\n",
            "[0/25][563/782] Loss_D: 0.2303 Loss_G: 4.6304\n",
            "[0/25][564/782] Loss_D: 0.1812 Loss_G: 5.4030\n",
            "[0/25][565/782] Loss_D: 0.4111 Loss_G: 2.9605\n",
            "[0/25][566/782] Loss_D: 0.4990 Loss_G: 7.1325\n",
            "[0/25][567/782] Loss_D: 0.5598 Loss_G: 3.5248\n",
            "[0/25][568/782] Loss_D: 0.4315 Loss_G: 6.1062\n",
            "[0/25][569/782] Loss_D: 0.1765 Loss_G: 5.6253\n",
            "[0/25][570/782] Loss_D: 0.5692 Loss_G: 2.5607\n",
            "[0/25][571/782] Loss_D: 0.6474 Loss_G: 7.7535\n",
            "[0/25][572/782] Loss_D: 0.1362 Loss_G: 7.7699\n",
            "[0/25][573/782] Loss_D: 1.0742 Loss_G: 2.3772\n",
            "[0/25][574/782] Loss_D: 0.7776 Loss_G: 7.4014\n",
            "[0/25][575/782] Loss_D: 0.0969 Loss_G: 7.8737\n",
            "[0/25][576/782] Loss_D: 0.2511 Loss_G: 5.9205\n",
            "[0/25][577/782] Loss_D: 0.0823 Loss_G: 4.6131\n",
            "[0/25][578/782] Loss_D: 0.1410 Loss_G: 4.7535\n",
            "[0/25][579/782] Loss_D: 0.1871 Loss_G: 5.3331\n",
            "[0/25][580/782] Loss_D: 0.1019 Loss_G: 5.2625\n",
            "[0/25][581/782] Loss_D: 0.4046 Loss_G: 2.7844\n",
            "[0/25][582/782] Loss_D: 0.7609 Loss_G: 5.1731\n",
            "[0/25][583/782] Loss_D: 0.6737 Loss_G: 2.3441\n",
            "[0/25][584/782] Loss_D: 0.4690 Loss_G: 5.9893\n",
            "[0/25][585/782] Loss_D: 0.1480 Loss_G: 6.6520\n",
            "[0/25][586/782] Loss_D: 0.2015 Loss_G: 4.5988\n",
            "[0/25][587/782] Loss_D: 0.2657 Loss_G: 5.1838\n",
            "[0/25][588/782] Loss_D: 0.1870 Loss_G: 5.4435\n",
            "[0/25][589/782] Loss_D: 0.4719 Loss_G: 2.9447\n",
            "[0/25][590/782] Loss_D: 0.7799 Loss_G: 8.8018\n",
            "[0/25][591/782] Loss_D: 1.4328 Loss_G: 1.7803\n",
            "[0/25][592/782] Loss_D: 1.0655 Loss_G: 11.4813\n",
            "[0/25][593/782] Loss_D: 2.2848 Loss_G: 4.0946\n",
            "[0/25][594/782] Loss_D: 0.3560 Loss_G: 4.4577\n",
            "[0/25][595/782] Loss_D: 0.8937 Loss_G: 7.6354\n",
            "[0/25][596/782] Loss_D: 1.1996 Loss_G: 2.0507\n",
            "[0/25][597/782] Loss_D: 1.0628 Loss_G: 6.0776\n",
            "[0/25][598/782] Loss_D: 0.8577 Loss_G: 2.9423\n",
            "[0/25][599/782] Loss_D: 0.6071 Loss_G: 5.3499\n",
            "[0/25][600/782] Loss_D: 0.7977 Loss_G: 2.1741\n",
            "[0/25][601/782] Loss_D: 1.4266 Loss_G: 8.9231\n",
            "[0/25][602/782] Loss_D: 1.8601 Loss_G: 4.5102\n",
            "[0/25][603/782] Loss_D: 0.4514 Loss_G: 2.2121\n",
            "[0/25][604/782] Loss_D: 1.7290 Loss_G: 7.0321\n",
            "[0/25][605/782] Loss_D: 0.8671 Loss_G: 5.5278\n",
            "[0/25][606/782] Loss_D: 0.5484 Loss_G: 2.9810\n",
            "[0/25][607/782] Loss_D: 1.1957 Loss_G: 5.3408\n",
            "[0/25][608/782] Loss_D: 0.4373 Loss_G: 5.1191\n",
            "[0/25][609/782] Loss_D: 0.4978 Loss_G: 3.3404\n",
            "[0/25][610/782] Loss_D: 1.1210 Loss_G: 4.9774\n",
            "[0/25][611/782] Loss_D: 0.9599 Loss_G: 2.8070\n",
            "[0/25][612/782] Loss_D: 0.7413 Loss_G: 3.1354\n",
            "[0/25][613/782] Loss_D: 0.9114 Loss_G: 4.5018\n",
            "[0/25][614/782] Loss_D: 0.4861 Loss_G: 3.7335\n",
            "[0/25][615/782] Loss_D: 0.4194 Loss_G: 4.3500\n",
            "[0/25][616/782] Loss_D: 0.4527 Loss_G: 4.0165\n",
            "[0/25][617/782] Loss_D: 0.6092 Loss_G: 2.0292\n",
            "[0/25][618/782] Loss_D: 1.2770 Loss_G: 7.2154\n",
            "[0/25][619/782] Loss_D: 2.1777 Loss_G: 1.9436\n",
            "[0/25][620/782] Loss_D: 1.1803 Loss_G: 4.4562\n",
            "[0/25][621/782] Loss_D: 0.5712 Loss_G: 3.6773\n",
            "[0/25][622/782] Loss_D: 0.4946 Loss_G: 4.1816\n",
            "[0/25][623/782] Loss_D: 0.4377 Loss_G: 3.5079\n",
            "[0/25][624/782] Loss_D: 0.4939 Loss_G: 4.3044\n",
            "[0/25][625/782] Loss_D: 0.6204 Loss_G: 2.9341\n",
            "[0/25][626/782] Loss_D: 0.5624 Loss_G: 3.1940\n",
            "[0/25][627/782] Loss_D: 0.7187 Loss_G: 3.5440\n",
            "[0/25][628/782] Loss_D: 0.6756 Loss_G: 3.9915\n",
            "[0/25][629/782] Loss_D: 0.3517 Loss_G: 3.5447\n",
            "[0/25][630/782] Loss_D: 0.6437 Loss_G: 1.8889\n",
            "[0/25][631/782] Loss_D: 0.7767 Loss_G: 5.8262\n",
            "[0/25][632/782] Loss_D: 0.4165 Loss_G: 5.8836\n",
            "[0/25][633/782] Loss_D: 0.1985 Loss_G: 3.4260\n",
            "[0/25][634/782] Loss_D: 0.4552 Loss_G: 4.5808\n",
            "[0/25][635/782] Loss_D: 0.5072 Loss_G: 3.0482\n",
            "[0/25][636/782] Loss_D: 0.7977 Loss_G: 4.1861\n",
            "[0/25][637/782] Loss_D: 0.9021 Loss_G: 2.5486\n",
            "[0/25][638/782] Loss_D: 0.7266 Loss_G: 2.9520\n",
            "[0/25][639/782] Loss_D: 0.5730 Loss_G: 3.0473\n",
            "[0/25][640/782] Loss_D: 0.5521 Loss_G: 3.3858\n",
            "[0/25][641/782] Loss_D: 0.8593 Loss_G: 4.4814\n",
            "[0/25][642/782] Loss_D: 1.3063 Loss_G: 0.9422\n",
            "[0/25][643/782] Loss_D: 1.2808 Loss_G: 6.2929\n",
            "[0/25][644/782] Loss_D: 0.9065 Loss_G: 2.9678\n",
            "[0/25][645/782] Loss_D: 0.3147 Loss_G: 4.0067\n",
            "[0/25][646/782] Loss_D: 0.3039 Loss_G: 4.9357\n",
            "[0/25][647/782] Loss_D: 0.3280 Loss_G: 3.3012\n",
            "[0/25][648/782] Loss_D: 0.5747 Loss_G: 6.0100\n",
            "[0/25][649/782] Loss_D: 1.0123 Loss_G: 2.0336\n",
            "[0/25][650/782] Loss_D: 0.9094 Loss_G: 6.6971\n",
            "[0/25][651/782] Loss_D: 0.7338 Loss_G: 2.0203\n",
            "[0/25][652/782] Loss_D: 0.7711 Loss_G: 5.7022\n",
            "[0/25][653/782] Loss_D: 0.6770 Loss_G: 2.2634\n",
            "[0/25][654/782] Loss_D: 1.0109 Loss_G: 7.8786\n",
            "[0/25][655/782] Loss_D: 1.8048 Loss_G: 1.8380\n",
            "[0/25][656/782] Loss_D: 1.0556 Loss_G: 4.0705\n",
            "[0/25][657/782] Loss_D: 0.5459 Loss_G: 4.3522\n",
            "[0/25][658/782] Loss_D: 0.7407 Loss_G: 1.5989\n",
            "[0/25][659/782] Loss_D: 1.3028 Loss_G: 5.1056\n",
            "[0/25][660/782] Loss_D: 0.8781 Loss_G: 1.4951\n",
            "[0/25][661/782] Loss_D: 1.3076 Loss_G: 4.5534\n",
            "[0/25][662/782] Loss_D: 0.9664 Loss_G: 2.3794\n",
            "[0/25][663/782] Loss_D: 0.7473 Loss_G: 3.2701\n",
            "[0/25][664/782] Loss_D: 0.6739 Loss_G: 2.6780\n",
            "[0/25][665/782] Loss_D: 1.0581 Loss_G: 3.6406\n",
            "[0/25][666/782] Loss_D: 1.0514 Loss_G: 1.3419\n",
            "[0/25][667/782] Loss_D: 1.1643 Loss_G: 4.4273\n",
            "[0/25][668/782] Loss_D: 1.0205 Loss_G: 1.6871\n",
            "[0/25][669/782] Loss_D: 1.0264 Loss_G: 4.0339\n",
            "[0/25][670/782] Loss_D: 0.6310 Loss_G: 3.2979\n",
            "[0/25][671/782] Loss_D: 0.6406 Loss_G: 2.2898\n",
            "[0/25][672/782] Loss_D: 0.4865 Loss_G: 3.9474\n",
            "[0/25][673/782] Loss_D: 0.3797 Loss_G: 3.7494\n",
            "[0/25][674/782] Loss_D: 0.4355 Loss_G: 2.4695\n",
            "[0/25][675/782] Loss_D: 0.4340 Loss_G: 3.1434\n",
            "[0/25][676/782] Loss_D: 0.3792 Loss_G: 3.3153\n",
            "[0/25][677/782] Loss_D: 0.3812 Loss_G: 2.5016\n",
            "[0/25][678/782] Loss_D: 0.4372 Loss_G: 3.3654\n",
            "[0/25][679/782] Loss_D: 0.2280 Loss_G: 3.7509\n",
            "[0/25][680/782] Loss_D: 0.4438 Loss_G: 2.1565\n",
            "[0/25][681/782] Loss_D: 0.6370 Loss_G: 4.8446\n",
            "[0/25][682/782] Loss_D: 1.2201 Loss_G: 0.9809\n",
            "[0/25][683/782] Loss_D: 1.3672 Loss_G: 2.9981\n",
            "[0/25][684/782] Loss_D: 0.6108 Loss_G: 4.7951\n",
            "[0/25][685/782] Loss_D: 1.0633 Loss_G: 0.5710\n",
            "[0/25][686/782] Loss_D: 1.9152 Loss_G: 6.3391\n",
            "[0/25][687/782] Loss_D: 2.5440 Loss_G: 2.4039\n",
            "[0/25][688/782] Loss_D: 0.6538 Loss_G: 2.7025\n",
            "[0/25][689/782] Loss_D: 0.5596 Loss_G: 4.5426\n",
            "[0/25][690/782] Loss_D: 1.0914 Loss_G: 0.7080\n",
            "[0/25][691/782] Loss_D: 2.0054 Loss_G: 6.0413\n",
            "[0/25][692/782] Loss_D: 1.4883 Loss_G: 2.4641\n",
            "[0/25][693/782] Loss_D: 0.6959 Loss_G: 2.5909\n",
            "[0/25][694/782] Loss_D: 0.5983 Loss_G: 3.4975\n",
            "[0/25][695/782] Loss_D: 0.5330 Loss_G: 2.5950\n",
            "[0/25][696/782] Loss_D: 0.4222 Loss_G: 3.6685\n",
            "[0/25][697/782] Loss_D: 0.3315 Loss_G: 3.9953\n",
            "[0/25][698/782] Loss_D: 0.2951 Loss_G: 3.4841\n",
            "[0/25][699/782] Loss_D: 0.3067 Loss_G: 3.0689\n",
            "[0/25][700/782] Loss_D: 0.4222 Loss_G: 3.0431\n",
            "[0/25][701/782] Loss_D: 0.3896 Loss_G: 4.6054\n",
            "[0/25][702/782] Loss_D: 0.3467 Loss_G: 3.6871\n",
            "[0/25][703/782] Loss_D: 0.3394 Loss_G: 3.5550\n",
            "[0/25][704/782] Loss_D: 0.3801 Loss_G: 4.2384\n",
            "[0/25][705/782] Loss_D: 0.2921 Loss_G: 3.7616\n",
            "[0/25][706/782] Loss_D: 0.5932 Loss_G: 3.5592\n",
            "[0/25][707/782] Loss_D: 0.3136 Loss_G: 4.3347\n",
            "[0/25][708/782] Loss_D: 0.5571 Loss_G: 3.1816\n",
            "[0/25][709/782] Loss_D: 0.3478 Loss_G: 5.6435\n",
            "[0/25][710/782] Loss_D: 0.1509 Loss_G: 5.3291\n",
            "[0/25][711/782] Loss_D: 0.2450 Loss_G: 4.0425\n",
            "[0/25][712/782] Loss_D: 0.3336 Loss_G: 4.4771\n",
            "[0/25][713/782] Loss_D: 0.2669 Loss_G: 5.2533\n",
            "[0/25][714/782] Loss_D: 0.2420 Loss_G: 4.4562\n",
            "[0/25][715/782] Loss_D: 0.3871 Loss_G: 3.4657\n",
            "[0/25][716/782] Loss_D: 0.4640 Loss_G: 6.2681\n",
            "[0/25][717/782] Loss_D: 0.2900 Loss_G: 4.6802\n",
            "[0/25][718/782] Loss_D: 0.4952 Loss_G: 6.5133\n",
            "[0/25][719/782] Loss_D: 0.2942 Loss_G: 3.1333\n",
            "[0/25][720/782] Loss_D: 0.8110 Loss_G: 8.1716\n",
            "[0/25][721/782] Loss_D: 0.8111 Loss_G: 2.6473\n",
            "[0/25][722/782] Loss_D: 1.2708 Loss_G: 10.3369\n",
            "[0/25][723/782] Loss_D: 1.1590 Loss_G: 4.7962\n",
            "[0/25][724/782] Loss_D: 0.6948 Loss_G: 5.4330\n",
            "[0/25][725/782] Loss_D: 0.4068 Loss_G: 6.9214\n",
            "[0/25][726/782] Loss_D: 0.6535 Loss_G: 4.5864\n",
            "[0/25][727/782] Loss_D: 0.6683 Loss_G: 7.0317\n",
            "[0/25][728/782] Loss_D: 1.0831 Loss_G: 3.2329\n",
            "[0/25][729/782] Loss_D: 1.5937 Loss_G: 11.4115\n",
            "[0/25][730/782] Loss_D: 2.1581 Loss_G: 5.5524\n",
            "[0/25][731/782] Loss_D: 0.5915 Loss_G: 2.3788\n",
            "[0/25][732/782] Loss_D: 1.8387 Loss_G: 7.6483\n",
            "[0/25][733/782] Loss_D: 1.0204 Loss_G: 4.3759\n",
            "[0/25][734/782] Loss_D: 0.6031 Loss_G: 3.1840\n",
            "[0/25][735/782] Loss_D: 0.9845 Loss_G: 5.7117\n",
            "[0/25][736/782] Loss_D: 1.2056 Loss_G: 1.3010\n",
            "[0/25][737/782] Loss_D: 1.4595 Loss_G: 6.9997\n",
            "[0/25][738/782] Loss_D: 0.5663 Loss_G: 5.6361\n",
            "[0/25][739/782] Loss_D: 0.1564 Loss_G: 4.2823\n",
            "[0/25][740/782] Loss_D: 0.6014 Loss_G: 5.5722\n",
            "[0/25][741/782] Loss_D: 0.4304 Loss_G: 4.2480\n",
            "[0/25][742/782] Loss_D: 0.3594 Loss_G: 4.0111\n",
            "[0/25][743/782] Loss_D: 0.6541 Loss_G: 3.5804\n",
            "[0/25][744/782] Loss_D: 0.3714 Loss_G: 4.0495\n",
            "[0/25][745/782] Loss_D: 1.0773 Loss_G: 1.2246\n",
            "[0/25][746/782] Loss_D: 1.2841 Loss_G: 6.7552\n",
            "[0/25][747/782] Loss_D: 0.8090 Loss_G: 4.5654\n",
            "[0/25][748/782] Loss_D: 0.2882 Loss_G: 3.1941\n",
            "[0/25][749/782] Loss_D: 0.2781 Loss_G: 4.0968\n",
            "[0/25][750/782] Loss_D: 0.3889 Loss_G: 3.7880\n",
            "[0/25][751/782] Loss_D: 0.3599 Loss_G: 3.9498\n",
            "[0/25][752/782] Loss_D: 0.5209 Loss_G: 3.5148\n",
            "[0/25][753/782] Loss_D: 0.7043 Loss_G: 3.0089\n",
            "[0/25][754/782] Loss_D: 0.5646 Loss_G: 3.9611\n",
            "[0/25][755/782] Loss_D: 0.2805 Loss_G: 4.0564\n",
            "[0/25][756/782] Loss_D: 0.4973 Loss_G: 3.5486\n",
            "[0/25][757/782] Loss_D: 0.4103 Loss_G: 3.3421\n",
            "[0/25][758/782] Loss_D: 0.4677 Loss_G: 5.1830\n",
            "[0/25][759/782] Loss_D: 0.5611 Loss_G: 2.3059\n",
            "[0/25][760/782] Loss_D: 0.9069 Loss_G: 7.3179\n",
            "[0/25][761/782] Loss_D: 1.5414 Loss_G: 1.9449\n",
            "[0/25][762/782] Loss_D: 1.2288 Loss_G: 6.5713\n",
            "[0/25][763/782] Loss_D: 1.2212 Loss_G: 2.0565\n",
            "[0/25][764/782] Loss_D: 0.7986 Loss_G: 5.4524\n",
            "[0/25][765/782] Loss_D: 0.8061 Loss_G: 3.1326\n",
            "[0/25][766/782] Loss_D: 0.5619 Loss_G: 4.4131\n",
            "[0/25][767/782] Loss_D: 0.3403 Loss_G: 3.6489\n",
            "[0/25][768/782] Loss_D: 0.4769 Loss_G: 3.8965\n",
            "[0/25][769/782] Loss_D: 0.5912 Loss_G: 2.6116\n",
            "[0/25][770/782] Loss_D: 0.8544 Loss_G: 5.3757\n",
            "[0/25][771/782] Loss_D: 0.6464 Loss_G: 3.3617\n",
            "[0/25][772/782] Loss_D: 0.5172 Loss_G: 2.9719\n",
            "[0/25][773/782] Loss_D: 0.4137 Loss_G: 3.9621\n",
            "[0/25][774/782] Loss_D: 0.5663 Loss_G: 3.4138\n",
            "[0/25][775/782] Loss_D: 0.2962 Loss_G: 4.5075\n",
            "[0/25][776/782] Loss_D: 0.2659 Loss_G: 4.0927\n",
            "[0/25][777/782] Loss_D: 0.4460 Loss_G: 2.4568\n",
            "[0/25][778/782] Loss_D: 0.6200 Loss_G: 5.2901\n",
            "[0/25][779/782] Loss_D: 0.3315 Loss_G: 4.0261\n",
            "[0/25][780/782] Loss_D: 0.3618 Loss_G: 3.2457\n",
            "[0/25][781/782] Loss_D: 0.4330 Loss_G: 4.8270\n",
            "[1/25][0/782] Loss_D: 0.4942 Loss_G: 2.7262\n",
            "[1/25][1/782] Loss_D: 0.4891 Loss_G: 5.4236\n",
            "[1/25][2/782] Loss_D: 0.7526 Loss_G: 2.3494\n",
            "[1/25][3/782] Loss_D: 0.6311 Loss_G: 6.1548\n",
            "[1/25][4/782] Loss_D: 0.5577 Loss_G: 2.7612\n",
            "[1/25][5/782] Loss_D: 0.6830 Loss_G: 6.2454\n",
            "[1/25][6/782] Loss_D: 1.0753 Loss_G: 2.0772\n",
            "[1/25][7/782] Loss_D: 0.8836 Loss_G: 7.6480\n",
            "[1/25][8/782] Loss_D: 1.1716 Loss_G: 2.7032\n",
            "[1/25][9/782] Loss_D: 0.7005 Loss_G: 4.9750\n",
            "[1/25][10/782] Loss_D: 0.2954 Loss_G: 5.0604\n",
            "[1/25][11/782] Loss_D: 0.6409 Loss_G: 2.6289\n",
            "[1/25][12/782] Loss_D: 0.8087 Loss_G: 6.5158\n",
            "[1/25][13/782] Loss_D: 0.3908 Loss_G: 5.2896\n",
            "[1/25][14/782] Loss_D: 0.3157 Loss_G: 3.8009\n",
            "[1/25][15/782] Loss_D: 0.4544 Loss_G: 5.2234\n",
            "[1/25][16/782] Loss_D: 0.5415 Loss_G: 2.5913\n",
            "[1/25][17/782] Loss_D: 1.1357 Loss_G: 7.2571\n",
            "[1/25][18/782] Loss_D: 1.3315 Loss_G: 2.9502\n",
            "[1/25][19/782] Loss_D: 0.6802 Loss_G: 3.2778\n",
            "[1/25][20/782] Loss_D: 0.5635 Loss_G: 5.3418\n",
            "[1/25][21/782] Loss_D: 0.6710 Loss_G: 2.6585\n",
            "[1/25][22/782] Loss_D: 0.6705 Loss_G: 5.2904\n",
            "[1/25][23/782] Loss_D: 0.3829 Loss_G: 3.9861\n",
            "[1/25][24/782] Loss_D: 0.4921 Loss_G: 3.0011\n",
            "[1/25][25/782] Loss_D: 0.4626 Loss_G: 4.6529\n",
            "[1/25][26/782] Loss_D: 0.5583 Loss_G: 3.8180\n",
            "[1/25][27/782] Loss_D: 0.4327 Loss_G: 3.2432\n",
            "[1/25][28/782] Loss_D: 0.6738 Loss_G: 5.3171\n",
            "[1/25][29/782] Loss_D: 0.8811 Loss_G: 1.4456\n",
            "[1/25][30/782] Loss_D: 1.1377 Loss_G: 7.9280\n",
            "[1/25][31/782] Loss_D: 1.8565 Loss_G: 1.3254\n",
            "[1/25][32/782] Loss_D: 1.5305 Loss_G: 8.3174\n",
            "[1/25][33/782] Loss_D: 2.5143 Loss_G: 1.4601\n",
            "[1/25][34/782] Loss_D: 1.6866 Loss_G: 4.8402\n",
            "[1/25][35/782] Loss_D: 0.6113 Loss_G: 3.6636\n",
            "[1/25][36/782] Loss_D: 0.6394 Loss_G: 4.3524\n",
            "[1/25][37/782] Loss_D: 0.9718 Loss_G: 2.4344\n",
            "[1/25][38/782] Loss_D: 1.0144 Loss_G: 4.1654\n",
            "[1/25][39/782] Loss_D: 0.5195 Loss_G: 3.3668\n",
            "[1/25][40/782] Loss_D: 0.8286 Loss_G: 3.4724\n",
            "[1/25][41/782] Loss_D: 0.6001 Loss_G: 4.8578\n",
            "[1/25][42/782] Loss_D: 0.6031 Loss_G: 2.9224\n",
            "[1/25][43/782] Loss_D: 0.8916 Loss_G: 4.1628\n",
            "[1/25][44/782] Loss_D: 0.2933 Loss_G: 4.3704\n",
            "[1/25][45/782] Loss_D: 0.3994 Loss_G: 2.9325\n",
            "[1/25][46/782] Loss_D: 0.6394 Loss_G: 4.4314\n",
            "[1/25][47/782] Loss_D: 0.4933 Loss_G: 2.9914\n",
            "[1/25][48/782] Loss_D: 0.3563 Loss_G: 3.3516\n",
            "[1/25][49/782] Loss_D: 0.3211 Loss_G: 4.5139\n",
            "[1/25][50/782] Loss_D: 0.3105 Loss_G: 4.1904\n",
            "[1/25][51/782] Loss_D: 0.6303 Loss_G: 2.1359\n",
            "[1/25][52/782] Loss_D: 1.2512 Loss_G: 5.7481\n",
            "[1/25][53/782] Loss_D: 1.0281 Loss_G: 1.6295\n",
            "[1/25][54/782] Loss_D: 1.2001 Loss_G: 6.1620\n",
            "[1/25][55/782] Loss_D: 1.3661 Loss_G: 1.5839\n",
            "[1/25][56/782] Loss_D: 1.0166 Loss_G: 6.7414\n",
            "[1/25][57/782] Loss_D: 1.4775 Loss_G: 2.3481\n",
            "[1/25][58/782] Loss_D: 0.7978 Loss_G: 5.1390\n",
            "[1/25][59/782] Loss_D: 0.5604 Loss_G: 3.1799\n",
            "[1/25][60/782] Loss_D: 0.4942 Loss_G: 4.1192\n",
            "[1/25][61/782] Loss_D: 0.6590 Loss_G: 4.1476\n",
            "[1/25][62/782] Loss_D: 0.8339 Loss_G: 2.3224\n",
            "[1/25][63/782] Loss_D: 1.1403 Loss_G: 4.4666\n",
            "[1/25][64/782] Loss_D: 0.6822 Loss_G: 3.1301\n",
            "[1/25][65/782] Loss_D: 0.6311 Loss_G: 2.3538\n",
            "[1/25][66/782] Loss_D: 0.8449 Loss_G: 4.6127\n",
            "[1/25][67/782] Loss_D: 0.8889 Loss_G: 2.5509\n",
            "[1/25][68/782] Loss_D: 0.3362 Loss_G: 3.6474\n",
            "[1/25][69/782] Loss_D: 0.5871 Loss_G: 4.0724\n",
            "[1/25][70/782] Loss_D: 0.2665 Loss_G: 4.6557\n",
            "[1/25][71/782] Loss_D: 0.4707 Loss_G: 3.1467\n",
            "[1/25][72/782] Loss_D: 0.8617 Loss_G: 4.1270\n",
            "[1/25][73/782] Loss_D: 0.7446 Loss_G: 2.1498\n",
            "[1/25][74/782] Loss_D: 0.8913 Loss_G: 5.5007\n",
            "[1/25][75/782] Loss_D: 0.7952 Loss_G: 0.9195\n",
            "[1/25][76/782] Loss_D: 1.7741 Loss_G: 6.6305\n",
            "[1/25][77/782] Loss_D: 1.6921 Loss_G: 1.3675\n",
            "[1/25][78/782] Loss_D: 1.1433 Loss_G: 3.4509\n",
            "[1/25][79/782] Loss_D: 0.5751 Loss_G: 4.0942\n",
            "[1/25][80/782] Loss_D: 1.2201 Loss_G: 1.3372\n",
            "[1/25][81/782] Loss_D: 1.6353 Loss_G: 4.0841\n",
            "[1/25][82/782] Loss_D: 1.2521 Loss_G: 2.1684\n",
            "[1/25][83/782] Loss_D: 1.0912 Loss_G: 3.7196\n",
            "[1/25][84/782] Loss_D: 0.6803 Loss_G: 3.1368\n",
            "[1/25][85/782] Loss_D: 0.7768 Loss_G: 2.2931\n",
            "[1/25][86/782] Loss_D: 0.9634 Loss_G: 3.1467\n",
            "[1/25][87/782] Loss_D: 0.9207 Loss_G: 2.3932\n",
            "[1/25][88/782] Loss_D: 0.5744 Loss_G: 4.0761\n",
            "[1/25][89/782] Loss_D: 0.6979 Loss_G: 2.3951\n",
            "[1/25][90/782] Loss_D: 0.7307 Loss_G: 3.5881\n",
            "[1/25][91/782] Loss_D: 0.5673 Loss_G: 2.6421\n",
            "[1/25][92/782] Loss_D: 0.5390 Loss_G: 3.4417\n",
            "[1/25][93/782] Loss_D: 0.5094 Loss_G: 3.0716\n",
            "[1/25][94/782] Loss_D: 0.5950 Loss_G: 3.0304\n",
            "[1/25][95/782] Loss_D: 0.4128 Loss_G: 3.9655\n",
            "[1/25][96/782] Loss_D: 0.7916 Loss_G: 2.0202\n",
            "[1/25][97/782] Loss_D: 0.6834 Loss_G: 3.5094\n",
            "[1/25][98/782] Loss_D: 0.4630 Loss_G: 3.0584\n",
            "[1/25][99/782] Loss_D: 0.4089 Loss_G: 3.7120\n",
            "[1/25][100/782] Loss_D: 0.5093 Loss_G: 2.9076\n",
            "[1/25][101/782] Loss_D: 0.3911 Loss_G: 3.0742\n",
            "[1/25][102/782] Loss_D: 0.5209 Loss_G: 3.5211\n",
            "[1/25][103/782] Loss_D: 0.5348 Loss_G: 2.6282\n",
            "[1/25][104/782] Loss_D: 0.5062 Loss_G: 3.1863\n",
            "[1/25][105/782] Loss_D: 0.3587 Loss_G: 3.7252\n",
            "[1/25][106/782] Loss_D: 0.4153 Loss_G: 2.8188\n",
            "[1/25][107/782] Loss_D: 0.3933 Loss_G: 3.2239\n",
            "[1/25][108/782] Loss_D: 0.4784 Loss_G: 2.6593\n",
            "[1/25][109/782] Loss_D: 0.3168 Loss_G: 3.4428\n",
            "[1/25][110/782] Loss_D: 0.3462 Loss_G: 4.1873\n",
            "[1/25][111/782] Loss_D: 0.4034 Loss_G: 3.1313\n",
            "[1/25][112/782] Loss_D: 0.3656 Loss_G: 2.9679\n",
            "[1/25][113/782] Loss_D: 0.3035 Loss_G: 3.9572\n",
            "[1/25][114/782] Loss_D: 0.2511 Loss_G: 3.5507\n",
            "[1/25][115/782] Loss_D: 0.3719 Loss_G: 2.9122\n",
            "[1/25][116/782] Loss_D: 0.4735 Loss_G: 3.3811\n",
            "[1/25][117/782] Loss_D: 0.2861 Loss_G: 4.0530\n",
            "[1/25][118/782] Loss_D: 0.3595 Loss_G: 3.2923\n",
            "[1/25][119/782] Loss_D: 0.2957 Loss_G: 3.3035\n",
            "[1/25][120/782] Loss_D: 0.5107 Loss_G: 4.6765\n",
            "[1/25][121/782] Loss_D: 0.5829 Loss_G: 1.8662\n",
            "[1/25][122/782] Loss_D: 0.8532 Loss_G: 6.0999\n",
            "[1/25][123/782] Loss_D: 0.9072 Loss_G: 2.2146\n",
            "[1/25][124/782] Loss_D: 0.9260 Loss_G: 6.5254\n",
            "[1/25][125/782] Loss_D: 1.2878 Loss_G: 1.8605\n",
            "[1/25][126/782] Loss_D: 0.8558 Loss_G: 5.6207\n",
            "[1/25][127/782] Loss_D: 1.0189 Loss_G: 2.1394\n",
            "[1/25][128/782] Loss_D: 0.8767 Loss_G: 4.7545\n",
            "[1/25][129/782] Loss_D: 0.6786 Loss_G: 2.6694\n",
            "[1/25][130/782] Loss_D: 0.4935 Loss_G: 3.3519\n",
            "[1/25][131/782] Loss_D: 0.4373 Loss_G: 3.7573\n",
            "[1/25][132/782] Loss_D: 0.3936 Loss_G: 3.0113\n",
            "[1/25][133/782] Loss_D: 0.4133 Loss_G: 2.6101\n",
            "[1/25][134/782] Loss_D: 0.4437 Loss_G: 4.1785\n",
            "[1/25][135/782] Loss_D: 0.5010 Loss_G: 2.6157\n",
            "[1/25][136/782] Loss_D: 0.5662 Loss_G: 3.8920\n",
            "[1/25][137/782] Loss_D: 0.6174 Loss_G: 2.3935\n",
            "[1/25][138/782] Loss_D: 0.4789 Loss_G: 3.6135\n",
            "[1/25][139/782] Loss_D: 0.4981 Loss_G: 3.5017\n",
            "[1/25][140/782] Loss_D: 0.3113 Loss_G: 3.4424\n",
            "[1/25][141/782] Loss_D: 0.3401 Loss_G: 3.1999\n",
            "[1/25][142/782] Loss_D: 0.4451 Loss_G: 4.1255\n",
            "[1/25][143/782] Loss_D: 0.4298 Loss_G: 3.1007\n",
            "[1/25][144/782] Loss_D: 0.3312 Loss_G: 3.7305\n",
            "[1/25][145/782] Loss_D: 0.4165 Loss_G: 3.5528\n",
            "[1/25][146/782] Loss_D: 0.3910 Loss_G: 3.4552\n",
            "[1/25][147/782] Loss_D: 0.3963 Loss_G: 3.2913\n",
            "[1/25][148/782] Loss_D: 0.3427 Loss_G: 3.0921\n",
            "[1/25][149/782] Loss_D: 0.2868 Loss_G: 4.1396\n",
            "[1/25][150/782] Loss_D: 0.4178 Loss_G: 2.6814\n",
            "[1/25][151/782] Loss_D: 0.5091 Loss_G: 5.5652\n",
            "[1/25][152/782] Loss_D: 0.3382 Loss_G: 4.0979\n",
            "[1/25][153/782] Loss_D: 0.4261 Loss_G: 2.2329\n",
            "[1/25][154/782] Loss_D: 0.7522 Loss_G: 5.5439\n",
            "[1/25][155/782] Loss_D: 1.5084 Loss_G: 0.5679\n",
            "[1/25][156/782] Loss_D: 2.6348 Loss_G: 8.7159\n",
            "[1/25][157/782] Loss_D: 1.7466 Loss_G: 2.1583\n",
            "[1/25][158/782] Loss_D: 0.8026 Loss_G: 2.3500\n",
            "[1/25][159/782] Loss_D: 0.5617 Loss_G: 5.0970\n",
            "[1/25][160/782] Loss_D: 0.4438 Loss_G: 3.7200\n",
            "[1/25][161/782] Loss_D: 0.4128 Loss_G: 2.2935\n",
            "[1/25][162/782] Loss_D: 0.9529 Loss_G: 5.0322\n",
            "[1/25][163/782] Loss_D: 1.4477 Loss_G: 1.0725\n",
            "[1/25][164/782] Loss_D: 1.5203 Loss_G: 5.6360\n",
            "[1/25][165/782] Loss_D: 0.9915 Loss_G: 3.5835\n",
            "[1/25][166/782] Loss_D: 0.6939 Loss_G: 1.8492\n",
            "[1/25][167/782] Loss_D: 0.6953 Loss_G: 4.1169\n",
            "[1/25][168/782] Loss_D: 0.5272 Loss_G: 3.6124\n",
            "[1/25][169/782] Loss_D: 1.0236 Loss_G: 1.5818\n",
            "[1/25][170/782] Loss_D: 1.0089 Loss_G: 4.2918\n",
            "[1/25][171/782] Loss_D: 0.8228 Loss_G: 2.2793\n",
            "[1/25][172/782] Loss_D: 0.4970 Loss_G: 3.1866\n",
            "[1/25][173/782] Loss_D: 0.6876 Loss_G: 5.0849\n",
            "[1/25][174/782] Loss_D: 0.7627 Loss_G: 3.0607\n",
            "[1/25][175/782] Loss_D: 0.3518 Loss_G: 2.9454\n",
            "[1/25][176/782] Loss_D: 0.4330 Loss_G: 4.2893\n",
            "[1/25][177/782] Loss_D: 0.4584 Loss_G: 2.8789\n",
            "[1/25][178/782] Loss_D: 0.4584 Loss_G: 3.8767\n",
            "[1/25][179/782] Loss_D: 0.4980 Loss_G: 2.6196\n",
            "[1/25][180/782] Loss_D: 0.5693 Loss_G: 2.6406\n",
            "[1/25][181/782] Loss_D: 0.4499 Loss_G: 3.9473\n",
            "[1/25][182/782] Loss_D: 0.5740 Loss_G: 2.8781\n",
            "[1/25][183/782] Loss_D: 0.3321 Loss_G: 3.1836\n",
            "[1/25][184/782] Loss_D: 0.3269 Loss_G: 3.6977\n",
            "[1/25][185/782] Loss_D: 0.2946 Loss_G: 3.5985\n",
            "[1/25][186/782] Loss_D: 0.4701 Loss_G: 2.5357\n",
            "[1/25][187/782] Loss_D: 0.5304 Loss_G: 4.1218\n",
            "[1/25][188/782] Loss_D: 0.4135 Loss_G: 3.3219\n",
            "[1/25][189/782] Loss_D: 0.3108 Loss_G: 2.9255\n",
            "[1/25][190/782] Loss_D: 0.4620 Loss_G: 3.5192\n",
            "[1/25][191/782] Loss_D: 0.3019 Loss_G: 3.3316\n",
            "[1/25][192/782] Loss_D: 0.4016 Loss_G: 3.5730\n",
            "[1/25][193/782] Loss_D: 0.3080 Loss_G: 3.3792\n",
            "[1/25][194/782] Loss_D: 0.3350 Loss_G: 3.3060\n",
            "[1/25][195/782] Loss_D: 0.3780 Loss_G: 4.0381\n",
            "[1/25][196/782] Loss_D: 0.4375 Loss_G: 2.7286\n",
            "[1/25][197/782] Loss_D: 0.5817 Loss_G: 3.5917\n",
            "[1/25][198/782] Loss_D: 0.4762 Loss_G: 2.8069\n",
            "[1/25][199/782] Loss_D: 0.4341 Loss_G: 3.9759\n",
            "[1/25][200/782] Loss_D: 0.3162 Loss_G: 3.2620\n",
            "[1/25][201/782] Loss_D: 0.3835 Loss_G: 3.1646\n",
            "[1/25][202/782] Loss_D: 0.6803 Loss_G: 3.9927\n",
            "[1/25][203/782] Loss_D: 0.3517 Loss_G: 3.8525\n",
            "[1/25][204/782] Loss_D: 0.3092 Loss_G: 3.6093\n",
            "[1/25][205/782] Loss_D: 0.4085 Loss_G: 4.7974\n",
            "[1/25][206/782] Loss_D: 1.0327 Loss_G: 0.6603\n",
            "[1/25][207/782] Loss_D: 1.3065 Loss_G: 8.4574\n",
            "[1/25][208/782] Loss_D: 0.4921 Loss_G: 7.1035\n",
            "[1/25][209/782] Loss_D: 0.2790 Loss_G: 3.8922\n",
            "[1/25][210/782] Loss_D: 0.4185 Loss_G: 4.8566\n",
            "[1/25][211/782] Loss_D: 0.4252 Loss_G: 5.8091\n",
            "[1/25][212/782] Loss_D: 0.8276 Loss_G: 1.9745\n",
            "[1/25][213/782] Loss_D: 1.4308 Loss_G: 7.5589\n",
            "[1/25][214/782] Loss_D: 2.1253 Loss_G: 1.6745\n",
            "[1/25][215/782] Loss_D: 1.0010 Loss_G: 3.7007\n",
            "[1/25][216/782] Loss_D: 0.5602 Loss_G: 4.6941\n",
            "[1/25][217/782] Loss_D: 0.8256 Loss_G: 2.5542\n",
            "[1/25][218/782] Loss_D: 1.0938 Loss_G: 5.7150\n",
            "[1/25][219/782] Loss_D: 1.3531 Loss_G: 1.3095\n",
            "[1/25][220/782] Loss_D: 1.1283 Loss_G: 5.9631\n",
            "[1/25][221/782] Loss_D: 0.3940 Loss_G: 5.3692\n",
            "[1/25][222/782] Loss_D: 1.1767 Loss_G: 1.3945\n",
            "[1/25][223/782] Loss_D: 1.0949 Loss_G: 5.9476\n",
            "[1/25][224/782] Loss_D: 0.3797 Loss_G: 5.4812\n",
            "[1/25][225/782] Loss_D: 0.3806 Loss_G: 3.8892\n",
            "[1/25][226/782] Loss_D: 0.5908 Loss_G: 3.2102\n",
            "[1/25][227/782] Loss_D: 0.8630 Loss_G: 5.3584\n",
            "[1/25][228/782] Loss_D: 0.3192 Loss_G: 4.5572\n",
            "[1/25][229/782] Loss_D: 0.5326 Loss_G: 2.3683\n",
            "[1/25][230/782] Loss_D: 1.6041 Loss_G: 7.5815\n",
            "[1/25][231/782] Loss_D: 1.7927 Loss_G: 2.9333\n",
            "[1/25][232/782] Loss_D: 2.1751 Loss_G: 4.0854\n",
            "[1/25][233/782] Loss_D: 1.1432 Loss_G: 2.9313\n",
            "[1/25][234/782] Loss_D: 0.5598 Loss_G: 3.7304\n",
            "[1/25][235/782] Loss_D: 0.7476 Loss_G: 3.9494\n",
            "[1/25][236/782] Loss_D: 0.7403 Loss_G: 3.6244\n",
            "[1/25][237/782] Loss_D: 0.4932 Loss_G: 3.2848\n",
            "[1/25][238/782] Loss_D: 0.8492 Loss_G: 2.4457\n",
            "[1/25][239/782] Loss_D: 0.9241 Loss_G: 5.1371\n",
            "[1/25][240/782] Loss_D: 1.6687 Loss_G: 1.0033\n",
            "[1/25][241/782] Loss_D: 1.4660 Loss_G: 5.5859\n",
            "[1/25][242/782] Loss_D: 0.6313 Loss_G: 4.3135\n",
            "[1/25][243/782] Loss_D: 0.5774 Loss_G: 2.3405\n",
            "[1/25][244/782] Loss_D: 0.9083 Loss_G: 5.3016\n",
            "[1/25][245/782] Loss_D: 0.7400 Loss_G: 3.5511\n",
            "[1/25][246/782] Loss_D: 0.7405 Loss_G: 2.4023\n",
            "[1/25][247/782] Loss_D: 1.3634 Loss_G: 3.9884\n",
            "[1/25][248/782] Loss_D: 1.2413 Loss_G: 2.6273\n",
            "[1/25][249/782] Loss_D: 1.0320 Loss_G: 3.5649\n",
            "[1/25][250/782] Loss_D: 0.9488 Loss_G: 3.4062\n",
            "[1/25][251/782] Loss_D: 0.9262 Loss_G: 3.9366\n",
            "[1/25][252/782] Loss_D: 0.5505 Loss_G: 2.8895\n",
            "[1/25][253/782] Loss_D: 1.0966 Loss_G: 4.2081\n",
            "[1/25][254/782] Loss_D: 0.6869 Loss_G: 3.3291\n",
            "[1/25][255/782] Loss_D: 1.1013 Loss_G: 3.5665\n",
            "[1/25][256/782] Loss_D: 0.9061 Loss_G: 2.8746\n",
            "[1/25][257/782] Loss_D: 0.8052 Loss_G: 3.5128\n",
            "[1/25][258/782] Loss_D: 0.6331 Loss_G: 4.5914\n",
            "[1/25][259/782] Loss_D: 0.6456 Loss_G: 2.5946\n",
            "[1/25][260/782] Loss_D: 1.3251 Loss_G: 6.4504\n",
            "[1/25][261/782] Loss_D: 0.8542 Loss_G: 2.6777\n",
            "[1/25][262/782] Loss_D: 1.0731 Loss_G: 5.0112\n",
            "[1/25][263/782] Loss_D: 0.6360 Loss_G: 2.4608\n",
            "[1/25][264/782] Loss_D: 1.0646 Loss_G: 5.4944\n",
            "[1/25][265/782] Loss_D: 1.1049 Loss_G: 1.9167\n",
            "[1/25][266/782] Loss_D: 1.0481 Loss_G: 5.0880\n",
            "[1/25][267/782] Loss_D: 0.7594 Loss_G: 2.4739\n",
            "[1/25][268/782] Loss_D: 0.4343 Loss_G: 3.7056\n",
            "[1/25][269/782] Loss_D: 0.4287 Loss_G: 3.9086\n",
            "[1/25][270/782] Loss_D: 0.4231 Loss_G: 2.6462\n",
            "[1/25][271/782] Loss_D: 0.4898 Loss_G: 3.7905\n",
            "[1/25][272/782] Loss_D: 0.4079 Loss_G: 3.8434\n",
            "[1/25][273/782] Loss_D: 0.6502 Loss_G: 1.7950\n",
            "[1/25][274/782] Loss_D: 1.2981 Loss_G: 4.5318\n",
            "[1/25][275/782] Loss_D: 0.8358 Loss_G: 2.4226\n",
            "[1/25][276/782] Loss_D: 0.5496 Loss_G: 2.4726\n",
            "[1/25][277/782] Loss_D: 0.5354 Loss_G: 4.3476\n",
            "[1/25][278/782] Loss_D: 0.8291 Loss_G: 1.7110\n",
            "[1/25][279/782] Loss_D: 0.6907 Loss_G: 4.3921\n",
            "[1/25][280/782] Loss_D: 0.4402 Loss_G: 3.4823\n",
            "[1/25][281/782] Loss_D: 0.5456 Loss_G: 1.6540\n",
            "[1/25][282/782] Loss_D: 1.0793 Loss_G: 5.6195\n",
            "[1/25][283/782] Loss_D: 0.6319 Loss_G: 3.4715\n",
            "[1/25][284/782] Loss_D: 0.4816 Loss_G: 1.8277\n",
            "[1/25][285/782] Loss_D: 0.6999 Loss_G: 5.6091\n",
            "[1/25][286/782] Loss_D: 0.7936 Loss_G: 2.2552\n",
            "[1/25][287/782] Loss_D: 0.4577 Loss_G: 2.9850\n",
            "[1/25][288/782] Loss_D: 0.3901 Loss_G: 4.1824\n",
            "[1/25][289/782] Loss_D: 0.5753 Loss_G: 2.9983\n",
            "[1/25][290/782] Loss_D: 0.4474 Loss_G: 3.5576\n",
            "[1/25][291/782] Loss_D: 0.7327 Loss_G: 2.3090\n",
            "[1/25][292/782] Loss_D: 0.6509 Loss_G: 3.3040\n",
            "[1/25][293/782] Loss_D: 0.3844 Loss_G: 3.6503\n",
            "[1/25][294/782] Loss_D: 0.3208 Loss_G: 3.3635\n",
            "[1/25][295/782] Loss_D: 0.5278 Loss_G: 2.3109\n",
            "[1/25][296/782] Loss_D: 0.7197 Loss_G: 4.3245\n",
            "[1/25][297/782] Loss_D: 0.5935 Loss_G: 2.4764\n",
            "[1/25][298/782] Loss_D: 0.5968 Loss_G: 2.9266\n",
            "[1/25][299/782] Loss_D: 0.5320 Loss_G: 3.6179\n",
            "[1/25][300/782] Loss_D: 0.4979 Loss_G: 2.6598\n",
            "[1/25][301/782] Loss_D: 0.7339 Loss_G: 4.2800\n",
            "[1/25][302/782] Loss_D: 0.5978 Loss_G: 2.7284\n",
            "[1/25][303/782] Loss_D: 0.4294 Loss_G: 2.7560\n",
            "[1/25][304/782] Loss_D: 0.5622 Loss_G: 4.9746\n",
            "[1/25][305/782] Loss_D: 0.5238 Loss_G: 2.6625\n",
            "[1/25][306/782] Loss_D: 0.5428 Loss_G: 4.8522\n",
            "[1/25][307/782] Loss_D: 0.6096 Loss_G: 1.6150\n",
            "[1/25][308/782] Loss_D: 0.9471 Loss_G: 5.3946\n",
            "[1/25][309/782] Loss_D: 0.6916 Loss_G: 1.9501\n",
            "[1/25][310/782] Loss_D: 0.6346 Loss_G: 5.2737\n",
            "[1/25][311/782] Loss_D: 0.8855 Loss_G: 1.6207\n",
            "[1/25][312/782] Loss_D: 0.9981 Loss_G: 5.6987\n",
            "[1/25][313/782] Loss_D: 0.8513 Loss_G: 2.2248\n",
            "[1/25][314/782] Loss_D: 0.5632 Loss_G: 4.1374\n",
            "[1/25][315/782] Loss_D: 0.3940 Loss_G: 3.9480\n",
            "[1/25][316/782] Loss_D: 0.4320 Loss_G: 2.8806\n",
            "[1/25][317/782] Loss_D: 0.5724 Loss_G: 4.5339\n",
            "[1/25][318/782] Loss_D: 0.6012 Loss_G: 2.0659\n",
            "[1/25][319/782] Loss_D: 0.8021 Loss_G: 4.6218\n",
            "[1/25][320/782] Loss_D: 0.3377 Loss_G: 3.8208\n",
            "[1/25][321/782] Loss_D: 0.4447 Loss_G: 2.5627\n",
            "[1/25][322/782] Loss_D: 0.5017 Loss_G: 4.3839\n",
            "[1/25][323/782] Loss_D: 0.3743 Loss_G: 3.9995\n",
            "[1/25][324/782] Loss_D: 0.4712 Loss_G: 2.4052\n",
            "[1/25][325/782] Loss_D: 0.6443 Loss_G: 3.6278\n",
            "[1/25][326/782] Loss_D: 0.3800 Loss_G: 4.6996\n",
            "[1/25][327/782] Loss_D: 0.6410 Loss_G: 2.1166\n",
            "[1/25][328/782] Loss_D: 0.9128 Loss_G: 5.6824\n",
            "[1/25][329/782] Loss_D: 1.0223 Loss_G: 2.2457\n",
            "[1/25][330/782] Loss_D: 0.6794 Loss_G: 5.2564\n",
            "[1/25][331/782] Loss_D: 0.4274 Loss_G: 3.3559\n",
            "[1/25][332/782] Loss_D: 0.7231 Loss_G: 5.8890\n",
            "[1/25][333/782] Loss_D: 0.6770 Loss_G: 3.2477\n",
            "[1/25][334/782] Loss_D: 0.7913 Loss_G: 4.9255\n",
            "[1/25][335/782] Loss_D: 0.6203 Loss_G: 2.3259\n",
            "[1/25][336/782] Loss_D: 0.9068 Loss_G: 6.5219\n",
            "[1/25][337/782] Loss_D: 0.7969 Loss_G: 3.6205\n",
            "[1/25][338/782] Loss_D: 0.4377 Loss_G: 3.7501\n",
            "[1/25][339/782] Loss_D: 0.5818 Loss_G: 6.3248\n",
            "[1/25][340/782] Loss_D: 0.8774 Loss_G: 2.3926\n",
            "[1/25][341/782] Loss_D: 1.5092 Loss_G: 6.4848\n",
            "[1/25][342/782] Loss_D: 1.1236 Loss_G: 3.7287\n",
            "[1/25][343/782] Loss_D: 0.7249 Loss_G: 3.3763\n",
            "[1/25][344/782] Loss_D: 0.6127 Loss_G: 4.0461\n",
            "[1/25][345/782] Loss_D: 0.4668 Loss_G: 3.1238\n",
            "[1/25][346/782] Loss_D: 0.3192 Loss_G: 3.5815\n",
            "[1/25][347/782] Loss_D: 0.3487 Loss_G: 3.3246\n",
            "[1/25][348/782] Loss_D: 0.5214 Loss_G: 2.5793\n",
            "[1/25][349/782] Loss_D: 0.5825 Loss_G: 4.2443\n",
            "[1/25][350/782] Loss_D: 0.5042 Loss_G: 3.0943\n",
            "[1/25][351/782] Loss_D: 0.6590 Loss_G: 4.5020\n",
            "[1/25][352/782] Loss_D: 0.4904 Loss_G: 2.4768\n",
            "[1/25][353/782] Loss_D: 0.6853 Loss_G: 5.1035\n",
            "[1/25][354/782] Loss_D: 0.8261 Loss_G: 2.4844\n",
            "[1/25][355/782] Loss_D: 0.5755 Loss_G: 6.2665\n",
            "[1/25][356/782] Loss_D: 1.0247 Loss_G: 1.9553\n",
            "[1/25][357/782] Loss_D: 0.9037 Loss_G: 6.0606\n",
            "[1/25][358/782] Loss_D: 0.3969 Loss_G: 4.3260\n",
            "[1/25][359/782] Loss_D: 0.3717 Loss_G: 2.4448\n",
            "[1/25][360/782] Loss_D: 0.7308 Loss_G: 5.0490\n",
            "[1/25][361/782] Loss_D: 0.3560 Loss_G: 4.2594\n",
            "[1/25][362/782] Loss_D: 0.2442 Loss_G: 3.7209\n",
            "[1/25][363/782] Loss_D: 0.4630 Loss_G: 4.9037\n",
            "[1/25][364/782] Loss_D: 1.0639 Loss_G: 0.7515\n",
            "[1/25][365/782] Loss_D: 2.0578 Loss_G: 8.5216\n",
            "[1/25][366/782] Loss_D: 2.5737 Loss_G: 3.5101\n",
            "[1/25][367/782] Loss_D: 0.4099 Loss_G: 3.2821\n",
            "[1/25][368/782] Loss_D: 0.5936 Loss_G: 5.3654\n",
            "[1/25][369/782] Loss_D: 1.1001 Loss_G: 1.2086\n",
            "[1/25][370/782] Loss_D: 0.9692 Loss_G: 4.8743\n",
            "[1/25][371/782] Loss_D: 0.4154 Loss_G: 4.1405\n",
            "[1/25][372/782] Loss_D: 0.5019 Loss_G: 2.5711\n",
            "[1/25][373/782] Loss_D: 0.6182 Loss_G: 4.1733\n",
            "[1/25][374/782] Loss_D: 0.6810 Loss_G: 3.0831\n",
            "[1/25][375/782] Loss_D: 0.6442 Loss_G: 2.2273\n",
            "[1/25][376/782] Loss_D: 0.8200 Loss_G: 3.8500\n",
            "[1/25][377/782] Loss_D: 0.3575 Loss_G: 4.1546\n",
            "[1/25][378/782] Loss_D: 0.4743 Loss_G: 2.6886\n",
            "[1/25][379/782] Loss_D: 0.5600 Loss_G: 3.6257\n",
            "[1/25][380/782] Loss_D: 0.2842 Loss_G: 3.8566\n",
            "[1/25][381/782] Loss_D: 0.3695 Loss_G: 3.4108\n",
            "[1/25][382/782] Loss_D: 0.5285 Loss_G: 3.8571\n",
            "[1/25][383/782] Loss_D: 0.3607 Loss_G: 3.4060\n",
            "[1/25][384/782] Loss_D: 0.3836 Loss_G: 4.9864\n",
            "[1/25][385/782] Loss_D: 0.8159 Loss_G: 1.7303\n",
            "[1/25][386/782] Loss_D: 0.4700 Loss_G: 4.1053\n",
            "[1/25][387/782] Loss_D: 0.3515 Loss_G: 3.9905\n",
            "[1/25][388/782] Loss_D: 0.3805 Loss_G: 3.2238\n",
            "[1/25][389/782] Loss_D: 0.3094 Loss_G: 4.0224\n",
            "[1/25][390/782] Loss_D: 0.4099 Loss_G: 3.7564\n",
            "[1/25][391/782] Loss_D: 0.3599 Loss_G: 3.5184\n",
            "[1/25][392/782] Loss_D: 0.4388 Loss_G: 3.6736\n",
            "[1/25][393/782] Loss_D: 0.6090 Loss_G: 1.8288\n",
            "[1/25][394/782] Loss_D: 0.9659 Loss_G: 5.3012\n",
            "[1/25][395/782] Loss_D: 1.1827 Loss_G: 1.4917\n",
            "[1/25][396/782] Loss_D: 1.4124 Loss_G: 5.4981\n",
            "[1/25][397/782] Loss_D: 0.7655 Loss_G: 3.5401\n",
            "[1/25][398/782] Loss_D: 0.4093 Loss_G: 2.5861\n",
            "[1/25][399/782] Loss_D: 0.6864 Loss_G: 4.1578\n",
            "[1/25][400/782] Loss_D: 0.6973 Loss_G: 2.5356\n",
            "[1/25][401/782] Loss_D: 0.8531 Loss_G: 4.9718\n",
            "[1/25][402/782] Loss_D: 0.9897 Loss_G: 2.0238\n",
            "[1/25][403/782] Loss_D: 0.9440 Loss_G: 5.6439\n",
            "[1/25][404/782] Loss_D: 1.4164 Loss_G: 1.3797\n",
            "[1/25][405/782] Loss_D: 1.3046 Loss_G: 7.1720\n",
            "[1/25][406/782] Loss_D: 1.2628 Loss_G: 2.6736\n",
            "[1/25][407/782] Loss_D: 0.7203 Loss_G: 3.4881\n",
            "[1/25][408/782] Loss_D: 0.5558 Loss_G: 3.9051\n",
            "[1/25][409/782] Loss_D: 0.3584 Loss_G: 3.5890\n",
            "[1/25][410/782] Loss_D: 0.4104 Loss_G: 4.0276\n",
            "[1/25][411/782] Loss_D: 0.4329 Loss_G: 3.8322\n",
            "[1/25][412/782] Loss_D: 0.5480 Loss_G: 2.7638\n",
            "[1/25][413/782] Loss_D: 0.5826 Loss_G: 4.5527\n",
            "[1/25][414/782] Loss_D: 0.5351 Loss_G: 3.0736\n",
            "[1/25][415/782] Loss_D: 0.6571 Loss_G: 4.4378\n",
            "[1/25][416/782] Loss_D: 0.9066 Loss_G: 1.9140\n",
            "[1/25][417/782] Loss_D: 0.9912 Loss_G: 5.7646\n",
            "[1/25][418/782] Loss_D: 1.6554 Loss_G: 1.9885\n",
            "[1/25][419/782] Loss_D: 0.9002 Loss_G: 4.3629\n",
            "[1/25][420/782] Loss_D: 0.5369 Loss_G: 3.5327\n",
            "[1/25][421/782] Loss_D: 0.5645 Loss_G: 2.5314\n",
            "[1/25][422/782] Loss_D: 0.4706 Loss_G: 4.2170\n",
            "[1/25][423/782] Loss_D: 0.4014 Loss_G: 3.7834\n",
            "[1/25][424/782] Loss_D: 0.3962 Loss_G: 3.1823\n",
            "[1/25][425/782] Loss_D: 0.4537 Loss_G: 3.6280\n",
            "[1/25][426/782] Loss_D: 0.3574 Loss_G: 3.3536\n",
            "[1/25][427/782] Loss_D: 0.3985 Loss_G: 3.0166\n",
            "[1/25][428/782] Loss_D: 0.5099 Loss_G: 4.1355\n",
            "[1/25][429/782] Loss_D: 0.4693 Loss_G: 3.4887\n",
            "[1/25][430/782] Loss_D: 0.5289 Loss_G: 2.4130\n",
            "[1/25][431/782] Loss_D: 0.5930 Loss_G: 4.6023\n",
            "[1/25][432/782] Loss_D: 0.4639 Loss_G: 3.1358\n",
            "[1/25][433/782] Loss_D: 0.4634 Loss_G: 3.7600\n",
            "[1/25][434/782] Loss_D: 0.5623 Loss_G: 4.0038\n",
            "[1/25][435/782] Loss_D: 0.4203 Loss_G: 2.6681\n",
            "[1/25][436/782] Loss_D: 1.0958 Loss_G: 7.0519\n",
            "[1/25][437/782] Loss_D: 1.7923 Loss_G: 2.0329\n",
            "[1/25][438/782] Loss_D: 0.8037 Loss_G: 5.4955\n",
            "[1/25][439/782] Loss_D: 0.4959 Loss_G: 3.4464\n",
            "[1/25][440/782] Loss_D: 0.5115 Loss_G: 4.1986\n",
            "[1/25][441/782] Loss_D: 0.4330 Loss_G: 3.8139\n",
            "[1/25][442/782] Loss_D: 0.5147 Loss_G: 3.0577\n",
            "[1/25][443/782] Loss_D: 0.2817 Loss_G: 3.9093\n",
            "[1/25][444/782] Loss_D: 0.3410 Loss_G: 3.6968\n",
            "[1/25][445/782] Loss_D: 0.3973 Loss_G: 3.8010\n",
            "[1/25][446/782] Loss_D: 0.4683 Loss_G: 2.9705\n",
            "[1/25][447/782] Loss_D: 0.4466 Loss_G: 4.0783\n",
            "[1/25][448/782] Loss_D: 0.5127 Loss_G: 3.7352\n",
            "[1/25][449/782] Loss_D: 0.5514 Loss_G: 2.4696\n",
            "[1/25][450/782] Loss_D: 0.6958 Loss_G: 4.2082\n",
            "[1/25][451/782] Loss_D: 0.6023 Loss_G: 2.1800\n",
            "[1/25][452/782] Loss_D: 0.7824 Loss_G: 4.4065\n",
            "[1/25][453/782] Loss_D: 0.5830 Loss_G: 2.0515\n",
            "[1/25][454/782] Loss_D: 0.6257 Loss_G: 5.6798\n",
            "[1/25][455/782] Loss_D: 0.5767 Loss_G: 3.1269\n",
            "[1/25][456/782] Loss_D: 0.4534 Loss_G: 2.8159\n",
            "[1/25][457/782] Loss_D: 0.4415 Loss_G: 4.8360\n",
            "[1/25][458/782] Loss_D: 0.3974 Loss_G: 3.9978\n",
            "[1/25][459/782] Loss_D: 0.4378 Loss_G: 2.4544\n",
            "[1/25][460/782] Loss_D: 0.6660 Loss_G: 5.1867\n",
            "[1/25][461/782] Loss_D: 0.8532 Loss_G: 1.7284\n",
            "[1/25][462/782] Loss_D: 0.7737 Loss_G: 5.7192\n",
            "[1/25][463/782] Loss_D: 0.9823 Loss_G: 1.8171\n",
            "[1/25][464/782] Loss_D: 0.6017 Loss_G: 4.1402\n",
            "[1/25][465/782] Loss_D: 0.3619 Loss_G: 4.2633\n",
            "[1/25][466/782] Loss_D: 0.3949 Loss_G: 3.8431\n",
            "[1/25][467/782] Loss_D: 0.9608 Loss_G: 2.3824\n",
            "[1/25][468/782] Loss_D: 0.6800 Loss_G: 5.9781\n",
            "[1/25][469/782] Loss_D: 0.6739 Loss_G: 2.8993\n",
            "[1/25][470/782] Loss_D: 0.9034 Loss_G: 5.4371\n",
            "[1/25][471/782] Loss_D: 1.2876 Loss_G: 1.2071\n",
            "[1/25][472/782] Loss_D: 0.8730 Loss_G: 6.1921\n",
            "[1/25][473/782] Loss_D: 0.3903 Loss_G: 5.1586\n",
            "[1/25][474/782] Loss_D: 0.2968 Loss_G: 2.9140\n",
            "[1/25][475/782] Loss_D: 0.5616 Loss_G: 5.4251\n",
            "[1/25][476/782] Loss_D: 0.4035 Loss_G: 3.5086\n",
            "[1/25][477/782] Loss_D: 0.5370 Loss_G: 3.4718\n",
            "[1/25][478/782] Loss_D: 0.7099 Loss_G: 4.4038\n",
            "[1/25][479/782] Loss_D: 0.8203 Loss_G: 1.4764\n",
            "[1/25][480/782] Loss_D: 1.3110 Loss_G: 7.1076\n",
            "[1/25][481/782] Loss_D: 2.0778 Loss_G: 2.7053\n",
            "[1/25][482/782] Loss_D: 0.4251 Loss_G: 3.3781\n",
            "[1/25][483/782] Loss_D: 0.8202 Loss_G: 5.4423\n",
            "[1/25][484/782] Loss_D: 1.2782 Loss_G: 1.0908\n",
            "[1/25][485/782] Loss_D: 1.4480 Loss_G: 5.6252\n",
            "[1/25][486/782] Loss_D: 0.7887 Loss_G: 2.5887\n",
            "[1/25][487/782] Loss_D: 0.5919 Loss_G: 5.1958\n",
            "[1/25][488/782] Loss_D: 0.5496 Loss_G: 2.6203\n",
            "[1/25][489/782] Loss_D: 0.7159 Loss_G: 4.8446\n",
            "[1/25][490/782] Loss_D: 0.5326 Loss_G: 2.6537\n",
            "[1/25][491/782] Loss_D: 0.5025 Loss_G: 2.1458\n",
            "[1/25][492/782] Loss_D: 0.7679 Loss_G: 6.1967\n",
            "[1/25][493/782] Loss_D: 1.0414 Loss_G: 1.5121\n",
            "[1/25][494/782] Loss_D: 0.9473 Loss_G: 4.6029\n",
            "[1/25][495/782] Loss_D: 0.5680 Loss_G: 3.3251\n",
            "[1/25][496/782] Loss_D: 0.3783 Loss_G: 3.2074\n",
            "[1/25][497/782] Loss_D: 0.4268 Loss_G: 3.9257\n",
            "[1/25][498/782] Loss_D: 0.4899 Loss_G: 2.8644\n",
            "[1/25][499/782] Loss_D: 0.5292 Loss_G: 3.8549\n",
            "[1/25][500/782] Loss_D: 0.5652 Loss_G: 2.4662\n",
            "[1/25][501/782] Loss_D: 0.5483 Loss_G: 3.1621\n",
            "[1/25][502/782] Loss_D: 0.4717 Loss_G: 4.9956\n",
            "[1/25][503/782] Loss_D: 0.7386 Loss_G: 2.0859\n",
            "[1/25][504/782] Loss_D: 0.6752 Loss_G: 4.8724\n",
            "[1/25][505/782] Loss_D: 0.5346 Loss_G: 2.7669\n",
            "[1/25][506/782] Loss_D: 0.5377 Loss_G: 3.9411\n",
            "[1/25][507/782] Loss_D: 0.5108 Loss_G: 3.0757\n",
            "[1/25][508/782] Loss_D: 0.4190 Loss_G: 3.1457\n",
            "[1/25][509/782] Loss_D: 0.4909 Loss_G: 4.7852\n",
            "[1/25][510/782] Loss_D: 0.5778 Loss_G: 1.9356\n",
            "[1/25][511/782] Loss_D: 0.7815 Loss_G: 6.6656\n",
            "[1/25][512/782] Loss_D: 0.9116 Loss_G: 1.8347\n",
            "[1/25][513/782] Loss_D: 0.9762 Loss_G: 6.5693\n",
            "[1/25][514/782] Loss_D: 1.0022 Loss_G: 2.9097\n",
            "[1/25][515/782] Loss_D: 0.3665 Loss_G: 3.3515\n",
            "[1/25][516/782] Loss_D: 0.4280 Loss_G: 4.7405\n",
            "[1/25][517/782] Loss_D: 0.5167 Loss_G: 2.7913\n",
            "[1/25][518/782] Loss_D: 0.6647 Loss_G: 3.4090\n",
            "[1/25][519/782] Loss_D: 0.5382 Loss_G: 4.0196\n",
            "[1/25][520/782] Loss_D: 0.3611 Loss_G: 4.1024\n",
            "[1/25][521/782] Loss_D: 0.6596 Loss_G: 2.2830\n",
            "[1/25][522/782] Loss_D: 0.8686 Loss_G: 5.8401\n",
            "[1/25][523/782] Loss_D: 1.0722 Loss_G: 1.4934\n",
            "[1/25][524/782] Loss_D: 1.2227 Loss_G: 6.3215\n",
            "[1/25][525/782] Loss_D: 1.2337 Loss_G: 1.5320\n",
            "[1/25][526/782] Loss_D: 1.0735 Loss_G: 6.0334\n",
            "[1/25][527/782] Loss_D: 0.8767 Loss_G: 2.5196\n",
            "[1/25][528/782] Loss_D: 0.8216 Loss_G: 4.5970\n",
            "[1/25][529/782] Loss_D: 0.4489 Loss_G: 4.6204\n",
            "[1/25][530/782] Loss_D: 1.0348 Loss_G: 1.0329\n",
            "[1/25][531/782] Loss_D: 1.4228 Loss_G: 5.9618\n",
            "[1/25][532/782] Loss_D: 1.0879 Loss_G: 3.2909\n",
            "[1/25][533/782] Loss_D: 0.5788 Loss_G: 2.7159\n",
            "[1/25][534/782] Loss_D: 0.5726 Loss_G: 4.4755\n",
            "[1/25][535/782] Loss_D: 0.6172 Loss_G: 2.8956\n",
            "[1/25][536/782] Loss_D: 0.3947 Loss_G: 3.3910\n",
            "[1/25][537/782] Loss_D: 0.5135 Loss_G: 4.7991\n",
            "[1/25][538/782] Loss_D: 0.6555 Loss_G: 2.3677\n",
            "[1/25][539/782] Loss_D: 0.6952 Loss_G: 4.0568\n",
            "[1/25][540/782] Loss_D: 0.5691 Loss_G: 3.4878\n",
            "[1/25][541/782] Loss_D: 0.4769 Loss_G: 3.0441\n",
            "[1/25][542/782] Loss_D: 0.5139 Loss_G: 2.8484\n",
            "[1/25][543/782] Loss_D: 0.6034 Loss_G: 4.0709\n",
            "[1/25][544/782] Loss_D: 0.5272 Loss_G: 2.8143\n",
            "[1/25][545/782] Loss_D: 0.4713 Loss_G: 4.1612\n",
            "[1/25][546/782] Loss_D: 0.5642 Loss_G: 2.9477\n",
            "[1/25][547/782] Loss_D: 0.4398 Loss_G: 3.6019\n",
            "[1/25][548/782] Loss_D: 0.6858 Loss_G: 3.7361\n",
            "[1/25][549/782] Loss_D: 0.5238 Loss_G: 3.2868\n",
            "[1/25][550/782] Loss_D: 0.8943 Loss_G: 4.9370\n",
            "[1/25][551/782] Loss_D: 0.6898 Loss_G: 2.4987\n",
            "[1/25][552/782] Loss_D: 0.8697 Loss_G: 5.7240\n",
            "[1/25][553/782] Loss_D: 0.7371 Loss_G: 3.2169\n",
            "[1/25][554/782] Loss_D: 0.3740 Loss_G: 3.4334\n",
            "[1/25][555/782] Loss_D: 0.3872 Loss_G: 5.2301\n",
            "[1/25][556/782] Loss_D: 0.4421 Loss_G: 3.4797\n",
            "[1/25][557/782] Loss_D: 0.3424 Loss_G: 3.2960\n",
            "[1/25][558/782] Loss_D: 0.5321 Loss_G: 3.3084\n",
            "[1/25][559/782] Loss_D: 0.6229 Loss_G: 4.9034\n",
            "[1/25][560/782] Loss_D: 0.4036 Loss_G: 3.1588\n",
            "[1/25][561/782] Loss_D: 0.4833 Loss_G: 3.3901\n",
            "[1/25][562/782] Loss_D: 0.4781 Loss_G: 3.8149\n",
            "[1/25][563/782] Loss_D: 0.4465 Loss_G: 2.7854\n",
            "[1/25][564/782] Loss_D: 1.0275 Loss_G: 3.0564\n",
            "[1/25][565/782] Loss_D: 0.4753 Loss_G: 2.7060\n",
            "[1/25][566/782] Loss_D: 0.5221 Loss_G: 4.8787\n",
            "[1/25][567/782] Loss_D: 0.7808 Loss_G: 1.5331\n",
            "[1/25][568/782] Loss_D: 0.7518 Loss_G: 5.2805\n",
            "[1/25][569/782] Loss_D: 0.9723 Loss_G: 1.7850\n",
            "[1/25][570/782] Loss_D: 0.6546 Loss_G: 4.2786\n",
            "[1/25][571/782] Loss_D: 0.6139 Loss_G: 2.6602\n",
            "[1/25][572/782] Loss_D: 0.5954 Loss_G: 3.4698\n",
            "[1/25][573/782] Loss_D: 0.4915 Loss_G: 3.8389\n",
            "[1/25][574/782] Loss_D: 0.5479 Loss_G: 2.9015\n",
            "[1/25][575/782] Loss_D: 0.4919 Loss_G: 3.1199\n",
            "[1/25][576/782] Loss_D: 0.6230 Loss_G: 4.4816\n",
            "[1/25][577/782] Loss_D: 0.4574 Loss_G: 2.1802\n",
            "[1/25][578/782] Loss_D: 0.8778 Loss_G: 5.8937\n",
            "[1/25][579/782] Loss_D: 0.9765 Loss_G: 0.7474\n",
            "[1/25][580/782] Loss_D: 1.7341 Loss_G: 8.3359\n",
            "[1/25][581/782] Loss_D: 1.7753 Loss_G: 1.2628\n",
            "[1/25][582/782] Loss_D: 1.4793 Loss_G: 6.6962\n",
            "[1/25][583/782] Loss_D: 2.4352 Loss_G: 1.7702\n",
            "[1/25][584/782] Loss_D: 0.9787 Loss_G: 3.1448\n",
            "[1/25][585/782] Loss_D: 0.6901 Loss_G: 4.0417\n",
            "[1/25][586/782] Loss_D: 1.0334 Loss_G: 1.5386\n",
            "[1/25][587/782] Loss_D: 2.0513 Loss_G: 7.0709\n",
            "[1/25][588/782] Loss_D: 2.2153 Loss_G: 2.2145\n",
            "[1/25][589/782] Loss_D: 1.8018 Loss_G: 2.5665\n",
            "[1/25][590/782] Loss_D: 1.1097 Loss_G: 3.9308\n",
            "[1/25][591/782] Loss_D: 1.3212 Loss_G: 1.5682\n",
            "[1/25][592/782] Loss_D: 1.7197 Loss_G: 5.0414\n",
            "[1/25][593/782] Loss_D: 0.8920 Loss_G: 2.8026\n",
            "[1/25][594/782] Loss_D: 0.8184 Loss_G: 3.3601\n",
            "[1/25][595/782] Loss_D: 0.6778 Loss_G: 3.0123\n",
            "[1/25][596/782] Loss_D: 0.7557 Loss_G: 3.6305\n",
            "[1/25][597/782] Loss_D: 0.7505 Loss_G: 2.6893\n",
            "[1/25][598/782] Loss_D: 0.8838 Loss_G: 3.4735\n",
            "[1/25][599/782] Loss_D: 0.8317 Loss_G: 2.0454\n",
            "[1/25][600/782] Loss_D: 0.7590 Loss_G: 4.6243\n",
            "[1/25][601/782] Loss_D: 0.6180 Loss_G: 2.8967\n",
            "[1/25][602/782] Loss_D: 0.7839 Loss_G: 1.8962\n",
            "[1/25][603/782] Loss_D: 1.1312 Loss_G: 4.9670\n",
            "[1/25][604/782] Loss_D: 1.0934 Loss_G: 2.5509\n",
            "[1/25][605/782] Loss_D: 0.6232 Loss_G: 2.1745\n",
            "[1/25][606/782] Loss_D: 0.8554 Loss_G: 4.3943\n",
            "[1/25][607/782] Loss_D: 0.5866 Loss_G: 3.3203\n",
            "[1/25][608/782] Loss_D: 0.6035 Loss_G: 1.9465\n",
            "[1/25][609/782] Loss_D: 0.7496 Loss_G: 3.3876\n",
            "[1/25][610/782] Loss_D: 0.4509 Loss_G: 3.4137\n",
            "[1/25][611/782] Loss_D: 0.2910 Loss_G: 3.3094\n",
            "[1/25][612/782] Loss_D: 0.8021 Loss_G: 1.5858\n",
            "[1/25][613/782] Loss_D: 1.1896 Loss_G: 5.0202\n",
            "[1/25][614/782] Loss_D: 1.2511 Loss_G: 1.7482\n",
            "[1/25][615/782] Loss_D: 0.9839 Loss_G: 3.9550\n",
            "[1/25][616/782] Loss_D: 0.5158 Loss_G: 2.9391\n",
            "[1/25][617/782] Loss_D: 0.9838 Loss_G: 1.7463\n",
            "[1/25][618/782] Loss_D: 0.8069 Loss_G: 4.2970\n",
            "[1/25][619/782] Loss_D: 0.7167 Loss_G: 2.4007\n",
            "[1/25][620/782] Loss_D: 0.4185 Loss_G: 2.6419\n",
            "[1/25][621/782] Loss_D: 0.7944 Loss_G: 3.7218\n",
            "[1/25][622/782] Loss_D: 0.6588 Loss_G: 2.4619\n",
            "[1/25][623/782] Loss_D: 0.5398 Loss_G: 2.1406\n",
            "[1/25][624/782] Loss_D: 0.6541 Loss_G: 4.9276\n",
            "[1/25][625/782] Loss_D: 0.6762 Loss_G: 2.2938\n",
            "[1/25][626/782] Loss_D: 0.5239 Loss_G: 3.4069\n",
            "[1/25][627/782] Loss_D: 0.3888 Loss_G: 3.5003\n",
            "[1/25][628/782] Loss_D: 0.7084 Loss_G: 2.1765\n",
            "[1/25][629/782] Loss_D: 0.6189 Loss_G: 4.6892\n",
            "[1/25][630/782] Loss_D: 0.5997 Loss_G: 2.7313\n",
            "[1/25][631/782] Loss_D: 0.4998 Loss_G: 3.1198\n",
            "[1/25][632/782] Loss_D: 0.6060 Loss_G: 3.7127\n",
            "[1/25][633/782] Loss_D: 0.4282 Loss_G: 2.8588\n",
            "[1/25][634/782] Loss_D: 0.5408 Loss_G: 3.7890\n",
            "[1/25][635/782] Loss_D: 0.5774 Loss_G: 2.6720\n",
            "[1/25][636/782] Loss_D: 0.3818 Loss_G: 3.0670\n",
            "[1/25][637/782] Loss_D: 0.7158 Loss_G: 4.9541\n",
            "[1/25][638/782] Loss_D: 0.6752 Loss_G: 2.0272\n",
            "[1/25][639/782] Loss_D: 0.6791 Loss_G: 3.9987\n",
            "[1/25][640/782] Loss_D: 0.5793 Loss_G: 2.8890\n",
            "[1/25][641/782] Loss_D: 0.5154 Loss_G: 2.7301\n",
            "[1/25][642/782] Loss_D: 0.7798 Loss_G: 4.1692\n",
            "[1/25][643/782] Loss_D: 0.6550 Loss_G: 2.1059\n",
            "[1/25][644/782] Loss_D: 0.5043 Loss_G: 3.1948\n",
            "[1/25][645/782] Loss_D: 0.6977 Loss_G: 4.5178\n",
            "[1/25][646/782] Loss_D: 0.6569 Loss_G: 2.2254\n",
            "[1/25][647/782] Loss_D: 0.6006 Loss_G: 3.7985\n",
            "[1/25][648/782] Loss_D: 0.5654 Loss_G: 3.3792\n",
            "[1/25][649/782] Loss_D: 0.5096 Loss_G: 3.3346\n",
            "[1/25][650/782] Loss_D: 0.4561 Loss_G: 2.9706\n",
            "[1/25][651/782] Loss_D: 0.5305 Loss_G: 2.7397\n",
            "[1/25][652/782] Loss_D: 0.6582 Loss_G: 4.1892\n",
            "[1/25][653/782] Loss_D: 0.4587 Loss_G: 3.3006\n",
            "[1/25][654/782] Loss_D: 0.4606 Loss_G: 2.4865\n",
            "[1/25][655/782] Loss_D: 0.4749 Loss_G: 4.0870\n",
            "[1/25][656/782] Loss_D: 0.3343 Loss_G: 3.4733\n",
            "[1/25][657/782] Loss_D: 0.3987 Loss_G: 2.6355\n",
            "[1/25][658/782] Loss_D: 0.7081 Loss_G: 4.7683\n",
            "[1/25][659/782] Loss_D: 0.5587 Loss_G: 2.5959\n",
            "[1/25][660/782] Loss_D: 0.4285 Loss_G: 3.9115\n",
            "[1/25][661/782] Loss_D: 0.4425 Loss_G: 4.0229\n",
            "[1/25][662/782] Loss_D: 0.7330 Loss_G: 1.8466\n",
            "[1/25][663/782] Loss_D: 0.8983 Loss_G: 4.7749\n",
            "[1/25][664/782] Loss_D: 0.9220 Loss_G: 2.2197\n",
            "[1/25][665/782] Loss_D: 0.8591 Loss_G: 2.8400\n",
            "[1/25][666/782] Loss_D: 0.4166 Loss_G: 3.9386\n",
            "[1/25][667/782] Loss_D: 0.4725 Loss_G: 3.2059\n",
            "[1/25][668/782] Loss_D: 0.5897 Loss_G: 2.4623\n",
            "[1/25][669/782] Loss_D: 0.6181 Loss_G: 4.3972\n",
            "[1/25][670/782] Loss_D: 0.7481 Loss_G: 1.4119\n",
            "[1/25][671/782] Loss_D: 1.1478 Loss_G: 6.2612\n",
            "[1/25][672/782] Loss_D: 1.2186 Loss_G: 0.4751\n",
            "[1/25][673/782] Loss_D: 2.1025 Loss_G: 6.9515\n",
            "[1/25][674/782] Loss_D: 3.1402 Loss_G: 0.4813\n",
            "[1/25][675/782] Loss_D: 2.7397 Loss_G: 3.5764\n",
            "[1/25][676/782] Loss_D: 1.1264 Loss_G: 2.4653\n",
            "[1/25][677/782] Loss_D: 1.2175 Loss_G: 0.9269\n",
            "[1/25][678/782] Loss_D: 1.8091 Loss_G: 3.0863\n",
            "[1/25][679/782] Loss_D: 1.4827 Loss_G: 1.6491\n",
            "[1/25][680/782] Loss_D: 1.4535 Loss_G: 2.0860\n",
            "[1/25][681/782] Loss_D: 0.9681 Loss_G: 2.8636\n",
            "[1/25][682/782] Loss_D: 1.3400 Loss_G: 1.3416\n",
            "[1/25][683/782] Loss_D: 0.9304 Loss_G: 3.5281\n",
            "[1/25][684/782] Loss_D: 0.8889 Loss_G: 3.9682\n",
            "[1/25][685/782] Loss_D: 0.9339 Loss_G: 1.6061\n",
            "[1/25][686/782] Loss_D: 1.6228 Loss_G: 4.1302\n",
            "[1/25][687/782] Loss_D: 0.9698 Loss_G: 1.1060\n",
            "[1/25][688/782] Loss_D: 1.5907 Loss_G: 5.5772\n",
            "[1/25][689/782] Loss_D: 1.3716 Loss_G: 2.2872\n",
            "[1/25][690/782] Loss_D: 1.1685 Loss_G: 4.3444\n",
            "[1/25][691/782] Loss_D: 0.8810 Loss_G: 2.4782\n",
            "[1/25][692/782] Loss_D: 0.8166 Loss_G: 3.7863\n",
            "[1/25][693/782] Loss_D: 0.9072 Loss_G: 3.1655\n",
            "[1/25][694/782] Loss_D: 0.8400 Loss_G: 2.9247\n",
            "[1/25][695/782] Loss_D: 0.8670 Loss_G: 2.7974\n",
            "[1/25][696/782] Loss_D: 1.2523 Loss_G: 4.8323\n",
            "[1/25][697/782] Loss_D: 0.6236 Loss_G: 3.4755\n",
            "[1/25][698/782] Loss_D: 0.7388 Loss_G: 3.3071\n",
            "[1/25][699/782] Loss_D: 0.4975 Loss_G: 3.7943\n",
            "[1/25][700/782] Loss_D: 0.5652 Loss_G: 3.2243\n",
            "[1/25][701/782] Loss_D: 0.8447 Loss_G: 3.7470\n",
            "[1/25][702/782] Loss_D: 0.9779 Loss_G: 2.4442\n",
            "[1/25][703/782] Loss_D: 0.7188 Loss_G: 4.0450\n",
            "[1/25][704/782] Loss_D: 0.5494 Loss_G: 3.0579\n",
            "[1/25][705/782] Loss_D: 0.4406 Loss_G: 3.8377\n",
            "[1/25][706/782] Loss_D: 0.4492 Loss_G: 3.7944\n",
            "[1/25][707/782] Loss_D: 0.5611 Loss_G: 3.0728\n",
            "[1/25][708/782] Loss_D: 0.5158 Loss_G: 3.3146\n",
            "[1/25][709/782] Loss_D: 0.3621 Loss_G: 3.7220\n",
            "[1/25][710/782] Loss_D: 0.5615 Loss_G: 2.7657\n",
            "[1/25][711/782] Loss_D: 0.6157 Loss_G: 3.9630\n",
            "[1/25][712/782] Loss_D: 0.6216 Loss_G: 2.1190\n",
            "[1/25][713/782] Loss_D: 0.8243 Loss_G: 3.7827\n",
            "[1/25][714/782] Loss_D: 0.4371 Loss_G: 2.7698\n",
            "[1/25][715/782] Loss_D: 0.5703 Loss_G: 4.5955\n",
            "[1/25][716/782] Loss_D: 0.3884 Loss_G: 3.7626\n",
            "[1/25][717/782] Loss_D: 0.4340 Loss_G: 2.0165\n",
            "[1/25][718/782] Loss_D: 0.4992 Loss_G: 3.7950\n",
            "[1/25][719/782] Loss_D: 0.4183 Loss_G: 3.4391\n",
            "[1/25][720/782] Loss_D: 0.2906 Loss_G: 3.6897\n",
            "[1/25][721/782] Loss_D: 0.4335 Loss_G: 3.0709\n",
            "[1/25][722/782] Loss_D: 0.4551 Loss_G: 3.3393\n",
            "[1/25][723/782] Loss_D: 0.6235 Loss_G: 2.0851\n",
            "[1/25][724/782] Loss_D: 0.6168 Loss_G: 4.2044\n",
            "[1/25][725/782] Loss_D: 0.4080 Loss_G: 2.5987\n",
            "[1/25][726/782] Loss_D: 0.5095 Loss_G: 4.4031\n",
            "[1/25][727/782] Loss_D: 0.8444 Loss_G: 1.3836\n",
            "[1/25][728/782] Loss_D: 0.8075 Loss_G: 3.1774\n",
            "[1/25][729/782] Loss_D: 0.6214 Loss_G: 2.4875\n",
            "[1/25][730/782] Loss_D: 0.8054 Loss_G: 3.8517\n",
            "[1/25][731/782] Loss_D: 0.6512 Loss_G: 2.2507\n",
            "[1/25][732/782] Loss_D: 0.6135 Loss_G: 3.6491\n",
            "[1/25][733/782] Loss_D: 0.5597 Loss_G: 2.3130\n",
            "[1/25][734/782] Loss_D: 0.4416 Loss_G: 3.4855\n",
            "[1/25][735/782] Loss_D: 0.4254 Loss_G: 2.7888\n",
            "[1/25][736/782] Loss_D: 0.4284 Loss_G: 3.4808\n",
            "[1/25][737/782] Loss_D: 0.5827 Loss_G: 3.7029\n",
            "[1/25][738/782] Loss_D: 0.5544 Loss_G: 2.1938\n",
            "[1/25][739/782] Loss_D: 0.6700 Loss_G: 5.5960\n",
            "[1/25][740/782] Loss_D: 0.7699 Loss_G: 2.8830\n",
            "[1/25][741/782] Loss_D: 0.3526 Loss_G: 3.1257\n",
            "[1/25][742/782] Loss_D: 0.3741 Loss_G: 4.4354\n",
            "[1/25][743/782] Loss_D: 0.7463 Loss_G: 1.9459\n",
            "[1/25][744/782] Loss_D: 0.7243 Loss_G: 4.6946\n",
            "[1/25][745/782] Loss_D: 0.3910 Loss_G: 2.9637\n",
            "[1/25][746/782] Loss_D: 0.5632 Loss_G: 4.1394\n",
            "[1/25][747/782] Loss_D: 0.4813 Loss_G: 2.9546\n",
            "[1/25][748/782] Loss_D: 0.4227 Loss_G: 3.4245\n",
            "[1/25][749/782] Loss_D: 0.4836 Loss_G: 3.4561\n",
            "[1/25][750/782] Loss_D: 0.3862 Loss_G: 3.0857\n",
            "[1/25][751/782] Loss_D: 0.4367 Loss_G: 3.0263\n",
            "[1/25][752/782] Loss_D: 0.5115 Loss_G: 4.2477\n",
            "[1/25][753/782] Loss_D: 0.4719 Loss_G: 2.4261\n",
            "[1/25][754/782] Loss_D: 0.7225 Loss_G: 5.0630\n",
            "[1/25][755/782] Loss_D: 0.7946 Loss_G: 1.4988\n",
            "[1/25][756/782] Loss_D: 1.0170 Loss_G: 5.9693\n",
            "[1/25][757/782] Loss_D: 0.7744 Loss_G: 2.5451\n",
            "[1/25][758/782] Loss_D: 0.7107 Loss_G: 3.1348\n",
            "[1/25][759/782] Loss_D: 0.4552 Loss_G: 4.2935\n",
            "[1/25][760/782] Loss_D: 0.5141 Loss_G: 3.0040\n",
            "[1/25][761/782] Loss_D: 0.6113 Loss_G: 2.9418\n",
            "[1/25][762/782] Loss_D: 0.4390 Loss_G: 5.0194\n",
            "[1/25][763/782] Loss_D: 0.5259 Loss_G: 2.6102\n",
            "[1/25][764/782] Loss_D: 0.6884 Loss_G: 4.0733\n",
            "[1/25][765/782] Loss_D: 0.3529 Loss_G: 3.2256\n",
            "[1/25][766/782] Loss_D: 0.4960 Loss_G: 3.3632\n",
            "[1/25][767/782] Loss_D: 0.3801 Loss_G: 3.5146\n",
            "[1/25][768/782] Loss_D: 0.5505 Loss_G: 4.0360\n",
            "[1/25][769/782] Loss_D: 0.4168 Loss_G: 3.0041\n",
            "[1/25][770/782] Loss_D: 0.4907 Loss_G: 3.4422\n",
            "[1/25][771/782] Loss_D: 0.5677 Loss_G: 3.6238\n",
            "[1/25][772/782] Loss_D: 0.8325 Loss_G: 1.7558\n",
            "[1/25][773/782] Loss_D: 0.7212 Loss_G: 5.1389\n",
            "[1/25][774/782] Loss_D: 0.7080 Loss_G: 2.6753\n",
            "[1/25][775/782] Loss_D: 0.4718 Loss_G: 3.9718\n",
            "[1/25][776/782] Loss_D: 0.3853 Loss_G: 3.2082\n",
            "[1/25][777/782] Loss_D: 0.3730 Loss_G: 4.2870\n",
            "[1/25][778/782] Loss_D: 0.6601 Loss_G: 2.3344\n",
            "[1/25][779/782] Loss_D: 0.5918 Loss_G: 4.8476\n",
            "[1/25][780/782] Loss_D: 0.8081 Loss_G: 1.7055\n",
            "[1/25][781/782] Loss_D: 1.0189 Loss_G: 6.6750\n",
            "[2/25][0/782] Loss_D: 0.5921 Loss_G: 2.5052\n",
            "[2/25][1/782] Loss_D: 0.5425 Loss_G: 5.0271\n",
            "[2/25][2/782] Loss_D: 0.2378 Loss_G: 4.6864\n",
            "[2/25][3/782] Loss_D: 0.3247 Loss_G: 2.7797\n",
            "[2/25][4/782] Loss_D: 0.7912 Loss_G: 5.5467\n",
            "[2/25][5/782] Loss_D: 0.8879 Loss_G: 1.0656\n",
            "[2/25][6/782] Loss_D: 1.3325 Loss_G: 6.8494\n",
            "[2/25][7/782] Loss_D: 1.3774 Loss_G: 2.1622\n",
            "[2/25][8/782] Loss_D: 0.9190 Loss_G: 3.4752\n",
            "[2/25][9/782] Loss_D: 0.4641 Loss_G: 3.6961\n",
            "[2/25][10/782] Loss_D: 0.6003 Loss_G: 2.5370\n",
            "[2/25][11/782] Loss_D: 0.7040 Loss_G: 4.2602\n",
            "[2/25][12/782] Loss_D: 1.0028 Loss_G: 1.4149\n",
            "[2/25][13/782] Loss_D: 1.4677 Loss_G: 7.5739\n",
            "[2/25][14/782] Loss_D: 2.0737 Loss_G: 0.8030\n",
            "[2/25][15/782] Loss_D: 1.1754 Loss_G: 4.7556\n",
            "[2/25][16/782] Loss_D: 1.1253 Loss_G: 1.8330\n",
            "[2/25][17/782] Loss_D: 0.9961 Loss_G: 4.6132\n",
            "[2/25][18/782] Loss_D: 0.7556 Loss_G: 2.5064\n",
            "[2/25][19/782] Loss_D: 0.6293 Loss_G: 4.6307\n",
            "[2/25][20/782] Loss_D: 0.7066 Loss_G: 2.0830\n",
            "[2/25][21/782] Loss_D: 0.6861 Loss_G: 4.9769\n",
            "[2/25][22/782] Loss_D: 1.1688 Loss_G: 0.8518\n",
            "[2/25][23/782] Loss_D: 1.0128 Loss_G: 4.4107\n",
            "[2/25][24/782] Loss_D: 0.4148 Loss_G: 4.5358\n",
            "[2/25][25/782] Loss_D: 0.7009 Loss_G: 1.3820\n",
            "[2/25][26/782] Loss_D: 1.6735 Loss_G: 7.0486\n",
            "[2/25][27/782] Loss_D: 2.5139 Loss_G: 0.3237\n",
            "[2/25][28/782] Loss_D: 3.0609 Loss_G: 5.9236\n",
            "[2/25][29/782] Loss_D: 1.4377 Loss_G: 1.0321\n",
            "[2/25][30/782] Loss_D: 1.7060 Loss_G: 5.7649\n",
            "[2/25][31/782] Loss_D: 2.7136 Loss_G: 1.5471\n",
            "[2/25][32/782] Loss_D: 0.7727 Loss_G: 2.6006\n",
            "[2/25][33/782] Loss_D: 0.5489 Loss_G: 4.5306\n",
            "[2/25][34/782] Loss_D: 0.4038 Loss_G: 3.9583\n",
            "[2/25][35/782] Loss_D: 0.5817 Loss_G: 2.0407\n",
            "[2/25][36/782] Loss_D: 0.5919 Loss_G: 3.1534\n",
            "[2/25][37/782] Loss_D: 0.4610 Loss_G: 3.2026\n",
            "[2/25][38/782] Loss_D: 0.4837 Loss_G: 3.0173\n",
            "[2/25][39/782] Loss_D: 0.6758 Loss_G: 2.8553\n",
            "[2/25][40/782] Loss_D: 0.9644 Loss_G: 1.4820\n",
            "[2/25][41/782] Loss_D: 0.9267 Loss_G: 2.8492\n",
            "[2/25][42/782] Loss_D: 0.6212 Loss_G: 3.1161\n",
            "[2/25][43/782] Loss_D: 0.7917 Loss_G: 1.7465\n",
            "[2/25][44/782] Loss_D: 0.6104 Loss_G: 3.4663\n",
            "[2/25][45/782] Loss_D: 0.6013 Loss_G: 2.7055\n",
            "[2/25][46/782] Loss_D: 0.4589 Loss_G: 2.3658\n",
            "[2/25][47/782] Loss_D: 0.7445 Loss_G: 3.1272\n",
            "[2/25][48/782] Loss_D: 0.3724 Loss_G: 3.7004\n",
            "[2/25][49/782] Loss_D: 0.2309 Loss_G: 3.5666\n",
            "[2/25][50/782] Loss_D: 0.4202 Loss_G: 2.3439\n",
            "[2/25][51/782] Loss_D: 0.5921 Loss_G: 2.8231\n",
            "[2/25][52/782] Loss_D: 0.5244 Loss_G: 3.0548\n",
            "[2/25][53/782] Loss_D: 0.4984 Loss_G: 2.5093\n",
            "[2/25][54/782] Loss_D: 0.7239 Loss_G: 3.0613\n",
            "[2/25][55/782] Loss_D: 0.5459 Loss_G: 2.9464\n",
            "[2/25][56/782] Loss_D: 0.3899 Loss_G: 2.9757\n",
            "[2/25][57/782] Loss_D: 0.6013 Loss_G: 2.2828\n",
            "[2/25][58/782] Loss_D: 0.7714 Loss_G: 2.9703\n",
            "[2/25][59/782] Loss_D: 0.6227 Loss_G: 2.9563\n",
            "[2/25][60/782] Loss_D: 0.4473 Loss_G: 3.5247\n",
            "[2/25][61/782] Loss_D: 0.4669 Loss_G: 2.3530\n",
            "[2/25][62/782] Loss_D: 0.7675 Loss_G: 4.8195\n",
            "[2/25][63/782] Loss_D: 0.8279 Loss_G: 2.2494\n",
            "[2/25][64/782] Loss_D: 0.3912 Loss_G: 2.7129\n",
            "[2/25][65/782] Loss_D: 0.6861 Loss_G: 4.8333\n",
            "[2/25][66/782] Loss_D: 1.0308 Loss_G: 1.7041\n",
            "[2/25][67/782] Loss_D: 0.7851 Loss_G: 4.3656\n",
            "[2/25][68/782] Loss_D: 0.3348 Loss_G: 3.9049\n",
            "[2/25][69/782] Loss_D: 0.5400 Loss_G: 2.9452\n",
            "[2/25][70/782] Loss_D: 0.8759 Loss_G: 4.2402\n",
            "[2/25][71/782] Loss_D: 0.6156 Loss_G: 2.3923\n",
            "[2/25][72/782] Loss_D: 0.4266 Loss_G: 3.3550\n",
            "[2/25][73/782] Loss_D: 0.6596 Loss_G: 5.3590\n",
            "[2/25][74/782] Loss_D: 0.4705 Loss_G: 2.9055\n",
            "[2/25][75/782] Loss_D: 0.5183 Loss_G: 3.5595\n",
            "[2/25][76/782] Loss_D: 0.5117 Loss_G: 2.9728\n",
            "[2/25][77/782] Loss_D: 0.6346 Loss_G: 3.0860\n",
            "[2/25][78/782] Loss_D: 0.3200 Loss_G: 4.2803\n",
            "[2/25][79/782] Loss_D: 0.3031 Loss_G: 3.8194\n",
            "[2/25][80/782] Loss_D: 0.4918 Loss_G: 2.0847\n",
            "[2/25][81/782] Loss_D: 0.4812 Loss_G: 4.1396\n",
            "[2/25][82/782] Loss_D: 0.3526 Loss_G: 3.2941\n",
            "[2/25][83/782] Loss_D: 0.5834 Loss_G: 3.6461\n",
            "[2/25][84/782] Loss_D: 0.7755 Loss_G: 1.1659\n",
            "[2/25][85/782] Loss_D: 1.1044 Loss_G: 3.6079\n",
            "[2/25][86/782] Loss_D: 0.9232 Loss_G: 1.0785\n",
            "[2/25][87/782] Loss_D: 1.1267 Loss_G: 4.6724\n",
            "[2/25][88/782] Loss_D: 1.0416 Loss_G: 1.6903\n",
            "[2/25][89/782] Loss_D: 0.7143 Loss_G: 2.9581\n",
            "[2/25][90/782] Loss_D: 0.5330 Loss_G: 3.7632\n",
            "[2/25][91/782] Loss_D: 0.5692 Loss_G: 3.1769\n",
            "[2/25][92/782] Loss_D: 0.4397 Loss_G: 2.6247\n",
            "[2/25][93/782] Loss_D: 0.3902 Loss_G: 3.3140\n",
            "[2/25][94/782] Loss_D: 0.6280 Loss_G: 2.7177\n",
            "[2/25][95/782] Loss_D: 0.4406 Loss_G: 2.8175\n",
            "[2/25][96/782] Loss_D: 0.3034 Loss_G: 3.3250\n",
            "[2/25][97/782] Loss_D: 0.6989 Loss_G: 3.2124\n",
            "[2/25][98/782] Loss_D: 0.5599 Loss_G: 2.0463\n",
            "[2/25][99/782] Loss_D: 0.9175 Loss_G: 4.0879\n",
            "[2/25][100/782] Loss_D: 0.4355 Loss_G: 3.2796\n",
            "[2/25][101/782] Loss_D: 0.3078 Loss_G: 2.9211\n",
            "[2/25][102/782] Loss_D: 0.4113 Loss_G: 2.4194\n",
            "[2/25][103/782] Loss_D: 0.6381 Loss_G: 4.8700\n",
            "[2/25][104/782] Loss_D: 0.7544 Loss_G: 1.7614\n",
            "[2/25][105/782] Loss_D: 0.6529 Loss_G: 4.6359\n",
            "[2/25][106/782] Loss_D: 0.3117 Loss_G: 3.7732\n",
            "[2/25][107/782] Loss_D: 0.3785 Loss_G: 2.9118\n",
            "[2/25][108/782] Loss_D: 0.3703 Loss_G: 4.0583\n",
            "[2/25][109/782] Loss_D: 0.3461 Loss_G: 3.6632\n",
            "[2/25][110/782] Loss_D: 0.2343 Loss_G: 3.1502\n",
            "[2/25][111/782] Loss_D: 0.3927 Loss_G: 3.8290\n",
            "[2/25][112/782] Loss_D: 0.4867 Loss_G: 2.7073\n",
            "[2/25][113/782] Loss_D: 0.3632 Loss_G: 3.7732\n",
            "[2/25][114/782] Loss_D: 0.5234 Loss_G: 2.6238\n",
            "[2/25][115/782] Loss_D: 0.5932 Loss_G: 5.4879\n",
            "[2/25][116/782] Loss_D: 0.6077 Loss_G: 2.9472\n",
            "[2/25][117/782] Loss_D: 0.3107 Loss_G: 3.7349\n",
            "[2/25][118/782] Loss_D: 0.3889 Loss_G: 3.5561\n",
            "[2/25][119/782] Loss_D: 0.3104 Loss_G: 3.7022\n",
            "[2/25][120/782] Loss_D: 0.4499 Loss_G: 2.7946\n",
            "[2/25][121/782] Loss_D: 0.3469 Loss_G: 3.7822\n",
            "[2/25][122/782] Loss_D: 0.3612 Loss_G: 3.6711\n",
            "[2/25][123/782] Loss_D: 0.2527 Loss_G: 3.9353\n",
            "[2/25][124/782] Loss_D: 0.3813 Loss_G: 3.7243\n",
            "[2/25][125/782] Loss_D: 0.4448 Loss_G: 2.9666\n",
            "[2/25][126/782] Loss_D: 0.4980 Loss_G: 4.7338\n",
            "[2/25][127/782] Loss_D: 0.7402 Loss_G: 2.3988\n",
            "[2/25][128/782] Loss_D: 0.5818 Loss_G: 5.5803\n",
            "[2/25][129/782] Loss_D: 0.5847 Loss_G: 1.8379\n",
            "[2/25][130/782] Loss_D: 0.9952 Loss_G: 7.5680\n",
            "[2/25][131/782] Loss_D: 0.9394 Loss_G: 1.6564\n",
            "[2/25][132/782] Loss_D: 1.0453 Loss_G: 6.9778\n",
            "[2/25][133/782] Loss_D: 0.5231 Loss_G: 4.0225\n",
            "[2/25][134/782] Loss_D: 0.3049 Loss_G: 3.7748\n",
            "[2/25][135/782] Loss_D: 0.9626 Loss_G: 6.7750\n",
            "[2/25][136/782] Loss_D: 2.9708 Loss_G: 0.0410\n",
            "[2/25][137/782] Loss_D: 3.8710 Loss_G: 7.2331\n",
            "[2/25][138/782] Loss_D: 2.4366 Loss_G: 1.1528\n",
            "[2/25][139/782] Loss_D: 1.4960 Loss_G: 3.5446\n",
            "[2/25][140/782] Loss_D: 0.7805 Loss_G: 3.6304\n",
            "[2/25][141/782] Loss_D: 0.6165 Loss_G: 2.4531\n",
            "[2/25][142/782] Loss_D: 1.1278 Loss_G: 5.3266\n",
            "[2/25][143/782] Loss_D: 1.2956 Loss_G: 2.0046\n",
            "[2/25][144/782] Loss_D: 1.4091 Loss_G: 3.7220\n",
            "[2/25][145/782] Loss_D: 1.2541 Loss_G: 2.7202\n",
            "[2/25][146/782] Loss_D: 0.7903 Loss_G: 3.3481\n",
            "[2/25][147/782] Loss_D: 0.6999 Loss_G: 2.8932\n",
            "[2/25][148/782] Loss_D: 0.6314 Loss_G: 3.4783\n",
            "[2/25][149/782] Loss_D: 0.4178 Loss_G: 3.5341\n",
            "[2/25][150/782] Loss_D: 0.3735 Loss_G: 3.2850\n",
            "[2/25][151/782] Loss_D: 0.4929 Loss_G: 2.6894\n",
            "[2/25][152/782] Loss_D: 0.5282 Loss_G: 3.1857\n",
            "[2/25][153/782] Loss_D: 0.3862 Loss_G: 3.4256\n",
            "[2/25][154/782] Loss_D: 0.3137 Loss_G: 3.0678\n",
            "[2/25][155/782] Loss_D: 0.3795 Loss_G: 2.5096\n",
            "[2/25][156/782] Loss_D: 0.6804 Loss_G: 4.6127\n",
            "[2/25][157/782] Loss_D: 0.5717 Loss_G: 2.9468\n",
            "[2/25][158/782] Loss_D: 0.4376 Loss_G: 2.6430\n",
            "[2/25][159/782] Loss_D: 0.4970 Loss_G: 4.1398\n",
            "[2/25][160/782] Loss_D: 0.3585 Loss_G: 3.6470\n",
            "[2/25][161/782] Loss_D: 0.3714 Loss_G: 2.5924\n",
            "[2/25][162/782] Loss_D: 0.4840 Loss_G: 3.7880\n",
            "[2/25][163/782] Loss_D: 0.4020 Loss_G: 4.0557\n",
            "[2/25][164/782] Loss_D: 0.4530 Loss_G: 2.4518\n",
            "[2/25][165/782] Loss_D: 0.4688 Loss_G: 4.1048\n",
            "[2/25][166/782] Loss_D: 0.4321 Loss_G: 2.8567\n",
            "[2/25][167/782] Loss_D: 0.4363 Loss_G: 3.5763\n",
            "[2/25][168/782] Loss_D: 0.4046 Loss_G: 4.1052\n",
            "[2/25][169/782] Loss_D: 0.7038 Loss_G: 1.4309\n",
            "[2/25][170/782] Loss_D: 0.9820 Loss_G: 5.4388\n",
            "[2/25][171/782] Loss_D: 0.8992 Loss_G: 1.9389\n",
            "[2/25][172/782] Loss_D: 0.9132 Loss_G: 4.0880\n",
            "[2/25][173/782] Loss_D: 0.3797 Loss_G: 3.8095\n",
            "[2/25][174/782] Loss_D: 0.6012 Loss_G: 1.9625\n",
            "[2/25][175/782] Loss_D: 1.1632 Loss_G: 5.5437\n",
            "[2/25][176/782] Loss_D: 1.4404 Loss_G: 0.7921\n",
            "[2/25][177/782] Loss_D: 1.6154 Loss_G: 6.8669\n",
            "[2/25][178/782] Loss_D: 1.7963 Loss_G: 1.2152\n",
            "[2/25][179/782] Loss_D: 1.1635 Loss_G: 4.6801\n",
            "[2/25][180/782] Loss_D: 0.6127 Loss_G: 4.0334\n",
            "[2/25][181/782] Loss_D: 0.8773 Loss_G: 1.8830\n",
            "[2/25][182/782] Loss_D: 1.1725 Loss_G: 4.5312\n",
            "[2/25][183/782] Loss_D: 0.6949 Loss_G: 2.9767\n",
            "[2/25][184/782] Loss_D: 0.4176 Loss_G: 2.7109\n",
            "[2/25][185/782] Loss_D: 0.8570 Loss_G: 5.4176\n",
            "[2/25][186/782] Loss_D: 0.9182 Loss_G: 2.4183\n",
            "[2/25][187/782] Loss_D: 0.4777 Loss_G: 2.3500\n",
            "[2/25][188/782] Loss_D: 0.5430 Loss_G: 4.5265\n",
            "[2/25][189/782] Loss_D: 0.6254 Loss_G: 2.4791\n",
            "[2/25][190/782] Loss_D: 0.6026 Loss_G: 3.2122\n",
            "[2/25][191/782] Loss_D: 0.3949 Loss_G: 3.8945\n",
            "[2/25][192/782] Loss_D: 1.0604 Loss_G: 0.9779\n",
            "[2/25][193/782] Loss_D: 1.3204 Loss_G: 7.0873\n",
            "[2/25][194/782] Loss_D: 1.4624 Loss_G: 2.3006\n",
            "[2/25][195/782] Loss_D: 0.4888 Loss_G: 3.2367\n",
            "[2/25][196/782] Loss_D: 0.3869 Loss_G: 3.7642\n",
            "[2/25][197/782] Loss_D: 0.4949 Loss_G: 3.7386\n",
            "[2/25][198/782] Loss_D: 0.7265 Loss_G: 1.6414\n",
            "[2/25][199/782] Loss_D: 0.8024 Loss_G: 3.8533\n",
            "[2/25][200/782] Loss_D: 0.6184 Loss_G: 2.3179\n",
            "[2/25][201/782] Loss_D: 0.6739 Loss_G: 2.9673\n",
            "[2/25][202/782] Loss_D: 0.6525 Loss_G: 2.1531\n",
            "[2/25][203/782] Loss_D: 0.6252 Loss_G: 3.2002\n",
            "[2/25][204/782] Loss_D: 0.5725 Loss_G: 2.5846\n",
            "[2/25][205/782] Loss_D: 0.7127 Loss_G: 2.4440\n",
            "[2/25][206/782] Loss_D: 0.4957 Loss_G: 3.0650\n",
            "[2/25][207/782] Loss_D: 0.4941 Loss_G: 2.6774\n",
            "[2/25][208/782] Loss_D: 0.4461 Loss_G: 2.8836\n",
            "[2/25][209/782] Loss_D: 0.4263 Loss_G: 3.2462\n",
            "[2/25][210/782] Loss_D: 0.6337 Loss_G: 2.5452\n",
            "[2/25][211/782] Loss_D: 0.3556 Loss_G: 3.0898\n",
            "[2/25][212/782] Loss_D: 0.2886 Loss_G: 3.3178\n",
            "[2/25][213/782] Loss_D: 0.2582 Loss_G: 3.1082\n",
            "[2/25][214/782] Loss_D: 0.3276 Loss_G: 3.2587\n",
            "[2/25][215/782] Loss_D: 0.3098 Loss_G: 3.5432\n",
            "[2/25][216/782] Loss_D: 0.5036 Loss_G: 3.2471\n",
            "[2/25][217/782] Loss_D: 0.4955 Loss_G: 3.2658\n",
            "[2/25][218/782] Loss_D: 0.5348 Loss_G: 3.2367\n",
            "[2/25][219/782] Loss_D: 0.5777 Loss_G: 3.5145\n",
            "[2/25][220/782] Loss_D: 0.4081 Loss_G: 3.4902\n",
            "[2/25][221/782] Loss_D: 0.3075 Loss_G: 3.3268\n",
            "[2/25][222/782] Loss_D: 0.3485 Loss_G: 4.4073\n",
            "[2/25][223/782] Loss_D: 0.3319 Loss_G: 2.5649\n",
            "[2/25][224/782] Loss_D: 0.7358 Loss_G: 6.2639\n",
            "[2/25][225/782] Loss_D: 1.0134 Loss_G: 0.7544\n",
            "[2/25][226/782] Loss_D: 1.5800 Loss_G: 7.1250\n",
            "[2/25][227/782] Loss_D: 2.0188 Loss_G: 2.1648\n",
            "[2/25][228/782] Loss_D: 0.5274 Loss_G: 4.1251\n",
            "[2/25][229/782] Loss_D: 0.3180 Loss_G: 5.4271\n",
            "[2/25][230/782] Loss_D: 0.5174 Loss_G: 4.0747\n",
            "[2/25][231/782] Loss_D: 0.5412 Loss_G: 1.9241\n",
            "[2/25][232/782] Loss_D: 0.8500 Loss_G: 7.0634\n",
            "[2/25][233/782] Loss_D: 1.2518 Loss_G: 3.1717\n",
            "[2/25][234/782] Loss_D: 0.5195 Loss_G: 4.0574\n",
            "[2/25][235/782] Loss_D: 0.3297 Loss_G: 4.1383\n",
            "[2/25][236/782] Loss_D: 0.3140 Loss_G: 3.2736\n",
            "[2/25][237/782] Loss_D: 0.3754 Loss_G: 4.1465\n",
            "[2/25][238/782] Loss_D: 0.6842 Loss_G: 2.6341\n",
            "[2/25][239/782] Loss_D: 0.7132 Loss_G: 4.6412\n",
            "[2/25][240/782] Loss_D: 0.7331 Loss_G: 2.2783\n",
            "[2/25][241/782] Loss_D: 0.7628 Loss_G: 4.4148\n",
            "[2/25][242/782] Loss_D: 0.2990 Loss_G: 4.0239\n",
            "[2/25][243/782] Loss_D: 0.3992 Loss_G: 2.9817\n",
            "[2/25][244/782] Loss_D: 0.6717 Loss_G: 4.6994\n",
            "[2/25][245/782] Loss_D: 0.6078 Loss_G: 2.6094\n",
            "[2/25][246/782] Loss_D: 0.7849 Loss_G: 4.8815\n",
            "[2/25][247/782] Loss_D: 0.4402 Loss_G: 3.5997\n",
            "[2/25][248/782] Loss_D: 0.2775 Loss_G: 2.7180\n",
            "[2/25][249/782] Loss_D: 0.7199 Loss_G: 4.2765\n",
            "[2/25][250/782] Loss_D: 0.4452 Loss_G: 4.6063\n",
            "[2/25][251/782] Loss_D: 0.5108 Loss_G: 1.6138\n",
            "[2/25][252/782] Loss_D: 1.0211 Loss_G: 8.0078\n",
            "[2/25][253/782] Loss_D: 1.8421 Loss_G: 0.2736\n",
            "[2/25][254/782] Loss_D: 2.1107 Loss_G: 5.7310\n",
            "[2/25][255/782] Loss_D: 3.3875 Loss_G: 0.2611\n",
            "[2/25][256/782] Loss_D: 1.8901 Loss_G: 2.0127\n",
            "[2/25][257/782] Loss_D: 0.8603 Loss_G: 2.3719\n",
            "[2/25][258/782] Loss_D: 0.8320 Loss_G: 1.9814\n",
            "[2/25][259/782] Loss_D: 0.6821 Loss_G: 2.3188\n",
            "[2/25][260/782] Loss_D: 0.9070 Loss_G: 1.6346\n",
            "[2/25][261/782] Loss_D: 0.9195 Loss_G: 2.4497\n",
            "[2/25][262/782] Loss_D: 0.9029 Loss_G: 2.5921\n",
            "[2/25][263/782] Loss_D: 0.9968 Loss_G: 1.6973\n",
            "[2/25][264/782] Loss_D: 0.9189 Loss_G: 3.3199\n",
            "[2/25][265/782] Loss_D: 0.7846 Loss_G: 1.9330\n",
            "[2/25][266/782] Loss_D: 0.7964 Loss_G: 3.0686\n",
            "[2/25][267/782] Loss_D: 0.6672 Loss_G: 2.4586\n",
            "[2/25][268/782] Loss_D: 0.5183 Loss_G: 2.6740\n",
            "[2/25][269/782] Loss_D: 0.5561 Loss_G: 3.3318\n",
            "[2/25][270/782] Loss_D: 0.3885 Loss_G: 2.9670\n",
            "[2/25][271/782] Loss_D: 0.4754 Loss_G: 2.3321\n",
            "[2/25][272/782] Loss_D: 0.5306 Loss_G: 3.5763\n",
            "[2/25][273/782] Loss_D: 0.6275 Loss_G: 1.3926\n",
            "[2/25][274/782] Loss_D: 0.8885 Loss_G: 4.5733\n",
            "[2/25][275/782] Loss_D: 0.7015 Loss_G: 2.5293\n",
            "[2/25][276/782] Loss_D: 0.5123 Loss_G: 2.0536\n",
            "[2/25][277/782] Loss_D: 1.0060 Loss_G: 3.8232\n",
            "[2/25][278/782] Loss_D: 1.2672 Loss_G: 1.0401\n",
            "[2/25][279/782] Loss_D: 1.2915 Loss_G: 3.8881\n",
            "[2/25][280/782] Loss_D: 0.5940 Loss_G: 2.6941\n",
            "[2/25][281/782] Loss_D: 0.8290 Loss_G: 2.7731\n",
            "[2/25][282/782] Loss_D: 0.7932 Loss_G: 2.6224\n",
            "[2/25][283/782] Loss_D: 0.9699 Loss_G: 1.6135\n",
            "[2/25][284/782] Loss_D: 1.1453 Loss_G: 3.9750\n",
            "[2/25][285/782] Loss_D: 0.9185 Loss_G: 2.2047\n",
            "[2/25][286/782] Loss_D: 0.6422 Loss_G: 2.9640\n",
            "[2/25][287/782] Loss_D: 0.8029 Loss_G: 4.2148\n",
            "[2/25][288/782] Loss_D: 0.9214 Loss_G: 1.9513\n",
            "[2/25][289/782] Loss_D: 1.1195 Loss_G: 4.3227\n",
            "[2/25][290/782] Loss_D: 0.6955 Loss_G: 2.7758\n",
            "[2/25][291/782] Loss_D: 0.6882 Loss_G: 2.7971\n",
            "[2/25][292/782] Loss_D: 0.4359 Loss_G: 3.8656\n",
            "[2/25][293/782] Loss_D: 0.6762 Loss_G: 1.9802\n",
            "[2/25][294/782] Loss_D: 0.6529 Loss_G: 4.4522\n",
            "[2/25][295/782] Loss_D: 0.6995 Loss_G: 2.3521\n",
            "[2/25][296/782] Loss_D: 1.0538 Loss_G: 5.1658\n",
            "[2/25][297/782] Loss_D: 1.2921 Loss_G: 1.5536\n",
            "[2/25][298/782] Loss_D: 1.5727 Loss_G: 4.9621\n",
            "[2/25][299/782] Loss_D: 1.5911 Loss_G: 1.2725\n",
            "[2/25][300/782] Loss_D: 1.5045 Loss_G: 3.2883\n",
            "[2/25][301/782] Loss_D: 1.4249 Loss_G: 2.1927\n",
            "[2/25][302/782] Loss_D: 1.3265 Loss_G: 1.5161\n",
            "[2/25][303/782] Loss_D: 1.2930 Loss_G: 5.9682\n",
            "[2/25][304/782] Loss_D: 1.7875 Loss_G: 1.4577\n",
            "[2/25][305/782] Loss_D: 1.3690 Loss_G: 3.0172\n",
            "[2/25][306/782] Loss_D: 0.5032 Loss_G: 3.9834\n",
            "[2/25][307/782] Loss_D: 0.6871 Loss_G: 2.0819\n",
            "[2/25][308/782] Loss_D: 0.9381 Loss_G: 2.8298\n",
            "[2/25][309/782] Loss_D: 0.4115 Loss_G: 3.2754\n",
            "[2/25][310/782] Loss_D: 0.4702 Loss_G: 3.2722\n",
            "[2/25][311/782] Loss_D: 0.5297 Loss_G: 2.4545\n",
            "[2/25][312/782] Loss_D: 0.7565 Loss_G: 3.5406\n",
            "[2/25][313/782] Loss_D: 0.6835 Loss_G: 2.8133\n",
            "[2/25][314/782] Loss_D: 0.8923 Loss_G: 1.2006\n",
            "[2/25][315/782] Loss_D: 1.1795 Loss_G: 4.6671\n",
            "[2/25][316/782] Loss_D: 0.6413 Loss_G: 2.8334\n",
            "[2/25][317/782] Loss_D: 0.7361 Loss_G: 1.5769\n",
            "[2/25][318/782] Loss_D: 0.8860 Loss_G: 4.6368\n",
            "[2/25][319/782] Loss_D: 0.7033 Loss_G: 2.1618\n",
            "[2/25][320/782] Loss_D: 0.5907 Loss_G: 2.9277\n",
            "[2/25][321/782] Loss_D: 0.4451 Loss_G: 3.3667\n",
            "[2/25][322/782] Loss_D: 0.3887 Loss_G: 2.9139\n",
            "[2/25][323/782] Loss_D: 0.5036 Loss_G: 2.5616\n",
            "[2/25][324/782] Loss_D: 0.5796 Loss_G: 2.4484\n",
            "[2/25][325/782] Loss_D: 0.5327 Loss_G: 2.6006\n",
            "[2/25][326/782] Loss_D: 0.7244 Loss_G: 2.4884\n",
            "[2/25][327/782] Loss_D: 0.4503 Loss_G: 3.1471\n",
            "[2/25][328/782] Loss_D: 0.5954 Loss_G: 1.9160\n",
            "[2/25][329/782] Loss_D: 0.7504 Loss_G: 3.9733\n",
            "[2/25][330/782] Loss_D: 0.5570 Loss_G: 2.1434\n",
            "[2/25][331/782] Loss_D: 0.5723 Loss_G: 2.6005\n",
            "[2/25][332/782] Loss_D: 0.6225 Loss_G: 2.0043\n",
            "[2/25][333/782] Loss_D: 0.6200 Loss_G: 4.2121\n",
            "[2/25][334/782] Loss_D: 0.8246 Loss_G: 1.8520\n",
            "[2/25][335/782] Loss_D: 0.5083 Loss_G: 2.0197\n",
            "[2/25][336/782] Loss_D: 0.5132 Loss_G: 3.3997\n",
            "[2/25][337/782] Loss_D: 0.3829 Loss_G: 3.1803\n",
            "[2/25][338/782] Loss_D: 0.5958 Loss_G: 1.5284\n",
            "[2/25][339/782] Loss_D: 0.5633 Loss_G: 3.5090\n",
            "[2/25][340/782] Loss_D: 0.4315 Loss_G: 3.3941\n",
            "[2/25][341/782] Loss_D: 0.7559 Loss_G: 1.1192\n",
            "[2/25][342/782] Loss_D: 1.1813 Loss_G: 4.5216\n",
            "[2/25][343/782] Loss_D: 0.5430 Loss_G: 3.4774\n",
            "[2/25][344/782] Loss_D: 0.4517 Loss_G: 1.8164\n",
            "[2/25][345/782] Loss_D: 0.6145 Loss_G: 2.8815\n",
            "[2/25][346/782] Loss_D: 0.4351 Loss_G: 3.9384\n",
            "[2/25][347/782] Loss_D: 0.5946 Loss_G: 2.3688\n",
            "[2/25][348/782] Loss_D: 0.4414 Loss_G: 2.3262\n",
            "[2/25][349/782] Loss_D: 0.4856 Loss_G: 2.6974\n",
            "[2/25][350/782] Loss_D: 0.4792 Loss_G: 3.6670\n",
            "[2/25][351/782] Loss_D: 0.4394 Loss_G: 2.6264\n",
            "[2/25][352/782] Loss_D: 0.3999 Loss_G: 2.3297\n",
            "[2/25][353/782] Loss_D: 0.4437 Loss_G: 3.0961\n",
            "[2/25][354/782] Loss_D: 0.5559 Loss_G: 2.4223\n",
            "[2/25][355/782] Loss_D: 0.6473 Loss_G: 3.1699\n",
            "[2/25][356/782] Loss_D: 0.5623 Loss_G: 2.0656\n",
            "[2/25][357/782] Loss_D: 0.5956 Loss_G: 2.8681\n",
            "[2/25][358/782] Loss_D: 0.5878 Loss_G: 3.2337\n",
            "[2/25][359/782] Loss_D: 0.5579 Loss_G: 2.4642\n",
            "[2/25][360/782] Loss_D: 0.3681 Loss_G: 3.2236\n",
            "[2/25][361/782] Loss_D: 0.7445 Loss_G: 1.9101\n",
            "[2/25][362/782] Loss_D: 0.7580 Loss_G: 5.1623\n",
            "[2/25][363/782] Loss_D: 1.1325 Loss_G: 1.6147\n",
            "[2/25][364/782] Loss_D: 0.5123 Loss_G: 3.7927\n",
            "[2/25][365/782] Loss_D: 0.4066 Loss_G: 3.0476\n",
            "[2/25][366/782] Loss_D: 0.9539 Loss_G: 0.4314\n",
            "[2/25][367/782] Loss_D: 1.9771 Loss_G: 7.5249\n",
            "[2/25][368/782] Loss_D: 2.1718 Loss_G: 2.0971\n",
            "[2/25][369/782] Loss_D: 0.5562 Loss_G: 3.0917\n",
            "[2/25][370/782] Loss_D: 0.8231 Loss_G: 5.4377\n",
            "[2/25][371/782] Loss_D: 0.9960 Loss_G: 1.3764\n",
            "[2/25][372/782] Loss_D: 1.1519 Loss_G: 4.5310\n",
            "[2/25][373/782] Loss_D: 0.6246 Loss_G: 2.8374\n",
            "[2/25][374/782] Loss_D: 0.8589 Loss_G: 2.5254\n",
            "[2/25][375/782] Loss_D: 0.5303 Loss_G: 2.3992\n",
            "[2/25][376/782] Loss_D: 0.7507 Loss_G: 4.3495\n",
            "[2/25][377/782] Loss_D: 0.5751 Loss_G: 2.0087\n",
            "[2/25][378/782] Loss_D: 0.7430 Loss_G: 3.2874\n",
            "[2/25][379/782] Loss_D: 0.4885 Loss_G: 2.7229\n",
            "[2/25][380/782] Loss_D: 0.5133 Loss_G: 2.9707\n",
            "[2/25][381/782] Loss_D: 0.6643 Loss_G: 2.3385\n",
            "[2/25][382/782] Loss_D: 0.8043 Loss_G: 3.2193\n",
            "[2/25][383/782] Loss_D: 0.4875 Loss_G: 3.0394\n",
            "[2/25][384/782] Loss_D: 0.6192 Loss_G: 2.6342\n",
            "[2/25][385/782] Loss_D: 0.6545 Loss_G: 3.6250\n",
            "[2/25][386/782] Loss_D: 0.8075 Loss_G: 1.5005\n",
            "[2/25][387/782] Loss_D: 1.3388 Loss_G: 6.5869\n",
            "[2/25][388/782] Loss_D: 1.7598 Loss_G: 2.1378\n",
            "[2/25][389/782] Loss_D: 0.5420 Loss_G: 2.6104\n",
            "[2/25][390/782] Loss_D: 0.7126 Loss_G: 4.2455\n",
            "[2/25][391/782] Loss_D: 0.7763 Loss_G: 1.8024\n",
            "[2/25][392/782] Loss_D: 0.7842 Loss_G: 4.2624\n",
            "[2/25][393/782] Loss_D: 0.9375 Loss_G: 1.0763\n",
            "[2/25][394/782] Loss_D: 1.4337 Loss_G: 5.1668\n",
            "[2/25][395/782] Loss_D: 1.3986 Loss_G: 0.8841\n",
            "[2/25][396/782] Loss_D: 1.2141 Loss_G: 3.3702\n",
            "[2/25][397/782] Loss_D: 0.8888 Loss_G: 2.2614\n",
            "[2/25][398/782] Loss_D: 0.8213 Loss_G: 1.4908\n",
            "[2/25][399/782] Loss_D: 0.8925 Loss_G: 3.3509\n",
            "[2/25][400/782] Loss_D: 1.0185 Loss_G: 1.6062\n",
            "[2/25][401/782] Loss_D: 0.6948 Loss_G: 3.0019\n",
            "[2/25][402/782] Loss_D: 0.5605 Loss_G: 3.2279\n",
            "[2/25][403/782] Loss_D: 0.5850 Loss_G: 2.7258\n",
            "[2/25][404/782] Loss_D: 0.6340 Loss_G: 2.6813\n",
            "[2/25][405/782] Loss_D: 0.6177 Loss_G: 2.7699\n",
            "[2/25][406/782] Loss_D: 0.7611 Loss_G: 2.7468\n",
            "[2/25][407/782] Loss_D: 0.6806 Loss_G: 1.9595\n",
            "[2/25][408/782] Loss_D: 0.7945 Loss_G: 4.1241\n",
            "[2/25][409/782] Loss_D: 0.8705 Loss_G: 1.9245\n",
            "[2/25][410/782] Loss_D: 0.7720 Loss_G: 3.7711\n",
            "[2/25][411/782] Loss_D: 0.6850 Loss_G: 2.7074\n",
            "[2/25][412/782] Loss_D: 0.5048 Loss_G: 2.8341\n",
            "[2/25][413/782] Loss_D: 0.4242 Loss_G: 2.9206\n",
            "[2/25][414/782] Loss_D: 0.4399 Loss_G: 2.8012\n",
            "[2/25][415/782] Loss_D: 0.5681 Loss_G: 4.3117\n",
            "[2/25][416/782] Loss_D: 0.5387 Loss_G: 2.8152\n",
            "[2/25][417/782] Loss_D: 0.4134 Loss_G: 2.1856\n",
            "[2/25][418/782] Loss_D: 0.5457 Loss_G: 4.2218\n",
            "[2/25][419/782] Loss_D: 0.7251 Loss_G: 2.1358\n",
            "[2/25][420/782] Loss_D: 0.5081 Loss_G: 3.7901\n",
            "[2/25][421/782] Loss_D: 0.5465 Loss_G: 2.4070\n",
            "[2/25][422/782] Loss_D: 0.4675 Loss_G: 3.2374\n",
            "[2/25][423/782] Loss_D: 0.5327 Loss_G: 3.2903\n",
            "[2/25][424/782] Loss_D: 0.4228 Loss_G: 3.0565\n",
            "[2/25][425/782] Loss_D: 0.4131 Loss_G: 3.0332\n",
            "[2/25][426/782] Loss_D: 0.4052 Loss_G: 3.0220\n",
            "[2/25][427/782] Loss_D: 0.4662 Loss_G: 2.6457\n",
            "[2/25][428/782] Loss_D: 0.3441 Loss_G: 4.1822\n",
            "[2/25][429/782] Loss_D: 0.3491 Loss_G: 2.9725\n",
            "[2/25][430/782] Loss_D: 0.4792 Loss_G: 2.9793\n",
            "[2/25][431/782] Loss_D: 0.7515 Loss_G: 3.8806\n",
            "[2/25][432/782] Loss_D: 1.0498 Loss_G: 1.2478\n",
            "[2/25][433/782] Loss_D: 1.4305 Loss_G: 6.2678\n",
            "[2/25][434/782] Loss_D: 1.7490 Loss_G: 2.0248\n",
            "[2/25][435/782] Loss_D: 0.7819 Loss_G: 3.9963\n",
            "[2/25][436/782] Loss_D: 0.5343 Loss_G: 3.4233\n",
            "[2/25][437/782] Loss_D: 0.6470 Loss_G: 1.8705\n",
            "[2/25][438/782] Loss_D: 1.3721 Loss_G: 4.8496\n",
            "[2/25][439/782] Loss_D: 1.4489 Loss_G: 1.0137\n",
            "[2/25][440/782] Loss_D: 1.4653 Loss_G: 4.0689\n",
            "[2/25][441/782] Loss_D: 1.0018 Loss_G: 2.9161\n",
            "[2/25][442/782] Loss_D: 0.5871 Loss_G: 3.6709\n",
            "[2/25][443/782] Loss_D: 0.8386 Loss_G: 1.6385\n",
            "[2/25][444/782] Loss_D: 1.2849 Loss_G: 5.3789\n",
            "[2/25][445/782] Loss_D: 1.0967 Loss_G: 1.8739\n",
            "[2/25][446/782] Loss_D: 0.7498 Loss_G: 4.0871\n",
            "[2/25][447/782] Loss_D: 0.5464 Loss_G: 3.1122\n",
            "[2/25][448/782] Loss_D: 0.4446 Loss_G: 3.0287\n",
            "[2/25][449/782] Loss_D: 0.4563 Loss_G: 3.2454\n",
            "[2/25][450/782] Loss_D: 0.3043 Loss_G: 3.3500\n",
            "[2/25][451/782] Loss_D: 0.6219 Loss_G: 2.5610\n",
            "[2/25][452/782] Loss_D: 0.7456 Loss_G: 2.1868\n",
            "[2/25][453/782] Loss_D: 0.6411 Loss_G: 1.7422\n",
            "[2/25][454/782] Loss_D: 0.8055 Loss_G: 4.7337\n",
            "[2/25][455/782] Loss_D: 1.3049 Loss_G: 0.8250\n",
            "[2/25][456/782] Loss_D: 1.2321 Loss_G: 5.1901\n",
            "[2/25][457/782] Loss_D: 1.5514 Loss_G: 0.9866\n",
            "[2/25][458/782] Loss_D: 1.1529 Loss_G: 5.7885\n",
            "[2/25][459/782] Loss_D: 1.4336 Loss_G: 1.1003\n",
            "[2/25][460/782] Loss_D: 1.0458 Loss_G: 4.0432\n",
            "[2/25][461/782] Loss_D: 0.6523 Loss_G: 2.6553\n",
            "[2/25][462/782] Loss_D: 0.6657 Loss_G: 2.7656\n",
            "[2/25][463/782] Loss_D: 0.5559 Loss_G: 2.9043\n",
            "[2/25][464/782] Loss_D: 0.6959 Loss_G: 2.9301\n",
            "[2/25][465/782] Loss_D: 0.5813 Loss_G: 2.8044\n",
            "[2/25][466/782] Loss_D: 0.6851 Loss_G: 2.7048\n",
            "[2/25][467/782] Loss_D: 0.5718 Loss_G: 2.8591\n",
            "[2/25][468/782] Loss_D: 0.4642 Loss_G: 4.0964\n",
            "[2/25][469/782] Loss_D: 0.6392 Loss_G: 1.9446\n",
            "[2/25][470/782] Loss_D: 0.5138 Loss_G: 3.2343\n",
            "[2/25][471/782] Loss_D: 0.4016 Loss_G: 3.4279\n",
            "[2/25][472/782] Loss_D: 0.3053 Loss_G: 3.1514\n",
            "[2/25][473/782] Loss_D: 0.6158 Loss_G: 2.4095\n",
            "[2/25][474/782] Loss_D: 0.4871 Loss_G: 3.1241\n",
            "[2/25][475/782] Loss_D: 0.6821 Loss_G: 3.5059\n",
            "[2/25][476/782] Loss_D: 0.5227 Loss_G: 2.4521\n",
            "[2/25][477/782] Loss_D: 0.4490 Loss_G: 2.7973\n",
            "[2/25][478/782] Loss_D: 0.4619 Loss_G: 3.8976\n",
            "[2/25][479/782] Loss_D: 0.6214 Loss_G: 1.6239\n",
            "[2/25][480/782] Loss_D: 0.7502 Loss_G: 4.5033\n",
            "[2/25][481/782] Loss_D: 0.5548 Loss_G: 3.0066\n",
            "[2/25][482/782] Loss_D: 0.4797 Loss_G: 2.5690\n",
            "[2/25][483/782] Loss_D: 0.4927 Loss_G: 3.7429\n",
            "[2/25][484/782] Loss_D: 0.6698 Loss_G: 1.9133\n",
            "[2/25][485/782] Loss_D: 0.7271 Loss_G: 4.5609\n",
            "[2/25][486/782] Loss_D: 0.8273 Loss_G: 1.3897\n",
            "[2/25][487/782] Loss_D: 0.6564 Loss_G: 3.9254\n",
            "[2/25][488/782] Loss_D: 0.5475 Loss_G: 2.6310\n",
            "[2/25][489/782] Loss_D: 0.5188 Loss_G: 2.6627\n",
            "[2/25][490/782] Loss_D: 1.0611 Loss_G: 3.6394\n",
            "[2/25][491/782] Loss_D: 0.6931 Loss_G: 2.3957\n",
            "[2/25][492/782] Loss_D: 0.5378 Loss_G: 3.0049\n",
            "[2/25][493/782] Loss_D: 0.5169 Loss_G: 2.2573\n",
            "[2/25][494/782] Loss_D: 0.6846 Loss_G: 3.7798\n",
            "[2/25][495/782] Loss_D: 0.6069 Loss_G: 1.9045\n",
            "[2/25][496/782] Loss_D: 0.6687 Loss_G: 4.4907\n",
            "[2/25][497/782] Loss_D: 0.5249 Loss_G: 2.8976\n",
            "[2/25][498/782] Loss_D: 0.4947 Loss_G: 2.5976\n",
            "[2/25][499/782] Loss_D: 0.4827 Loss_G: 3.2878\n",
            "[2/25][500/782] Loss_D: 0.3694 Loss_G: 3.3660\n",
            "[2/25][501/782] Loss_D: 0.5993 Loss_G: 1.5327\n",
            "[2/25][502/782] Loss_D: 0.6769 Loss_G: 4.3621\n",
            "[2/25][503/782] Loss_D: 0.4501 Loss_G: 2.6244\n",
            "[2/25][504/782] Loss_D: 0.5432 Loss_G: 2.9657\n",
            "[2/25][505/782] Loss_D: 0.5757 Loss_G: 3.0890\n",
            "[2/25][506/782] Loss_D: 0.3182 Loss_G: 3.5312\n",
            "[2/25][507/782] Loss_D: 0.4461 Loss_G: 2.0055\n",
            "[2/25][508/782] Loss_D: 0.7692 Loss_G: 4.0204\n",
            "[2/25][509/782] Loss_D: 0.6480 Loss_G: 1.6063\n",
            "[2/25][510/782] Loss_D: 0.5623 Loss_G: 4.0926\n",
            "[2/25][511/782] Loss_D: 0.6833 Loss_G: 2.0498\n",
            "[2/25][512/782] Loss_D: 0.4457 Loss_G: 4.1862\n",
            "[2/25][513/782] Loss_D: 0.4820 Loss_G: 2.5001\n",
            "[2/25][514/782] Loss_D: 0.4262 Loss_G: 2.5839\n",
            "[2/25][515/782] Loss_D: 0.3771 Loss_G: 3.4849\n",
            "[2/25][516/782] Loss_D: 0.6774 Loss_G: 2.0132\n",
            "[2/25][517/782] Loss_D: 0.5026 Loss_G: 3.7172\n",
            "[2/25][518/782] Loss_D: 0.5146 Loss_G: 1.5813\n",
            "[2/25][519/782] Loss_D: 0.7280 Loss_G: 4.3684\n",
            "[2/25][520/782] Loss_D: 0.6104 Loss_G: 1.8687\n",
            "[2/25][521/782] Loss_D: 0.6755 Loss_G: 3.7795\n",
            "[2/25][522/782] Loss_D: 0.5686 Loss_G: 2.1606\n",
            "[2/25][523/782] Loss_D: 0.4830 Loss_G: 3.4973\n",
            "[2/25][524/782] Loss_D: 0.4920 Loss_G: 2.9385\n",
            "[2/25][525/782] Loss_D: 0.4665 Loss_G: 3.1443\n",
            "[2/25][526/782] Loss_D: 0.3226 Loss_G: 3.4921\n",
            "[2/25][527/782] Loss_D: 0.4224 Loss_G: 2.7844\n",
            "[2/25][528/782] Loss_D: 0.5798 Loss_G: 3.7478\n",
            "[2/25][529/782] Loss_D: 0.3523 Loss_G: 3.3520\n",
            "[2/25][530/782] Loss_D: 0.5568 Loss_G: 2.0691\n",
            "[2/25][531/782] Loss_D: 0.9260 Loss_G: 6.2580\n",
            "[2/25][532/782] Loss_D: 1.2440 Loss_G: 2.0885\n",
            "[2/25][533/782] Loss_D: 0.9477 Loss_G: 4.0815\n",
            "[2/25][534/782] Loss_D: 0.8993 Loss_G: 1.0692\n",
            "[2/25][535/782] Loss_D: 1.0705 Loss_G: 6.2753\n",
            "[2/25][536/782] Loss_D: 0.9519 Loss_G: 2.0949\n",
            "[2/25][537/782] Loss_D: 0.7833 Loss_G: 4.8172\n",
            "[2/25][538/782] Loss_D: 0.4612 Loss_G: 2.6985\n",
            "[2/25][539/782] Loss_D: 0.5166 Loss_G: 4.1814\n",
            "[2/25][540/782] Loss_D: 0.7943 Loss_G: 1.1168\n",
            "[2/25][541/782] Loss_D: 1.7836 Loss_G: 4.7354\n",
            "[2/25][542/782] Loss_D: 1.8637 Loss_G: 0.8217\n",
            "[2/25][543/782] Loss_D: 1.6387 Loss_G: 4.6460\n",
            "[2/25][544/782] Loss_D: 1.7381 Loss_G: 1.0345\n",
            "[2/25][545/782] Loss_D: 1.2720 Loss_G: 5.7839\n",
            "[2/25][546/782] Loss_D: 1.4228 Loss_G: 0.7819\n",
            "[2/25][547/782] Loss_D: 1.4971 Loss_G: 4.7060\n",
            "[2/25][548/782] Loss_D: 1.3252 Loss_G: 1.3805\n",
            "[2/25][549/782] Loss_D: 1.3742 Loss_G: 6.1883\n",
            "[2/25][550/782] Loss_D: 1.8891 Loss_G: 0.7476\n",
            "[2/25][551/782] Loss_D: 1.4885 Loss_G: 5.3660\n",
            "[2/25][552/782] Loss_D: 1.0243 Loss_G: 2.0407\n",
            "[2/25][553/782] Loss_D: 0.7022 Loss_G: 3.9035\n",
            "[2/25][554/782] Loss_D: 0.6315 Loss_G: 2.8851\n",
            "[2/25][555/782] Loss_D: 0.4173 Loss_G: 2.7134\n",
            "[2/25][556/782] Loss_D: 0.5426 Loss_G: 3.5758\n",
            "[2/25][557/782] Loss_D: 0.6542 Loss_G: 1.7445\n",
            "[2/25][558/782] Loss_D: 0.8139 Loss_G: 4.9456\n",
            "[2/25][559/782] Loss_D: 0.4937 Loss_G: 3.0192\n",
            "[2/25][560/782] Loss_D: 0.6829 Loss_G: 3.2836\n",
            "[2/25][561/782] Loss_D: 0.6872 Loss_G: 3.1066\n",
            "[2/25][562/782] Loss_D: 0.7032 Loss_G: 1.8943\n",
            "[2/25][563/782] Loss_D: 0.7606 Loss_G: 4.3567\n",
            "[2/25][564/782] Loss_D: 0.5509 Loss_G: 2.5010\n",
            "[2/25][565/782] Loss_D: 0.6412 Loss_G: 3.7057\n",
            "[2/25][566/782] Loss_D: 0.5443 Loss_G: 2.2811\n",
            "[2/25][567/782] Loss_D: 0.5733 Loss_G: 4.4358\n",
            "[2/25][568/782] Loss_D: 0.3368 Loss_G: 3.5764\n",
            "[2/25][569/782] Loss_D: 0.6347 Loss_G: 1.6904\n",
            "[2/25][570/782] Loss_D: 0.6744 Loss_G: 4.2899\n",
            "[2/25][571/782] Loss_D: 0.6495 Loss_G: 2.1982\n",
            "[2/25][572/782] Loss_D: 0.6798 Loss_G: 3.2820\n",
            "[2/25][573/782] Loss_D: 0.4208 Loss_G: 3.6633\n",
            "[2/25][574/782] Loss_D: 0.4859 Loss_G: 2.2995\n",
            "[2/25][575/782] Loss_D: 0.8798 Loss_G: 4.9793\n",
            "[2/25][576/782] Loss_D: 1.3301 Loss_G: 1.0110\n",
            "[2/25][577/782] Loss_D: 1.0874 Loss_G: 4.5568\n",
            "[2/25][578/782] Loss_D: 0.8253 Loss_G: 1.6857\n",
            "[2/25][579/782] Loss_D: 0.7289 Loss_G: 4.2454\n",
            "[2/25][580/782] Loss_D: 0.5575 Loss_G: 2.6286\n",
            "[2/25][581/782] Loss_D: 0.4909 Loss_G: 3.3274\n",
            "[2/25][582/782] Loss_D: 0.5038 Loss_G: 2.6506\n",
            "[2/25][583/782] Loss_D: 0.3767 Loss_G: 2.7105\n",
            "[2/25][584/782] Loss_D: 0.4199 Loss_G: 3.3783\n",
            "[2/25][585/782] Loss_D: 0.4328 Loss_G: 2.3731\n",
            "[2/25][586/782] Loss_D: 0.4527 Loss_G: 3.1530\n",
            "[2/25][587/782] Loss_D: 0.3832 Loss_G: 3.0166\n",
            "[2/25][588/782] Loss_D: 0.4622 Loss_G: 2.5992\n",
            "[2/25][589/782] Loss_D: 0.4017 Loss_G: 3.1740\n",
            "[2/25][590/782] Loss_D: 0.4250 Loss_G: 2.5551\n",
            "[2/25][591/782] Loss_D: 0.3368 Loss_G: 3.2969\n",
            "[2/25][592/782] Loss_D: 0.4271 Loss_G: 2.5726\n",
            "[2/25][593/782] Loss_D: 0.4331 Loss_G: 3.2701\n",
            "[2/25][594/782] Loss_D: 0.4556 Loss_G: 3.4660\n",
            "[2/25][595/782] Loss_D: 0.6364 Loss_G: 1.1052\n",
            "[2/25][596/782] Loss_D: 0.8013 Loss_G: 5.5844\n",
            "[2/25][597/782] Loss_D: 0.5372 Loss_G: 2.7307\n",
            "[2/25][598/782] Loss_D: 0.3229 Loss_G: 2.5308\n",
            "[2/25][599/782] Loss_D: 0.4973 Loss_G: 3.9639\n",
            "[2/25][600/782] Loss_D: 0.6654 Loss_G: 2.0702\n",
            "[2/25][601/782] Loss_D: 0.9854 Loss_G: 5.6835\n",
            "[2/25][602/782] Loss_D: 1.2243 Loss_G: 2.0497\n",
            "[2/25][603/782] Loss_D: 0.5855 Loss_G: 5.0747\n",
            "[2/25][604/782] Loss_D: 0.8293 Loss_G: 0.9453\n",
            "[2/25][605/782] Loss_D: 1.1808 Loss_G: 6.0041\n",
            "[2/25][606/782] Loss_D: 0.8831 Loss_G: 0.1575\n",
            "[2/25][607/782] Loss_D: 3.1683 Loss_G: 9.6203\n",
            "[2/25][608/782] Loss_D: 3.3743 Loss_G: 2.6655\n",
            "[2/25][609/782] Loss_D: 0.7258 Loss_G: 1.1589\n",
            "[2/25][610/782] Loss_D: 1.2789 Loss_G: 4.7426\n",
            "[2/25][611/782] Loss_D: 1.3844 Loss_G: 1.5381\n",
            "[2/25][612/782] Loss_D: 1.2035 Loss_G: 3.9607\n",
            "[2/25][613/782] Loss_D: 0.9129 Loss_G: 3.1784\n",
            "[2/25][614/782] Loss_D: 0.6944 Loss_G: 2.0709\n",
            "[2/25][615/782] Loss_D: 0.8649 Loss_G: 3.6815\n",
            "[2/25][616/782] Loss_D: 0.7316 Loss_G: 2.9465\n",
            "[2/25][617/782] Loss_D: 0.5879 Loss_G: 1.9716\n",
            "[2/25][618/782] Loss_D: 1.0521 Loss_G: 5.5027\n",
            "[2/25][619/782] Loss_D: 0.9589 Loss_G: 1.9560\n",
            "[2/25][620/782] Loss_D: 0.6017 Loss_G: 3.3620\n",
            "[2/25][621/782] Loss_D: 0.5937 Loss_G: 3.4226\n",
            "[2/25][622/782] Loss_D: 0.7980 Loss_G: 2.3018\n",
            "[2/25][623/782] Loss_D: 1.0293 Loss_G: 3.5434\n",
            "[2/25][624/782] Loss_D: 0.8358 Loss_G: 2.3149\n",
            "[2/25][625/782] Loss_D: 0.8458 Loss_G: 3.8304\n",
            "[2/25][626/782] Loss_D: 0.7759 Loss_G: 2.3947\n",
            "[2/25][627/782] Loss_D: 0.6497 Loss_G: 3.7801\n",
            "[2/25][628/782] Loss_D: 0.4223 Loss_G: 3.0479\n",
            "[2/25][629/782] Loss_D: 0.4673 Loss_G: 3.9965\n",
            "[2/25][630/782] Loss_D: 0.5890 Loss_G: 2.4727\n",
            "[2/25][631/782] Loss_D: 0.5977 Loss_G: 4.0757\n",
            "[2/25][632/782] Loss_D: 0.6473 Loss_G: 2.4884\n",
            "[2/25][633/782] Loss_D: 0.5743 Loss_G: 4.1262\n",
            "[2/25][634/782] Loss_D: 0.6521 Loss_G: 2.2187\n",
            "[2/25][635/782] Loss_D: 0.6374 Loss_G: 3.4098\n",
            "[2/25][636/782] Loss_D: 0.5190 Loss_G: 3.3978\n",
            "[2/25][637/782] Loss_D: 0.3892 Loss_G: 4.0209\n",
            "[2/25][638/782] Loss_D: 0.4725 Loss_G: 2.7289\n",
            "[2/25][639/782] Loss_D: 0.8531 Loss_G: 1.6408\n",
            "[2/25][640/782] Loss_D: 0.6789 Loss_G: 5.5108\n",
            "[2/25][641/782] Loss_D: 0.6776 Loss_G: 2.2812\n",
            "[2/25][642/782] Loss_D: 0.8109 Loss_G: 5.2949\n",
            "[2/25][643/782] Loss_D: 0.6034 Loss_G: 2.6648\n",
            "[2/25][644/782] Loss_D: 0.4918 Loss_G: 3.1688\n",
            "[2/25][645/782] Loss_D: 0.4901 Loss_G: 4.5000\n",
            "[2/25][646/782] Loss_D: 0.7840 Loss_G: 1.3010\n",
            "[2/25][647/782] Loss_D: 1.8344 Loss_G: 9.2237\n",
            "[2/25][648/782] Loss_D: 2.3312 Loss_G: 3.8205\n",
            "[2/25][649/782] Loss_D: 0.6452 Loss_G: 1.8268\n",
            "[2/25][650/782] Loss_D: 1.1619 Loss_G: 5.4938\n",
            "[2/25][651/782] Loss_D: 2.6751 Loss_G: 0.1081\n",
            "[2/25][652/782] Loss_D: 3.0176 Loss_G: 3.8813\n",
            "[2/25][653/782] Loss_D: 1.1023 Loss_G: 2.7101\n",
            "[2/25][654/782] Loss_D: 1.1811 Loss_G: 0.8616\n",
            "[2/25][655/782] Loss_D: 1.7013 Loss_G: 3.3706\n",
            "[2/25][656/782] Loss_D: 0.8800 Loss_G: 2.7103\n",
            "[2/25][657/782] Loss_D: 0.7770 Loss_G: 1.9720\n",
            "[2/25][658/782] Loss_D: 0.7984 Loss_G: 2.6799\n",
            "[2/25][659/782] Loss_D: 0.9353 Loss_G: 2.6623\n",
            "[2/25][660/782] Loss_D: 0.8772 Loss_G: 1.9493\n",
            "[2/25][661/782] Loss_D: 0.9571 Loss_G: 3.3717\n",
            "[2/25][662/782] Loss_D: 0.9905 Loss_G: 1.5965\n",
            "[2/25][663/782] Loss_D: 1.0827 Loss_G: 2.9193\n",
            "[2/25][664/782] Loss_D: 0.8450 Loss_G: 2.8158\n",
            "[2/25][665/782] Loss_D: 0.6659 Loss_G: 1.8919\n",
            "[2/25][666/782] Loss_D: 0.8608 Loss_G: 4.6185\n",
            "[2/25][667/782] Loss_D: 1.2986 Loss_G: 1.0414\n",
            "[2/25][668/782] Loss_D: 1.3418 Loss_G: 4.0704\n",
            "[2/25][669/782] Loss_D: 0.3737 Loss_G: 4.1372\n",
            "[2/25][670/782] Loss_D: 1.1857 Loss_G: 0.5514\n",
            "[2/25][671/782] Loss_D: 2.2305 Loss_G: 5.3543\n",
            "[2/25][672/782] Loss_D: 1.4071 Loss_G: 0.9456\n",
            "[2/25][673/782] Loss_D: 0.8534 Loss_G: 4.3944\n",
            "[2/25][674/782] Loss_D: 0.6481 Loss_G: 2.4884\n",
            "[2/25][675/782] Loss_D: 0.3055 Loss_G: 2.6618\n",
            "[2/25][676/782] Loss_D: 0.7854 Loss_G: 3.9754\n",
            "[2/25][677/782] Loss_D: 0.6950 Loss_G: 1.8391\n",
            "[2/25][678/782] Loss_D: 0.6650 Loss_G: 2.6608\n",
            "[2/25][679/782] Loss_D: 0.5860 Loss_G: 4.1442\n",
            "[2/25][680/782] Loss_D: 1.0839 Loss_G: 1.4421\n",
            "[2/25][681/782] Loss_D: 0.9023 Loss_G: 3.1527\n",
            "[2/25][682/782] Loss_D: 0.4826 Loss_G: 2.9370\n",
            "[2/25][683/782] Loss_D: 0.3539 Loss_G: 3.1535\n",
            "[2/25][684/782] Loss_D: 0.2523 Loss_G: 3.3146\n",
            "[2/25][685/782] Loss_D: 0.3026 Loss_G: 3.0329\n",
            "[2/25][686/782] Loss_D: 0.3438 Loss_G: 3.5434\n",
            "[2/25][687/782] Loss_D: 0.3788 Loss_G: 3.1438\n",
            "[2/25][688/782] Loss_D: 0.4314 Loss_G: 2.3869\n",
            "[2/25][689/782] Loss_D: 0.8024 Loss_G: 3.0798\n",
            "[2/25][690/782] Loss_D: 0.5655 Loss_G: 2.4789\n",
            "[2/25][691/782] Loss_D: 0.5074 Loss_G: 2.7216\n",
            "[2/25][692/782] Loss_D: 0.7249 Loss_G: 2.5352\n",
            "[2/25][693/782] Loss_D: 0.5107 Loss_G: 3.2549\n",
            "[2/25][694/782] Loss_D: 0.3682 Loss_G: 3.1947\n",
            "[2/25][695/782] Loss_D: 0.4509 Loss_G: 2.1505\n",
            "[2/25][696/782] Loss_D: 0.8500 Loss_G: 4.3507\n",
            "[2/25][697/782] Loss_D: 0.6806 Loss_G: 2.8058\n",
            "[2/25][698/782] Loss_D: 0.7189 Loss_G: 3.8702\n",
            "[2/25][699/782] Loss_D: 0.5023 Loss_G: 2.2494\n",
            "[2/25][700/782] Loss_D: 0.6029 Loss_G: 4.1499\n",
            "[2/25][701/782] Loss_D: 0.3385 Loss_G: 3.2548\n",
            "[2/25][702/782] Loss_D: 0.4587 Loss_G: 3.0270\n",
            "[2/25][703/782] Loss_D: 0.7805 Loss_G: 2.5562\n",
            "[2/25][704/782] Loss_D: 0.5922 Loss_G: 3.2591\n",
            "[2/25][705/782] Loss_D: 0.4508 Loss_G: 3.2876\n",
            "[2/25][706/782] Loss_D: 0.5049 Loss_G: 3.6205\n",
            "[2/25][707/782] Loss_D: 0.5684 Loss_G: 2.3138\n",
            "[2/25][708/782] Loss_D: 0.4236 Loss_G: 3.4576\n",
            "[2/25][709/782] Loss_D: 0.3698 Loss_G: 3.3370\n",
            "[2/25][710/782] Loss_D: 0.3083 Loss_G: 3.2439\n",
            "[2/25][711/782] Loss_D: 0.3775 Loss_G: 3.6506\n",
            "[2/25][712/782] Loss_D: 0.3938 Loss_G: 2.4730\n",
            "[2/25][713/782] Loss_D: 0.4586 Loss_G: 3.8298\n",
            "[2/25][714/782] Loss_D: 0.3298 Loss_G: 3.7653\n",
            "[2/25][715/782] Loss_D: 0.3254 Loss_G: 3.2093\n",
            "[2/25][716/782] Loss_D: 0.2812 Loss_G: 3.9768\n",
            "[2/25][717/782] Loss_D: 0.5157 Loss_G: 2.1945\n",
            "[2/25][718/782] Loss_D: 0.5582 Loss_G: 4.9228\n",
            "[2/25][719/782] Loss_D: 0.5334 Loss_G: 2.5817\n",
            "[2/25][720/782] Loss_D: 0.4779 Loss_G: 4.4356\n",
            "[2/25][721/782] Loss_D: 0.5264 Loss_G: 2.4106\n",
            "[2/25][722/782] Loss_D: 0.4854 Loss_G: 3.1807\n",
            "[2/25][723/782] Loss_D: 0.3347 Loss_G: 3.8682\n",
            "[2/25][724/782] Loss_D: 0.3397 Loss_G: 2.6711\n",
            "[2/25][725/782] Loss_D: 0.5136 Loss_G: 4.9038\n",
            "[2/25][726/782] Loss_D: 0.5024 Loss_G: 2.4963\n",
            "[2/25][727/782] Loss_D: 0.6975 Loss_G: 3.6668\n",
            "[2/25][728/782] Loss_D: 0.9046 Loss_G: 1.1922\n",
            "[2/25][729/782] Loss_D: 0.9569 Loss_G: 5.7940\n",
            "[2/25][730/782] Loss_D: 0.7602 Loss_G: 2.7913\n",
            "[2/25][731/782] Loss_D: 0.2983 Loss_G: 3.1020\n",
            "[2/25][732/782] Loss_D: 0.3913 Loss_G: 2.9337\n",
            "[2/25][733/782] Loss_D: 0.6928 Loss_G: 4.3579\n",
            "[2/25][734/782] Loss_D: 0.4607 Loss_G: 2.7626\n",
            "[2/25][735/782] Loss_D: 0.3586 Loss_G: 3.7493\n",
            "[2/25][736/782] Loss_D: 0.5608 Loss_G: 2.6516\n",
            "[2/25][737/782] Loss_D: 0.3466 Loss_G: 3.8983\n",
            "[2/25][738/782] Loss_D: 0.2977 Loss_G: 3.1935\n",
            "[2/25][739/782] Loss_D: 0.2709 Loss_G: 3.4826\n",
            "[2/25][740/782] Loss_D: 0.3676 Loss_G: 2.7251\n",
            "[2/25][741/782] Loss_D: 0.5110 Loss_G: 3.5384\n",
            "[2/25][742/782] Loss_D: 0.6321 Loss_G: 1.5664\n",
            "[2/25][743/782] Loss_D: 0.9908 Loss_G: 6.5750\n",
            "[2/25][744/782] Loss_D: 1.2713 Loss_G: 1.7394\n",
            "[2/25][745/782] Loss_D: 1.0468 Loss_G: 6.6872\n",
            "[2/25][746/782] Loss_D: 2.5110 Loss_G: 0.1312\n",
            "[2/25][747/782] Loss_D: 3.0860 Loss_G: 5.9701\n",
            "[2/25][748/782] Loss_D: 2.3277 Loss_G: 1.2076\n",
            "[2/25][749/782] Loss_D: 1.3676 Loss_G: 2.0725\n",
            "[2/25][750/782] Loss_D: 1.1285 Loss_G: 3.1963\n",
            "[2/25][751/782] Loss_D: 1.6236 Loss_G: 0.8859\n",
            "[2/25][752/782] Loss_D: 1.6322 Loss_G: 3.4094\n",
            "[2/25][753/782] Loss_D: 1.2487 Loss_G: 1.6207\n",
            "[2/25][754/782] Loss_D: 1.3659 Loss_G: 2.0059\n",
            "[2/25][755/782] Loss_D: 1.7760 Loss_G: 2.5490\n",
            "[2/25][756/782] Loss_D: 2.1087 Loss_G: 0.5303\n",
            "[2/25][757/782] Loss_D: 1.8913 Loss_G: 4.2724\n",
            "[2/25][758/782] Loss_D: 1.4533 Loss_G: 1.6756\n",
            "[2/25][759/782] Loss_D: 1.1364 Loss_G: 2.8155\n",
            "[2/25][760/782] Loss_D: 0.9873 Loss_G: 3.9312\n",
            "[2/25][761/782] Loss_D: 1.2120 Loss_G: 1.2599\n",
            "[2/25][762/782] Loss_D: 1.1412 Loss_G: 4.3842\n",
            "[2/25][763/782] Loss_D: 0.9969 Loss_G: 1.9236\n",
            "[2/25][764/782] Loss_D: 0.7011 Loss_G: 2.6555\n",
            "[2/25][765/782] Loss_D: 0.7445 Loss_G: 3.6836\n",
            "[2/25][766/782] Loss_D: 0.6302 Loss_G: 2.4257\n",
            "[2/25][767/782] Loss_D: 0.6300 Loss_G: 3.2026\n",
            "[2/25][768/782] Loss_D: 1.2569 Loss_G: 2.5196\n",
            "[2/25][769/782] Loss_D: 0.8841 Loss_G: 3.9655\n",
            "[2/25][770/782] Loss_D: 0.7122 Loss_G: 2.2467\n",
            "[2/25][771/782] Loss_D: 0.7495 Loss_G: 3.2826\n",
            "[2/25][772/782] Loss_D: 0.7822 Loss_G: 2.3119\n",
            "[2/25][773/782] Loss_D: 0.9448 Loss_G: 3.5846\n",
            "[2/25][774/782] Loss_D: 1.2472 Loss_G: 1.0592\n",
            "[2/25][775/782] Loss_D: 1.4599 Loss_G: 5.3383\n",
            "[2/25][776/782] Loss_D: 1.2200 Loss_G: 1.3656\n",
            "[2/25][777/782] Loss_D: 1.0545 Loss_G: 4.2004\n",
            "[2/25][778/782] Loss_D: 0.6797 Loss_G: 2.8321\n",
            "[2/25][779/782] Loss_D: 0.4976 Loss_G: 2.7600\n",
            "[2/25][780/782] Loss_D: 0.6684 Loss_G: 3.7438\n",
            "[2/25][781/782] Loss_D: 0.5788 Loss_G: 2.6693\n",
            "[3/25][0/782] Loss_D: 0.5741 Loss_G: 3.1526\n",
            "[3/25][1/782] Loss_D: 0.5783 Loss_G: 2.5775\n",
            "[3/25][2/782] Loss_D: 0.7622 Loss_G: 3.3384\n",
            "[3/25][3/782] Loss_D: 0.5731 Loss_G: 2.5484\n",
            "[3/25][4/782] Loss_D: 0.4412 Loss_G: 2.5934\n",
            "[3/25][5/782] Loss_D: 0.7277 Loss_G: 3.7574\n",
            "[3/25][6/782] Loss_D: 0.6086 Loss_G: 2.8494\n",
            "[3/25][7/782] Loss_D: 0.6398 Loss_G: 2.9747\n",
            "[3/25][8/782] Loss_D: 0.8590 Loss_G: 1.3928\n",
            "[3/25][9/782] Loss_D: 0.8679 Loss_G: 4.4112\n",
            "[3/25][10/782] Loss_D: 1.0207 Loss_G: 1.4018\n",
            "[3/25][11/782] Loss_D: 0.8467 Loss_G: 4.5560\n",
            "[3/25][12/782] Loss_D: 0.5688 Loss_G: 2.8487\n",
            "[3/25][13/782] Loss_D: 0.4979 Loss_G: 2.7095\n",
            "[3/25][14/782] Loss_D: 0.4405 Loss_G: 3.7331\n",
            "[3/25][15/782] Loss_D: 0.5797 Loss_G: 2.4112\n",
            "[3/25][16/782] Loss_D: 0.6043 Loss_G: 3.8134\n",
            "[3/25][17/782] Loss_D: 0.6919 Loss_G: 1.8509\n",
            "[3/25][18/782] Loss_D: 0.6058 Loss_G: 4.1143\n",
            "[3/25][19/782] Loss_D: 0.5735 Loss_G: 2.7680\n",
            "[3/25][20/782] Loss_D: 0.4156 Loss_G: 3.0871\n",
            "[3/25][21/782] Loss_D: 0.4780 Loss_G: 2.6017\n",
            "[3/25][22/782] Loss_D: 0.4763 Loss_G: 2.8304\n",
            "[3/25][23/782] Loss_D: 0.5971 Loss_G: 2.9637\n",
            "[3/25][24/782] Loss_D: 0.6267 Loss_G: 2.1198\n",
            "[3/25][25/782] Loss_D: 0.6834 Loss_G: 3.7754\n",
            "[3/25][26/782] Loss_D: 0.6996 Loss_G: 2.2435\n",
            "[3/25][27/782] Loss_D: 0.4134 Loss_G: 3.8825\n",
            "[3/25][28/782] Loss_D: 0.3642 Loss_G: 3.1282\n",
            "[3/25][29/782] Loss_D: 0.5363 Loss_G: 3.0440\n",
            "[3/25][30/782] Loss_D: 0.5181 Loss_G: 3.5803\n",
            "[3/25][31/782] Loss_D: 0.6105 Loss_G: 1.0740\n",
            "[3/25][32/782] Loss_D: 1.2440 Loss_G: 6.1849\n",
            "[3/25][33/782] Loss_D: 1.5782 Loss_G: 0.2220\n",
            "[3/25][34/782] Loss_D: 2.5638 Loss_G: 5.6165\n",
            "[3/25][35/782] Loss_D: 1.9083 Loss_G: 1.8419\n",
            "[3/25][36/782] Loss_D: 1.0363 Loss_G: 1.4194\n",
            "[3/25][37/782] Loss_D: 0.7856 Loss_G: 3.9071\n",
            "[3/25][38/782] Loss_D: 0.8214 Loss_G: 2.5976\n",
            "[3/25][39/782] Loss_D: 0.8499 Loss_G: 1.2434\n",
            "[3/25][40/782] Loss_D: 1.3164 Loss_G: 4.3026\n",
            "[3/25][41/782] Loss_D: 1.5149 Loss_G: 0.8496\n",
            "[3/25][42/782] Loss_D: 1.4753 Loss_G: 4.1251\n",
            "[3/25][43/782] Loss_D: 1.1686 Loss_G: 2.0123\n",
            "[3/25][44/782] Loss_D: 0.8268 Loss_G: 4.3647\n",
            "[3/25][45/782] Loss_D: 0.9861 Loss_G: 1.7623\n",
            "[3/25][46/782] Loss_D: 0.9890 Loss_G: 3.9616\n",
            "[3/25][47/782] Loss_D: 0.6535 Loss_G: 2.5697\n",
            "[3/25][48/782] Loss_D: 0.6717 Loss_G: 2.8712\n",
            "[3/25][49/782] Loss_D: 0.6012 Loss_G: 4.1989\n",
            "[3/25][50/782] Loss_D: 0.7115 Loss_G: 2.6080\n",
            "[3/25][51/782] Loss_D: 0.5702 Loss_G: 3.4308\n",
            "[3/25][52/782] Loss_D: 0.3739 Loss_G: 3.9742\n",
            "[3/25][53/782] Loss_D: 0.6424 Loss_G: 2.2323\n",
            "[3/25][54/782] Loss_D: 0.6457 Loss_G: 3.5093\n",
            "[3/25][55/782] Loss_D: 0.3762 Loss_G: 2.7830\n",
            "[3/25][56/782] Loss_D: 0.5243 Loss_G: 3.4356\n",
            "[3/25][57/782] Loss_D: 0.5490 Loss_G: 2.5342\n",
            "[3/25][58/782] Loss_D: 0.4637 Loss_G: 3.0295\n",
            "[3/25][59/782] Loss_D: 0.5206 Loss_G: 3.0842\n",
            "[3/25][60/782] Loss_D: 0.3683 Loss_G: 3.0630\n",
            "[3/25][61/782] Loss_D: 0.3744 Loss_G: 2.9338\n",
            "[3/25][62/782] Loss_D: 0.3639 Loss_G: 2.7255\n",
            "[3/25][63/782] Loss_D: 0.6782 Loss_G: 2.8431\n",
            "[3/25][64/782] Loss_D: 0.5260 Loss_G: 4.0994\n",
            "[3/25][65/782] Loss_D: 1.1757 Loss_G: 1.0075\n",
            "[3/25][66/782] Loss_D: 1.2709 Loss_G: 3.8410\n",
            "[3/25][67/782] Loss_D: 0.6353 Loss_G: 4.2875\n",
            "[3/25][68/782] Loss_D: 0.4747 Loss_G: 3.0372\n",
            "[3/25][69/782] Loss_D: 0.4437 Loss_G: 4.0136\n",
            "[3/25][70/782] Loss_D: 0.5634 Loss_G: 3.7928\n",
            "[3/25][71/782] Loss_D: 0.9037 Loss_G: 1.4819\n",
            "[3/25][72/782] Loss_D: 0.9625 Loss_G: 4.6771\n",
            "[3/25][73/782] Loss_D: 0.6530 Loss_G: 2.5627\n",
            "[3/25][74/782] Loss_D: 0.4627 Loss_G: 3.0222\n",
            "[3/25][75/782] Loss_D: 0.3330 Loss_G: 4.2316\n",
            "[3/25][76/782] Loss_D: 0.7303 Loss_G: 1.5475\n",
            "[3/25][77/782] Loss_D: 1.0087 Loss_G: 5.4206\n",
            "[3/25][78/782] Loss_D: 1.0440 Loss_G: 1.5170\n",
            "[3/25][79/782] Loss_D: 0.6898 Loss_G: 3.5517\n",
            "[3/25][80/782] Loss_D: 0.6644 Loss_G: 3.0750\n",
            "[3/25][81/782] Loss_D: 0.4297 Loss_G: 2.3843\n",
            "[3/25][82/782] Loss_D: 0.7397 Loss_G: 5.2338\n",
            "[3/25][83/782] Loss_D: 0.7256 Loss_G: 2.0722\n",
            "[3/25][84/782] Loss_D: 0.6902 Loss_G: 5.2189\n",
            "[3/25][85/782] Loss_D: 0.9075 Loss_G: 1.2344\n",
            "[3/25][86/782] Loss_D: 0.9598 Loss_G: 5.6042\n",
            "[3/25][87/782] Loss_D: 0.8945 Loss_G: 2.3350\n",
            "[3/25][88/782] Loss_D: 0.4547 Loss_G: 3.8401\n",
            "[3/25][89/782] Loss_D: 0.4708 Loss_G: 3.9446\n",
            "[3/25][90/782] Loss_D: 0.4787 Loss_G: 2.6386\n",
            "[3/25][91/782] Loss_D: 0.6043 Loss_G: 3.4331\n",
            "[3/25][92/782] Loss_D: 0.6428 Loss_G: 2.2702\n",
            "[3/25][93/782] Loss_D: 0.8156 Loss_G: 5.4869\n",
            "[3/25][94/782] Loss_D: 0.6770 Loss_G: 2.1262\n",
            "[3/25][95/782] Loss_D: 0.8717 Loss_G: 3.9542\n",
            "[3/25][96/782] Loss_D: 0.6440 Loss_G: 1.5807\n",
            "[3/25][97/782] Loss_D: 0.5676 Loss_G: 4.3841\n",
            "[3/25][98/782] Loss_D: 0.6598 Loss_G: 1.6371\n",
            "[3/25][99/782] Loss_D: 1.0863 Loss_G: 5.6735\n",
            "[3/25][100/782] Loss_D: 0.6466 Loss_G: 1.4926\n",
            "[3/25][101/782] Loss_D: 0.6542 Loss_G: 4.8762\n",
            "[3/25][102/782] Loss_D: 0.8935 Loss_G: 1.6977\n",
            "[3/25][103/782] Loss_D: 0.9986 Loss_G: 3.9804\n",
            "[3/25][104/782] Loss_D: 1.0089 Loss_G: 1.3771\n",
            "[3/25][105/782] Loss_D: 1.3387 Loss_G: 4.3786\n",
            "[3/25][106/782] Loss_D: 1.2151 Loss_G: 0.7302\n",
            "[3/25][107/782] Loss_D: 1.2506 Loss_G: 5.9994\n",
            "[3/25][108/782] Loss_D: 0.7044 Loss_G: 2.2848\n",
            "[3/25][109/782] Loss_D: 0.3724 Loss_G: 3.1258\n",
            "[3/25][110/782] Loss_D: 0.4483 Loss_G: 3.0946\n",
            "[3/25][111/782] Loss_D: 0.3885 Loss_G: 3.3705\n",
            "[3/25][112/782] Loss_D: 0.3091 Loss_G: 4.1512\n",
            "[3/25][113/782] Loss_D: 0.9834 Loss_G: 1.1218\n",
            "[3/25][114/782] Loss_D: 1.0105 Loss_G: 4.7728\n",
            "[3/25][115/782] Loss_D: 0.5382 Loss_G: 3.0190\n",
            "[3/25][116/782] Loss_D: 0.5268 Loss_G: 1.8855\n",
            "[3/25][117/782] Loss_D: 0.7795 Loss_G: 4.6276\n",
            "[3/25][118/782] Loss_D: 0.7463 Loss_G: 2.2096\n",
            "[3/25][119/782] Loss_D: 0.4583 Loss_G: 2.5412\n",
            "[3/25][120/782] Loss_D: 0.8879 Loss_G: 3.8129\n",
            "[3/25][121/782] Loss_D: 0.9535 Loss_G: 1.4138\n",
            "[3/25][122/782] Loss_D: 0.9638 Loss_G: 4.5486\n",
            "[3/25][123/782] Loss_D: 1.0973 Loss_G: 1.1396\n",
            "[3/25][124/782] Loss_D: 1.3721 Loss_G: 4.4996\n",
            "[3/25][125/782] Loss_D: 0.9429 Loss_G: 1.5375\n",
            "[3/25][126/782] Loss_D: 1.0821 Loss_G: 2.5060\n",
            "[3/25][127/782] Loss_D: 0.8249 Loss_G: 1.7853\n",
            "[3/25][128/782] Loss_D: 0.6811 Loss_G: 3.8927\n",
            "[3/25][129/782] Loss_D: 0.6342 Loss_G: 1.8905\n",
            "[3/25][130/782] Loss_D: 0.6629 Loss_G: 4.0089\n",
            "[3/25][131/782] Loss_D: 0.7769 Loss_G: 1.6556\n",
            "[3/25][132/782] Loss_D: 0.7261 Loss_G: 3.3102\n",
            "[3/25][133/782] Loss_D: 0.3401 Loss_G: 3.3365\n",
            "[3/25][134/782] Loss_D: 0.4786 Loss_G: 1.7284\n",
            "[3/25][135/782] Loss_D: 0.5331 Loss_G: 3.3924\n",
            "[3/25][136/782] Loss_D: 0.3664 Loss_G: 3.1475\n",
            "[3/25][137/782] Loss_D: 0.2825 Loss_G: 2.8327\n",
            "[3/25][138/782] Loss_D: 0.3963 Loss_G: 2.8515\n",
            "[3/25][139/782] Loss_D: 0.4937 Loss_G: 1.8263\n",
            "[3/25][140/782] Loss_D: 0.6590 Loss_G: 3.5848\n",
            "[3/25][141/782] Loss_D: 0.5825 Loss_G: 2.7072\n",
            "[3/25][142/782] Loss_D: 0.3491 Loss_G: 2.8507\n",
            "[3/25][143/782] Loss_D: 0.4590 Loss_G: 2.4744\n",
            "[3/25][144/782] Loss_D: 0.4214 Loss_G: 3.5383\n",
            "[3/25][145/782] Loss_D: 0.5197 Loss_G: 2.0438\n",
            "[3/25][146/782] Loss_D: 0.5032 Loss_G: 2.2710\n",
            "[3/25][147/782] Loss_D: 0.4287 Loss_G: 3.3451\n",
            "[3/25][148/782] Loss_D: 0.4576 Loss_G: 2.5676\n",
            "[3/25][149/782] Loss_D: 0.4737 Loss_G: 2.2151\n",
            "[3/25][150/782] Loss_D: 0.5130 Loss_G: 3.0024\n",
            "[3/25][151/782] Loss_D: 0.3299 Loss_G: 3.2173\n",
            "[3/25][152/782] Loss_D: 0.3606 Loss_G: 2.2781\n",
            "[3/25][153/782] Loss_D: 0.6272 Loss_G: 2.3000\n",
            "[3/25][154/782] Loss_D: 0.4427 Loss_G: 4.0891\n",
            "[3/25][155/782] Loss_D: 0.4725 Loss_G: 2.3890\n",
            "[3/25][156/782] Loss_D: 0.3744 Loss_G: 3.7771\n",
            "[3/25][157/782] Loss_D: 0.5357 Loss_G: 2.0266\n",
            "[3/25][158/782] Loss_D: 0.6015 Loss_G: 4.6759\n",
            "[3/25][159/782] Loss_D: 0.6480 Loss_G: 2.1693\n",
            "[3/25][160/782] Loss_D: 0.6804 Loss_G: 5.0895\n",
            "[3/25][161/782] Loss_D: 0.9041 Loss_G: 0.9668\n",
            "[3/25][162/782] Loss_D: 1.0963 Loss_G: 7.5172\n",
            "[3/25][163/782] Loss_D: 2.5359 Loss_G: 0.8244\n",
            "[3/25][164/782] Loss_D: 1.3238 Loss_G: 5.5657\n",
            "[3/25][165/782] Loss_D: 0.9112 Loss_G: 1.7059\n",
            "[3/25][166/782] Loss_D: 0.7231 Loss_G: 3.8767\n",
            "[3/25][167/782] Loss_D: 0.4693 Loss_G: 2.7548\n",
            "[3/25][168/782] Loss_D: 0.4309 Loss_G: 2.5306\n",
            "[3/25][169/782] Loss_D: 0.6934 Loss_G: 2.7146\n",
            "[3/25][170/782] Loss_D: 0.6265 Loss_G: 2.3976\n",
            "[3/25][171/782] Loss_D: 0.4819 Loss_G: 3.8167\n",
            "[3/25][172/782] Loss_D: 0.7413 Loss_G: 1.1260\n",
            "[3/25][173/782] Loss_D: 0.9395 Loss_G: 5.0146\n",
            "[3/25][174/782] Loss_D: 0.5804 Loss_G: 2.5114\n",
            "[3/25][175/782] Loss_D: 0.5802 Loss_G: 1.8700\n",
            "[3/25][176/782] Loss_D: 0.6595 Loss_G: 5.2626\n",
            "[3/25][177/782] Loss_D: 0.6559 Loss_G: 2.4526\n",
            "[3/25][178/782] Loss_D: 0.6280 Loss_G: 4.4755\n",
            "[3/25][179/782] Loss_D: 0.6343 Loss_G: 1.9723\n",
            "[3/25][180/782] Loss_D: 0.6429 Loss_G: 4.5397\n",
            "[3/25][181/782] Loss_D: 0.5697 Loss_G: 1.8215\n",
            "[3/25][182/782] Loss_D: 0.7479 Loss_G: 3.3807\n",
            "[3/25][183/782] Loss_D: 0.4310 Loss_G: 4.4949\n",
            "[3/25][184/782] Loss_D: 0.6250 Loss_G: 1.7482\n",
            "[3/25][185/782] Loss_D: 0.7358 Loss_G: 5.1618\n",
            "[3/25][186/782] Loss_D: 0.6162 Loss_G: 2.3738\n",
            "[3/25][187/782] Loss_D: 0.4276 Loss_G: 3.6374\n",
            "[3/25][188/782] Loss_D: 0.3512 Loss_G: 3.6931\n",
            "[3/25][189/782] Loss_D: 0.3032 Loss_G: 3.0076\n",
            "[3/25][190/782] Loss_D: 0.3830 Loss_G: 3.9131\n",
            "[3/25][191/782] Loss_D: 0.4124 Loss_G: 3.1591\n",
            "[3/25][192/782] Loss_D: 0.3099 Loss_G: 3.0986\n",
            "[3/25][193/782] Loss_D: 0.3821 Loss_G: 4.3942\n",
            "[3/25][194/782] Loss_D: 0.3431 Loss_G: 2.9754\n",
            "[3/25][195/782] Loss_D: 0.4014 Loss_G: 3.6340\n",
            "[3/25][196/782] Loss_D: 0.4034 Loss_G: 2.7101\n",
            "[3/25][197/782] Loss_D: 0.4377 Loss_G: 4.0017\n",
            "[3/25][198/782] Loss_D: 0.4543 Loss_G: 3.3612\n",
            "[3/25][199/782] Loss_D: 0.4209 Loss_G: 2.7298\n",
            "[3/25][200/782] Loss_D: 0.3955 Loss_G: 3.6819\n",
            "[3/25][201/782] Loss_D: 0.7614 Loss_G: 1.4369\n",
            "[3/25][202/782] Loss_D: 1.0156 Loss_G: 5.5587\n",
            "[3/25][203/782] Loss_D: 0.6757 Loss_G: 2.4373\n",
            "[3/25][204/782] Loss_D: 0.6251 Loss_G: 4.7127\n",
            "[3/25][205/782] Loss_D: 0.6764 Loss_G: 2.0832\n",
            "[3/25][206/782] Loss_D: 1.1021 Loss_G: 5.1784\n",
            "[3/25][207/782] Loss_D: 0.7542 Loss_G: 1.3246\n",
            "[3/25][208/782] Loss_D: 1.1808 Loss_G: 5.0909\n",
            "[3/25][209/782] Loss_D: 2.1166 Loss_G: 0.6336\n",
            "[3/25][210/782] Loss_D: 1.9028 Loss_G: 7.9658\n",
            "[3/25][211/782] Loss_D: 1.5853 Loss_G: 2.4696\n",
            "[3/25][212/782] Loss_D: 0.6109 Loss_G: 2.1809\n",
            "[3/25][213/782] Loss_D: 0.9545 Loss_G: 5.4913\n",
            "[3/25][214/782] Loss_D: 0.6216 Loss_G: 2.4181\n",
            "[3/25][215/782] Loss_D: 0.4508 Loss_G: 2.1990\n",
            "[3/25][216/782] Loss_D: 0.8864 Loss_G: 3.6015\n",
            "[3/25][217/782] Loss_D: 0.7276 Loss_G: 2.4812\n",
            "[3/25][218/782] Loss_D: 0.8405 Loss_G: 6.1841\n",
            "[3/25][219/782] Loss_D: 1.9017 Loss_G: 1.2100\n",
            "[3/25][220/782] Loss_D: 1.1412 Loss_G: 4.8002\n",
            "[3/25][221/782] Loss_D: 0.9798 Loss_G: 1.9851\n",
            "[3/25][222/782] Loss_D: 0.6626 Loss_G: 3.4098\n",
            "[3/25][223/782] Loss_D: 0.7170 Loss_G: 4.0542\n",
            "[3/25][224/782] Loss_D: 0.5083 Loss_G: 2.7855\n",
            "[3/25][225/782] Loss_D: 0.5505 Loss_G: 3.2817\n",
            "[3/25][226/782] Loss_D: 0.4284 Loss_G: 4.4788\n",
            "[3/25][227/782] Loss_D: 0.8077 Loss_G: 1.7403\n",
            "[3/25][228/782] Loss_D: 0.7817 Loss_G: 3.9939\n",
            "[3/25][229/782] Loss_D: 0.3005 Loss_G: 4.0324\n",
            "[3/25][230/782] Loss_D: 0.6782 Loss_G: 1.3575\n",
            "[3/25][231/782] Loss_D: 0.8208 Loss_G: 5.3896\n",
            "[3/25][232/782] Loss_D: 0.4371 Loss_G: 3.2743\n",
            "[3/25][233/782] Loss_D: 0.5530 Loss_G: 2.1982\n",
            "[3/25][234/782] Loss_D: 0.5569 Loss_G: 4.7742\n",
            "[3/25][235/782] Loss_D: 0.5946 Loss_G: 2.5579\n",
            "[3/25][236/782] Loss_D: 0.9499 Loss_G: 5.5396\n",
            "[3/25][237/782] Loss_D: 1.0839 Loss_G: 2.0379\n",
            "[3/25][238/782] Loss_D: 0.8014 Loss_G: 3.9066\n",
            "[3/25][239/782] Loss_D: 0.6303 Loss_G: 2.3358\n",
            "[3/25][240/782] Loss_D: 0.7067 Loss_G: 5.2499\n",
            "[3/25][241/782] Loss_D: 0.9951 Loss_G: 1.4782\n",
            "[3/25][242/782] Loss_D: 1.0101 Loss_G: 6.1011\n",
            "[3/25][243/782] Loss_D: 1.4873 Loss_G: 1.4315\n",
            "[3/25][244/782] Loss_D: 0.9363 Loss_G: 5.8414\n",
            "[3/25][245/782] Loss_D: 1.7949 Loss_G: 0.2739\n",
            "[3/25][246/782] Loss_D: 2.6988 Loss_G: 6.4219\n",
            "[3/25][247/782] Loss_D: 1.2788 Loss_G: 2.4664\n",
            "[3/25][248/782] Loss_D: 0.7619 Loss_G: 2.3530\n",
            "[3/25][249/782] Loss_D: 0.8846 Loss_G: 4.1357\n",
            "[3/25][250/782] Loss_D: 0.9638 Loss_G: 1.7874\n",
            "[3/25][251/782] Loss_D: 1.2219 Loss_G: 5.0604\n",
            "[3/25][252/782] Loss_D: 2.0189 Loss_G: 1.2281\n",
            "[3/25][253/782] Loss_D: 1.1973 Loss_G: 4.5408\n",
            "[3/25][254/782] Loss_D: 0.9242 Loss_G: 2.4856\n",
            "[3/25][255/782] Loss_D: 0.7604 Loss_G: 3.4394\n",
            "[3/25][256/782] Loss_D: 0.3805 Loss_G: 4.0257\n",
            "[3/25][257/782] Loss_D: 0.7281 Loss_G: 1.8602\n",
            "[3/25][258/782] Loss_D: 0.6819 Loss_G: 4.0216\n",
            "[3/25][259/782] Loss_D: 0.5111 Loss_G: 3.1962\n",
            "[3/25][260/782] Loss_D: 0.4429 Loss_G: 2.0400\n",
            "[3/25][261/782] Loss_D: 0.5545 Loss_G: 3.3660\n",
            "[3/25][262/782] Loss_D: 0.4279 Loss_G: 3.2769\n",
            "[3/25][263/782] Loss_D: 0.4020 Loss_G: 2.5488\n",
            "[3/25][264/782] Loss_D: 0.4551 Loss_G: 2.8265\n",
            "[3/25][265/782] Loss_D: 0.4009 Loss_G: 2.9085\n",
            "[3/25][266/782] Loss_D: 0.3431 Loss_G: 2.9093\n",
            "[3/25][267/782] Loss_D: 0.3360 Loss_G: 3.0068\n",
            "[3/25][268/782] Loss_D: 0.4144 Loss_G: 2.6490\n",
            "[3/25][269/782] Loss_D: 0.3158 Loss_G: 2.9167\n",
            "[3/25][270/782] Loss_D: 0.4506 Loss_G: 3.4827\n",
            "[3/25][271/782] Loss_D: 0.4209 Loss_G: 2.4869\n",
            "[3/25][272/782] Loss_D: 0.4858 Loss_G: 3.6587\n",
            "[3/25][273/782] Loss_D: 0.6229 Loss_G: 2.1509\n",
            "[3/25][274/782] Loss_D: 0.4751 Loss_G: 3.0068\n",
            "[3/25][275/782] Loss_D: 0.3710 Loss_G: 3.2214\n",
            "[3/25][276/782] Loss_D: 0.4100 Loss_G: 3.6303\n",
            "[3/25][277/782] Loss_D: 0.5998 Loss_G: 2.1390\n",
            "[3/25][278/782] Loss_D: 0.6375 Loss_G: 2.4018\n",
            "[3/25][279/782] Loss_D: 0.5345 Loss_G: 3.8008\n",
            "[3/25][280/782] Loss_D: 0.4366 Loss_G: 2.9974\n",
            "[3/25][281/782] Loss_D: 0.4427 Loss_G: 2.5928\n",
            "[3/25][282/782] Loss_D: 0.3013 Loss_G: 3.7859\n",
            "[3/25][283/782] Loss_D: 0.2358 Loss_G: 3.5120\n",
            "[3/25][284/782] Loss_D: 0.4679 Loss_G: 3.3352\n",
            "[3/25][285/782] Loss_D: 0.3157 Loss_G: 3.1148\n",
            "[3/25][286/782] Loss_D: 0.6067 Loss_G: 4.4115\n",
            "[3/25][287/782] Loss_D: 0.6189 Loss_G: 1.7153\n",
            "[3/25][288/782] Loss_D: 0.8096 Loss_G: 6.1485\n",
            "[3/25][289/782] Loss_D: 0.9319 Loss_G: 1.5774\n",
            "[3/25][290/782] Loss_D: 1.0149 Loss_G: 8.6570\n",
            "[3/25][291/782] Loss_D: 4.2015 Loss_G: 1.6104\n",
            "[3/25][292/782] Loss_D: 0.9530 Loss_G: 4.1903\n",
            "[3/25][293/782] Loss_D: 0.6338 Loss_G: 1.9767\n",
            "[3/25][294/782] Loss_D: 0.6431 Loss_G: 3.4926\n",
            "[3/25][295/782] Loss_D: 0.4792 Loss_G: 3.8886\n",
            "[3/25][296/782] Loss_D: 0.7160 Loss_G: 1.5339\n",
            "[3/25][297/782] Loss_D: 0.9956 Loss_G: 4.5645\n",
            "[3/25][298/782] Loss_D: 0.8834 Loss_G: 0.9596\n",
            "[3/25][299/782] Loss_D: 1.3533 Loss_G: 5.8247\n",
            "[3/25][300/782] Loss_D: 1.6633 Loss_G: 0.2563\n",
            "[3/25][301/782] Loss_D: 1.8448 Loss_G: 5.4324\n",
            "[3/25][302/782] Loss_D: 0.8108 Loss_G: 3.6438\n",
            "[3/25][303/782] Loss_D: 0.3274 Loss_G: 2.0765\n",
            "[3/25][304/782] Loss_D: 0.8412 Loss_G: 4.3204\n",
            "[3/25][305/782] Loss_D: 0.7810 Loss_G: 1.6246\n",
            "[3/25][306/782] Loss_D: 0.8899 Loss_G: 4.3630\n",
            "[3/25][307/782] Loss_D: 1.0913 Loss_G: 1.5299\n",
            "[3/25][308/782] Loss_D: 0.9075 Loss_G: 4.0205\n",
            "[3/25][309/782] Loss_D: 0.9814 Loss_G: 2.0999\n",
            "[3/25][310/782] Loss_D: 0.7565 Loss_G: 3.8254\n",
            "[3/25][311/782] Loss_D: 0.7835 Loss_G: 2.0224\n",
            "[3/25][312/782] Loss_D: 0.7155 Loss_G: 3.4656\n",
            "[3/25][313/782] Loss_D: 0.4285 Loss_G: 3.1695\n",
            "[3/25][314/782] Loss_D: 0.4728 Loss_G: 2.5164\n",
            "[3/25][315/782] Loss_D: 0.7541 Loss_G: 3.1635\n",
            "[3/25][316/782] Loss_D: 0.6641 Loss_G: 2.3217\n",
            "[3/25][317/782] Loss_D: 0.6232 Loss_G: 3.2074\n",
            "[3/25][318/782] Loss_D: 0.6923 Loss_G: 2.5170\n",
            "[3/25][319/782] Loss_D: 0.7639 Loss_G: 3.7169\n",
            "[3/25][320/782] Loss_D: 0.5026 Loss_G: 2.5484\n",
            "[3/25][321/782] Loss_D: 0.3679 Loss_G: 2.9682\n",
            "[3/25][322/782] Loss_D: 0.4564 Loss_G: 3.5317\n",
            "[3/25][323/782] Loss_D: 0.4958 Loss_G: 2.9113\n",
            "[3/25][324/782] Loss_D: 0.4713 Loss_G: 2.3457\n",
            "[3/25][325/782] Loss_D: 0.4396 Loss_G: 3.6146\n",
            "[3/25][326/782] Loss_D: 0.5254 Loss_G: 2.4478\n",
            "[3/25][327/782] Loss_D: 0.3622 Loss_G: 3.4963\n",
            "[3/25][328/782] Loss_D: 0.3800 Loss_G: 3.7720\n",
            "[3/25][329/782] Loss_D: 0.3193 Loss_G: 3.0525\n",
            "[3/25][330/782] Loss_D: 0.3287 Loss_G: 2.2737\n",
            "[3/25][331/782] Loss_D: 0.5113 Loss_G: 4.4711\n",
            "[3/25][332/782] Loss_D: 0.5888 Loss_G: 2.0989\n",
            "[3/25][333/782] Loss_D: 0.5960 Loss_G: 4.9309\n",
            "[3/25][334/782] Loss_D: 0.5935 Loss_G: 2.4598\n",
            "[3/25][335/782] Loss_D: 0.3625 Loss_G: 2.9343\n",
            "[3/25][336/782] Loss_D: 0.4400 Loss_G: 2.6725\n",
            "[3/25][337/782] Loss_D: 0.6922 Loss_G: 4.9388\n",
            "[3/25][338/782] Loss_D: 1.5313 Loss_G: 0.7650\n",
            "[3/25][339/782] Loss_D: 1.5639 Loss_G: 5.4682\n",
            "[3/25][340/782] Loss_D: 1.0603 Loss_G: 2.2445\n",
            "[3/25][341/782] Loss_D: 0.7954 Loss_G: 1.9812\n",
            "[3/25][342/782] Loss_D: 0.5274 Loss_G: 4.5838\n",
            "[3/25][343/782] Loss_D: 1.0758 Loss_G: 1.0685\n",
            "[3/25][344/782] Loss_D: 1.1702 Loss_G: 5.4666\n",
            "[3/25][345/782] Loss_D: 0.6680 Loss_G: 3.1507\n",
            "[3/25][346/782] Loss_D: 0.2810 Loss_G: 2.2910\n",
            "[3/25][347/782] Loss_D: 0.4301 Loss_G: 4.3390\n",
            "[3/25][348/782] Loss_D: 0.6457 Loss_G: 1.4298\n",
            "[3/25][349/782] Loss_D: 0.9467 Loss_G: 5.9761\n",
            "[3/25][350/782] Loss_D: 0.9316 Loss_G: 3.0177\n",
            "[3/25][351/782] Loss_D: 0.1933 Loss_G: 2.2073\n",
            "[3/25][352/782] Loss_D: 0.8489 Loss_G: 5.4692\n",
            "[3/25][353/782] Loss_D: 0.9838 Loss_G: 2.3196\n",
            "[3/25][354/782] Loss_D: 0.4247 Loss_G: 3.2802\n",
            "[3/25][355/782] Loss_D: 0.6288 Loss_G: 3.5780\n",
            "[3/25][356/782] Loss_D: 0.3224 Loss_G: 3.2220\n",
            "[3/25][357/782] Loss_D: 0.4418 Loss_G: 2.6556\n",
            "[3/25][358/782] Loss_D: 0.4521 Loss_G: 5.2311\n",
            "[3/25][359/782] Loss_D: 0.5667 Loss_G: 2.4194\n",
            "[3/25][360/782] Loss_D: 0.3754 Loss_G: 3.1954\n",
            "[3/25][361/782] Loss_D: 0.3961 Loss_G: 3.1177\n",
            "[3/25][362/782] Loss_D: 0.5099 Loss_G: 3.1992\n",
            "[3/25][363/782] Loss_D: 0.3776 Loss_G: 3.0542\n",
            "[3/25][364/782] Loss_D: 0.5809 Loss_G: 4.1763\n",
            "[3/25][365/782] Loss_D: 0.2990 Loss_G: 3.4358\n",
            "[3/25][366/782] Loss_D: 0.2482 Loss_G: 2.8756\n",
            "[3/25][367/782] Loss_D: 0.6249 Loss_G: 5.0124\n",
            "[3/25][368/782] Loss_D: 0.5657 Loss_G: 3.0640\n",
            "[3/25][369/782] Loss_D: 0.4074 Loss_G: 3.3915\n",
            "[3/25][370/782] Loss_D: 0.4612 Loss_G: 3.1796\n",
            "[3/25][371/782] Loss_D: 0.3487 Loss_G: 4.4647\n",
            "[3/25][372/782] Loss_D: 0.3618 Loss_G: 2.8782\n",
            "[3/25][373/782] Loss_D: 0.4414 Loss_G: 5.1246\n",
            "[3/25][374/782] Loss_D: 0.5732 Loss_G: 2.9730\n",
            "[3/25][375/782] Loss_D: 0.5412 Loss_G: 5.2946\n",
            "[3/25][376/782] Loss_D: 0.6398 Loss_G: 2.3324\n",
            "[3/25][377/782] Loss_D: 0.8113 Loss_G: 6.4278\n",
            "[3/25][378/782] Loss_D: 1.0134 Loss_G: 2.6147\n",
            "[3/25][379/782] Loss_D: 0.7529 Loss_G: 5.7211\n",
            "[3/25][380/782] Loss_D: 1.4277 Loss_G: 0.6347\n",
            "[3/25][381/782] Loss_D: 1.9302 Loss_G: 7.4083\n",
            "[3/25][382/782] Loss_D: 0.8550 Loss_G: 4.5517\n",
            "[3/25][383/782] Loss_D: 0.3674 Loss_G: 2.0097\n",
            "[3/25][384/782] Loss_D: 0.9861 Loss_G: 6.1608\n",
            "[3/25][385/782] Loss_D: 1.1954 Loss_G: 1.3838\n",
            "[3/25][386/782] Loss_D: 1.9623 Loss_G: 5.1796\n",
            "[3/25][387/782] Loss_D: 2.0075 Loss_G: 0.9486\n",
            "[3/25][388/782] Loss_D: 1.6407 Loss_G: 5.8350\n",
            "[3/25][389/782] Loss_D: 0.5053 Loss_G: 3.6625\n",
            "[3/25][390/782] Loss_D: 0.2227 Loss_G: 2.8156\n",
            "[3/25][391/782] Loss_D: 0.7188 Loss_G: 4.9513\n",
            "[3/25][392/782] Loss_D: 0.6006 Loss_G: 2.8077\n",
            "[3/25][393/782] Loss_D: 0.3908 Loss_G: 2.9081\n",
            "[3/25][394/782] Loss_D: 0.6293 Loss_G: 3.8617\n",
            "[3/25][395/782] Loss_D: 0.5698 Loss_G: 2.3200\n",
            "[3/25][396/782] Loss_D: 0.5846 Loss_G: 4.0760\n",
            "[3/25][397/782] Loss_D: 0.8007 Loss_G: 1.6926\n",
            "[3/25][398/782] Loss_D: 0.8668 Loss_G: 4.8324\n",
            "[3/25][399/782] Loss_D: 0.7004 Loss_G: 2.7347\n",
            "[3/25][400/782] Loss_D: 0.4737 Loss_G: 2.8574\n",
            "[3/25][401/782] Loss_D: 0.3047 Loss_G: 3.9899\n",
            "[3/25][402/782] Loss_D: 0.4466 Loss_G: 2.6219\n",
            "[3/25][403/782] Loss_D: 0.3686 Loss_G: 4.5815\n",
            "[3/25][404/782] Loss_D: 0.5578 Loss_G: 2.3163\n",
            "[3/25][405/782] Loss_D: 0.4481 Loss_G: 3.8880\n",
            "[3/25][406/782] Loss_D: 0.3465 Loss_G: 3.4244\n",
            "[3/25][407/782] Loss_D: 0.2406 Loss_G: 3.2964\n",
            "[3/25][408/782] Loss_D: 0.3607 Loss_G: 3.6138\n",
            "[3/25][409/782] Loss_D: 0.5757 Loss_G: 1.6872\n",
            "[3/25][410/782] Loss_D: 1.1180 Loss_G: 5.5228\n",
            "[3/25][411/782] Loss_D: 1.1948 Loss_G: 1.4827\n",
            "[3/25][412/782] Loss_D: 0.4894 Loss_G: 4.1939\n",
            "[3/25][413/782] Loss_D: 0.5664 Loss_G: 2.0918\n",
            "[3/25][414/782] Loss_D: 0.4304 Loss_G: 3.4172\n",
            "[3/25][415/782] Loss_D: 0.3190 Loss_G: 2.9771\n",
            "[3/25][416/782] Loss_D: 0.1945 Loss_G: 3.2901\n",
            "[3/25][417/782] Loss_D: 0.3191 Loss_G: 3.3527\n",
            "[3/25][418/782] Loss_D: 0.1798 Loss_G: 3.6413\n",
            "[3/25][419/782] Loss_D: 0.2494 Loss_G: 2.7931\n",
            "[3/25][420/782] Loss_D: 0.2420 Loss_G: 3.2992\n",
            "[3/25][421/782] Loss_D: 0.4228 Loss_G: 2.6815\n",
            "[3/25][422/782] Loss_D: 0.4258 Loss_G: 3.4400\n",
            "[3/25][423/782] Loss_D: 0.4896 Loss_G: 2.1081\n",
            "[3/25][424/782] Loss_D: 0.4942 Loss_G: 3.7223\n",
            "[3/25][425/782] Loss_D: 0.3140 Loss_G: 3.4774\n",
            "[3/25][426/782] Loss_D: 0.2311 Loss_G: 2.5337\n",
            "[3/25][427/782] Loss_D: 0.2445 Loss_G: 3.2130\n",
            "[3/25][428/782] Loss_D: 0.2861 Loss_G: 3.7397\n",
            "[3/25][429/782] Loss_D: 0.3666 Loss_G: 2.4393\n",
            "[3/25][430/782] Loss_D: 0.3622 Loss_G: 3.6282\n",
            "[3/25][431/782] Loss_D: 0.2531 Loss_G: 3.6127\n",
            "[3/25][432/782] Loss_D: 0.3135 Loss_G: 2.1468\n",
            "[3/25][433/782] Loss_D: 0.7289 Loss_G: 6.1663\n",
            "[3/25][434/782] Loss_D: 1.1945 Loss_G: 2.6616\n",
            "[3/25][435/782] Loss_D: 0.3145 Loss_G: 3.0673\n",
            "[3/25][436/782] Loss_D: 0.4084 Loss_G: 5.4981\n",
            "[3/25][437/782] Loss_D: 1.2463 Loss_G: 0.5609\n",
            "[3/25][438/782] Loss_D: 2.0843 Loss_G: 8.4476\n",
            "[3/25][439/782] Loss_D: 4.0292 Loss_G: 1.0469\n",
            "[3/25][440/782] Loss_D: 0.9924 Loss_G: 2.6229\n",
            "[3/25][441/782] Loss_D: 0.9545 Loss_G: 2.8247\n",
            "[3/25][442/782] Loss_D: 0.6032 Loss_G: 2.3959\n",
            "[3/25][443/782] Loss_D: 1.0200 Loss_G: 1.6896\n",
            "[3/25][444/782] Loss_D: 1.0108 Loss_G: 3.6869\n",
            "[3/25][445/782] Loss_D: 1.2640 Loss_G: 0.8094\n",
            "[3/25][446/782] Loss_D: 1.3390 Loss_G: 5.9990\n",
            "[3/25][447/782] Loss_D: 1.8880 Loss_G: 1.0594\n",
            "[3/25][448/782] Loss_D: 1.5461 Loss_G: 4.5272\n",
            "[3/25][449/782] Loss_D: 0.6762 Loss_G: 2.7326\n",
            "[3/25][450/782] Loss_D: 0.5388 Loss_G: 3.8784\n",
            "[3/25][451/782] Loss_D: 0.4766 Loss_G: 2.8520\n",
            "[3/25][452/782] Loss_D: 0.6819 Loss_G: 2.8932\n",
            "[3/25][453/782] Loss_D: 0.7584 Loss_G: 3.6863\n",
            "[3/25][454/782] Loss_D: 0.8609 Loss_G: 1.4260\n",
            "[3/25][455/782] Loss_D: 0.9806 Loss_G: 5.4363\n",
            "[3/25][456/782] Loss_D: 0.5601 Loss_G: 2.9436\n",
            "[3/25][457/782] Loss_D: 0.6084 Loss_G: 2.5296\n",
            "[3/25][458/782] Loss_D: 0.6160 Loss_G: 4.7496\n",
            "[3/25][459/782] Loss_D: 0.9371 Loss_G: 1.3311\n",
            "[3/25][460/782] Loss_D: 1.2564 Loss_G: 6.2845\n",
            "[3/25][461/782] Loss_D: 2.1198 Loss_G: 1.1494\n",
            "[3/25][462/782] Loss_D: 1.1160 Loss_G: 5.5520\n",
            "[3/25][463/782] Loss_D: 1.1268 Loss_G: 1.3965\n",
            "[3/25][464/782] Loss_D: 1.6102 Loss_G: 5.0335\n",
            "[3/25][466/782] Loss_D: 0.6651 Loss_G: 3.2748\n",
            "[3/25][467/782] Loss_D: 0.5527 Loss_G: 3.6889\n",
            "[3/25][468/782] Loss_D: 0.5964 Loss_G: 2.1905\n",
            "[3/25][469/782] Loss_D: 0.6001 Loss_G: 3.8564\n",
            "[3/25][470/782] Loss_D: 0.6417 Loss_G: 2.7001\n",
            "[3/25][471/782] Loss_D: 0.5142 Loss_G: 2.9236\n",
            "[3/25][472/782] Loss_D: 0.5502 Loss_G: 2.0093\n",
            "[3/25][473/782] Loss_D: 0.9506 Loss_G: 5.3224\n",
            "[3/25][474/782] Loss_D: 1.3524 Loss_G: 1.3327\n",
            "[3/25][475/782] Loss_D: 0.9403 Loss_G: 4.5004\n",
            "[3/25][476/782] Loss_D: 1.1362 Loss_G: 1.1721\n",
            "[3/25][477/782] Loss_D: 0.9544 Loss_G: 4.0497\n",
            "[3/25][478/782] Loss_D: 0.8168 Loss_G: 2.7138\n",
            "[3/25][479/782] Loss_D: 0.7918 Loss_G: 4.8502\n",
            "[3/25][480/782] Loss_D: 0.5556 Loss_G: 2.7198\n",
            "[3/25][481/782] Loss_D: 0.5484 Loss_G: 2.5421\n",
            "[3/25][482/782] Loss_D: 0.4536 Loss_G: 3.7805\n",
            "[3/25][483/782] Loss_D: 0.6088 Loss_G: 2.2151\n",
            "[3/25][484/782] Loss_D: 0.4703 Loss_G: 3.7335\n",
            "[3/25][485/782] Loss_D: 0.3273 Loss_G: 3.5489\n",
            "[3/25][486/782] Loss_D: 0.5281 Loss_G: 1.8158\n",
            "[3/25][487/782] Loss_D: 0.4381 Loss_G: 3.5941\n",
            "[3/25][488/782] Loss_D: 0.3490 Loss_G: 3.6765\n",
            "[3/25][489/782] Loss_D: 0.3574 Loss_G: 2.4993\n",
            "[3/25][490/782] Loss_D: 0.3192 Loss_G: 3.3377\n",
            "[3/25][491/782] Loss_D: 0.3583 Loss_G: 3.0183\n",
            "[3/25][492/782] Loss_D: 0.2460 Loss_G: 2.9869\n",
            "[3/25][493/782] Loss_D: 0.4315 Loss_G: 3.9530\n",
            "[3/25][494/782] Loss_D: 0.4155 Loss_G: 2.6218\n",
            "[3/25][495/782] Loss_D: 0.4680 Loss_G: 4.1955\n",
            "[3/25][496/782] Loss_D: 0.5284 Loss_G: 2.0874\n",
            "[3/25][497/782] Loss_D: 0.4093 Loss_G: 2.7955\n",
            "[3/25][498/782] Loss_D: 0.5885 Loss_G: 5.1321\n",
            "[3/25][499/782] Loss_D: 0.8555 Loss_G: 1.9592\n",
            "[3/25][500/782] Loss_D: 0.5388 Loss_G: 4.0562\n",
            "[3/25][501/782] Loss_D: 0.4435 Loss_G: 2.2913\n",
            "[3/25][502/782] Loss_D: 0.3811 Loss_G: 3.8142\n",
            "[3/25][503/782] Loss_D: 0.4518 Loss_G: 2.5076\n",
            "[3/25][504/782] Loss_D: 0.3313 Loss_G: 4.1468\n",
            "[3/25][505/782] Loss_D: 0.2650 Loss_G: 3.3967\n",
            "[3/25][506/782] Loss_D: 0.2654 Loss_G: 2.6163\n",
            "[3/25][507/782] Loss_D: 0.4243 Loss_G: 4.3459\n",
            "[3/25][508/782] Loss_D: 0.6275 Loss_G: 1.8276\n",
            "[3/25][509/782] Loss_D: 0.4955 Loss_G: 4.7846\n",
            "[3/25][510/782] Loss_D: 0.5464 Loss_G: 2.5209\n",
            "[3/25][511/782] Loss_D: 0.2536 Loss_G: 3.3229\n",
            "[3/25][512/782] Loss_D: 0.2486 Loss_G: 4.1504\n",
            "[3/25][513/782] Loss_D: 0.1731 Loss_G: 3.9740\n",
            "[3/25][514/782] Loss_D: 0.2484 Loss_G: 2.8051\n",
            "[3/25][515/782] Loss_D: 0.2669 Loss_G: 3.9392\n",
            "[3/25][516/782] Loss_D: 0.2011 Loss_G: 3.6786\n",
            "[3/25][517/782] Loss_D: 0.2004 Loss_G: 2.9632\n",
            "[3/25][518/782] Loss_D: 0.4947 Loss_G: 5.9751\n",
            "[3/25][519/782] Loss_D: 0.5350 Loss_G: 2.9075\n",
            "[3/25][520/782] Loss_D: 0.3548 Loss_G: 2.8969\n",
            "[3/25][521/782] Loss_D: 0.5506 Loss_G: 5.2706\n",
            "[3/25][522/782] Loss_D: 0.6702 Loss_G: 3.3983\n",
            "[3/25][523/782] Loss_D: 1.0555 Loss_G: 7.3484\n",
            "[3/25][524/782] Loss_D: 2.7531 Loss_G: 0.4418\n",
            "[3/25][525/782] Loss_D: 2.1472 Loss_G: 6.7114\n",
            "[3/25][526/782] Loss_D: 1.6150 Loss_G: 0.1720\n",
            "[3/25][527/782] Loss_D: 2.5697 Loss_G: 4.4521\n",
            "[3/25][528/782] Loss_D: 1.3954 Loss_G: 1.6363\n",
            "[3/25][529/782] Loss_D: 0.7639 Loss_G: 1.7769\n",
            "[3/25][530/782] Loss_D: 0.7898 Loss_G: 3.9087\n",
            "[3/25][531/782] Loss_D: 0.6136 Loss_G: 2.5258\n",
            "[3/25][532/782] Loss_D: 1.1311 Loss_G: 1.7813\n",
            "[3/25][533/782] Loss_D: 0.9124 Loss_G: 2.2656\n",
            "[3/25][534/782] Loss_D: 1.7122 Loss_G: 2.9491\n",
            "[3/25][535/782] Loss_D: 0.8934 Loss_G: 2.4767\n",
            "[3/25][536/782] Loss_D: 0.7230 Loss_G: 1.9778\n",
            "[3/25][537/782] Loss_D: 1.1089 Loss_G: 5.4709\n",
            "[3/25][538/782] Loss_D: 2.0190 Loss_G: 1.3376\n",
            "[3/25][539/782] Loss_D: 1.4339 Loss_G: 5.8171\n",
            "[3/25][540/782] Loss_D: 1.3393 Loss_G: 1.2500\n",
            "[3/25][541/782] Loss_D: 0.9644 Loss_G: 5.2156\n",
            "[3/25][542/782] Loss_D: 0.4479 Loss_G: 3.5827\n",
            "[3/25][543/782] Loss_D: 0.9455 Loss_G: 1.6118\n",
            "[3/25][544/782] Loss_D: 1.6100 Loss_G: 8.2972\n",
            "[3/25][545/782] Loss_D: 2.6078 Loss_G: 2.8617\n",
            "[3/25][546/782] Loss_D: 0.5579 Loss_G: 2.8682\n",
            "[3/25][547/782] Loss_D: 1.0378 Loss_G: 5.4560\n",
            "[3/25][548/782] Loss_D: 1.5337 Loss_G: 1.5118\n",
            "[3/25][549/782] Loss_D: 1.5682 Loss_G: 5.4328\n",
            "[3/25][550/782] Loss_D: 0.6829 Loss_G: 3.0841\n",
            "[3/25][551/782] Loss_D: 1.1144 Loss_G: 0.6225\n",
            "[3/25][552/782] Loss_D: 1.7582 Loss_G: 6.4192\n",
            "[3/25][553/782] Loss_D: 1.5440 Loss_G: 0.3877\n",
            "[3/25][554/782] Loss_D: 1.7344 Loss_G: 5.9246\n",
            "[3/25][555/782] Loss_D: 1.2390 Loss_G: 1.8582\n",
            "[3/25][556/782] Loss_D: 0.6395 Loss_G: 3.5065\n",
            "[3/25][557/782] Loss_D: 0.6460 Loss_G: 2.7661\n",
            "[3/25][558/782] Loss_D: 0.9090 Loss_G: 2.6044\n",
            "[3/25][559/782] Loss_D: 1.3013 Loss_G: 1.9602\n",
            "[3/25][560/782] Loss_D: 0.6664 Loss_G: 3.7440\n",
            "[3/25][561/782] Loss_D: 0.5965 Loss_G: 2.5981\n",
            "[3/25][562/782] Loss_D: 0.5771 Loss_G: 2.2062\n",
            "[3/25][563/782] Loss_D: 0.6616 Loss_G: 2.5155\n",
            "[3/25][564/782] Loss_D: 0.6833 Loss_G: 2.3903\n",
            "[3/25][565/782] Loss_D: 0.6371 Loss_G: 2.8591\n",
            "[3/25][566/782] Loss_D: 0.4890 Loss_G: 2.9629\n",
            "[3/25][567/782] Loss_D: 0.6704 Loss_G: 1.7507\n",
            "[3/25][568/782] Loss_D: 0.6848 Loss_G: 4.1530\n",
            "[3/25][569/782] Loss_D: 0.7940 Loss_G: 2.1308\n",
            "[3/25][570/782] Loss_D: 0.6151 Loss_G: 3.5086\n",
            "[3/25][571/782] Loss_D: 0.4052 Loss_G: 3.1266\n",
            "[3/25][572/782] Loss_D: 0.2656 Loss_G: 2.8245\n",
            "[3/25][573/782] Loss_D: 0.6816 Loss_G: 2.9824\n",
            "[3/25][574/782] Loss_D: 0.5439 Loss_G: 3.1135\n",
            "[3/25][575/782] Loss_D: 0.4025 Loss_G: 2.8055\n",
            "[3/25][576/782] Loss_D: 0.5037 Loss_G: 2.7950\n",
            "[3/25][577/782] Loss_D: 0.4388 Loss_G: 2.7042\n",
            "[3/25][578/782] Loss_D: 0.3171 Loss_G: 3.9057\n",
            "[3/25][579/782] Loss_D: 0.6128 Loss_G: 3.3233\n",
            "[3/25][580/782] Loss_D: 0.4089 Loss_G: 2.4945\n",
            "[3/25][581/782] Loss_D: 0.4173 Loss_G: 4.0452\n",
            "[3/25][582/782] Loss_D: 0.5895 Loss_G: 2.1706\n",
            "[3/25][583/782] Loss_D: 0.6558 Loss_G: 5.6409\n",
            "[3/25][584/782] Loss_D: 0.7122 Loss_G: 3.4011\n",
            "[3/25][585/782] Loss_D: 0.3479 Loss_G: 3.6796\n",
            "[3/25][586/782] Loss_D: 0.2623 Loss_G: 3.4123\n",
            "[3/25][587/782] Loss_D: 0.5502 Loss_G: 4.1218\n",
            "[3/25][588/782] Loss_D: 0.3119 Loss_G: 3.4659\n",
            "[3/25][589/782] Loss_D: 0.5796 Loss_G: 1.9543\n",
            "[3/25][590/782] Loss_D: 0.5265 Loss_G: 4.8167\n",
            "[3/25][591/782] Loss_D: 0.2443 Loss_G: 4.2016\n",
            "[3/25][592/782] Loss_D: 0.1205 Loss_G: 3.9514\n",
            "[3/25][593/782] Loss_D: 0.3856 Loss_G: 3.6888\n",
            "[3/25][594/782] Loss_D: 0.2496 Loss_G: 3.3889\n",
            "[3/25][595/782] Loss_D: 0.4559 Loss_G: 4.3061\n",
            "[3/25][596/782] Loss_D: 0.5321 Loss_G: 2.2162\n",
            "[3/25][597/782] Loss_D: 0.2245 Loss_G: 3.3624\n",
            "[3/25][598/782] Loss_D: 0.3393 Loss_G: 4.5227\n",
            "[3/25][599/782] Loss_D: 0.2885 Loss_G: 3.3848\n",
            "[3/25][600/782] Loss_D: 0.2057 Loss_G: 3.6538\n",
            "[3/25][601/782] Loss_D: 0.1694 Loss_G: 4.3505\n",
            "[3/25][602/782] Loss_D: 0.2225 Loss_G: 3.3058\n",
            "[3/25][603/782] Loss_D: 0.2307 Loss_G: 3.1610\n",
            "[3/25][604/782] Loss_D: 0.4460 Loss_G: 3.2608\n",
            "[3/25][605/782] Loss_D: 0.5786 Loss_G: 6.2698\n",
            "[3/25][606/782] Loss_D: 0.7577 Loss_G: 3.1113\n",
            "[3/25][607/782] Loss_D: 0.1634 Loss_G: 2.8257\n",
            "[3/25][608/782] Loss_D: 0.3845 Loss_G: 5.3730\n",
            "[3/25][609/782] Loss_D: 0.6926 Loss_G: 1.6627\n",
            "[3/25][610/782] Loss_D: 0.9369 Loss_G: 7.7086\n",
            "[3/25][611/782] Loss_D: 2.3619 Loss_G: 1.6855\n",
            "[3/25][612/782] Loss_D: 1.1113 Loss_G: 6.7710\n",
            "[3/25][613/782] Loss_D: 1.1566 Loss_G: 1.2236\n",
            "[3/25][614/782] Loss_D: 1.2964 Loss_G: 6.2822\n",
            "[3/25][615/782] Loss_D: 0.8713 Loss_G: 2.5862\n",
            "[3/25][616/782] Loss_D: 0.4186 Loss_G: 3.6364\n",
            "[3/25][617/782] Loss_D: 0.4387 Loss_G: 2.9398\n",
            "[3/25][618/782] Loss_D: 0.6794 Loss_G: 3.7434\n",
            "[3/25][619/782] Loss_D: 0.9105 Loss_G: 1.0610\n",
            "[3/25][620/782] Loss_D: 1.4648 Loss_G: 6.7664\n",
            "[3/25][621/782] Loss_D: 1.4413 Loss_G: 2.8802\n",
            "[3/25][622/782] Loss_D: 0.2631 Loss_G: 1.7949\n",
            "[3/25][623/782] Loss_D: 0.9406 Loss_G: 4.9633\n",
            "[3/25][624/782] Loss_D: 0.6885 Loss_G: 2.9180\n",
            "[3/25][625/782] Loss_D: 0.8344 Loss_G: 2.0479\n",
            "[3/25][626/782] Loss_D: 0.9147 Loss_G: 6.3077\n",
            "[3/25][627/782] Loss_D: 1.2428 Loss_G: 1.1576\n",
            "[3/25][628/782] Loss_D: 0.8070 Loss_G: 5.6011\n",
            "[3/25][629/782] Loss_D: 0.4752 Loss_G: 2.3735\n",
            "[3/25][630/782] Loss_D: 0.5930 Loss_G: 2.7215\n",
            "[3/25][631/782] Loss_D: 0.4785 Loss_G: 4.1579\n",
            "[3/25][632/782] Loss_D: 0.5027 Loss_G: 2.9465\n",
            "[3/25][633/782] Loss_D: 0.4958 Loss_G: 4.0753\n",
            "[3/25][634/782] Loss_D: 0.3831 Loss_G: 3.1836\n",
            "[3/25][635/782] Loss_D: 0.4515 Loss_G: 3.0728\n",
            "[3/25][636/782] Loss_D: 0.3294 Loss_G: 4.0161\n",
            "[3/25][637/782] Loss_D: 0.5005 Loss_G: 2.8958\n",
            "[3/25][638/782] Loss_D: 0.4270 Loss_G: 2.6206\n",
            "[3/25][639/782] Loss_D: 0.3606 Loss_G: 4.0691\n",
            "[3/25][640/782] Loss_D: 0.3895 Loss_G: 3.0873\n",
            "[3/25][641/782] Loss_D: 0.2720 Loss_G: 3.4179\n",
            "[3/25][642/782] Loss_D: 0.3516 Loss_G: 4.3403\n",
            "[3/25][643/782] Loss_D: 0.3215 Loss_G: 3.3431\n",
            "[3/25][644/782] Loss_D: 0.2814 Loss_G: 3.3344\n",
            "[3/25][645/782] Loss_D: 0.2800 Loss_G: 4.0847\n",
            "[3/25][646/782] Loss_D: 0.3163 Loss_G: 3.3690\n",
            "[3/25][647/782] Loss_D: 0.2731 Loss_G: 3.5737\n",
            "[3/25][648/782] Loss_D: 0.2249 Loss_G: 3.6678\n",
            "[3/25][649/782] Loss_D: 0.5041 Loss_G: 4.0006\n",
            "[3/25][650/782] Loss_D: 0.2517 Loss_G: 3.3261\n",
            "[3/25][651/782] Loss_D: 0.4954 Loss_G: 5.8624\n",
            "[3/25][652/782] Loss_D: 0.7383 Loss_G: 2.8636\n",
            "[3/25][653/782] Loss_D: 0.9347 Loss_G: 6.7085\n",
            "[3/25][654/782] Loss_D: 0.9454 Loss_G: 2.6828\n",
            "[3/25][655/782] Loss_D: 0.3064 Loss_G: 4.7048\n",
            "[3/25][656/782] Loss_D: 0.6324 Loss_G: 1.2182\n",
            "[3/25][657/782] Loss_D: 1.2065 Loss_G: 9.1244\n",
            "[3/25][658/782] Loss_D: 1.5701 Loss_G: 2.9900\n",
            "[3/25][659/782] Loss_D: 0.4925 Loss_G: 4.1258\n",
            "[3/25][660/782] Loss_D: 0.4109 Loss_G: 4.1300\n",
            "[3/25][661/782] Loss_D: 1.4061 Loss_G: 0.1384\n",
            "[3/25][662/782] Loss_D: 4.2125 Loss_G: 5.9750\n",
            "[3/25][663/782] Loss_D: 2.1550 Loss_G: 1.5106\n",
            "[3/25][664/782] Loss_D: 1.0918 Loss_G: 4.2121\n",
            "[3/25][665/782] Loss_D: 0.8099 Loss_G: 2.2370\n",
            "[3/25][666/782] Loss_D: 0.7637 Loss_G: 3.1793\n",
            "[3/25][667/782] Loss_D: 0.7068 Loss_G: 2.1004\n",
            "[3/25][668/782] Loss_D: 0.4472 Loss_G: 3.9187\n",
            "[3/25][669/782] Loss_D: 0.4589 Loss_G: 3.5009\n",
            "[3/25][670/782] Loss_D: 0.5150 Loss_G: 2.3261\n",
            "[3/25][671/782] Loss_D: 0.6395 Loss_G: 4.1326\n",
            "[3/25][672/782] Loss_D: 0.3607 Loss_G: 3.6736\n",
            "[3/25][673/782] Loss_D: 0.4364 Loss_G: 2.1492\n",
            "[3/25][674/782] Loss_D: 0.6767 Loss_G: 5.1938\n",
            "[3/25][675/782] Loss_D: 0.3848 Loss_G: 3.5963\n",
            "[3/25][676/782] Loss_D: 0.6452 Loss_G: 1.8210\n",
            "[3/25][677/782] Loss_D: 1.0635 Loss_G: 7.1115\n",
            "[3/25][678/782] Loss_D: 0.9930 Loss_G: 3.5953\n",
            "[3/25][679/782] Loss_D: 0.6029 Loss_G: 2.9296\n",
            "[3/25][680/782] Loss_D: 0.7056 Loss_G: 3.4885\n",
            "[3/25][681/782] Loss_D: 0.5883 Loss_G: 2.5838\n",
            "[3/25][682/782] Loss_D: 0.6777 Loss_G: 6.1124\n",
            "[3/25][683/782] Loss_D: 1.3425 Loss_G: 1.4819\n",
            "[3/25][684/782] Loss_D: 0.9091 Loss_G: 5.2523\n",
            "[3/25][685/782] Loss_D: 0.5405 Loss_G: 2.5764\n",
            "[3/25][686/782] Loss_D: 0.7144 Loss_G: 4.0177\n",
            "[3/25][687/782] Loss_D: 0.5643 Loss_G: 3.0418\n",
            "[3/25][688/782] Loss_D: 0.4481 Loss_G: 4.5119\n",
            "[3/25][689/782] Loss_D: 0.4121 Loss_G: 4.8951\n",
            "[3/25][690/782] Loss_D: 0.2316 Loss_G: 4.3706\n",
            "[3/25][691/782] Loss_D: 0.7875 Loss_G: 1.3955\n",
            "[3/25][692/782] Loss_D: 1.2436 Loss_G: 8.9645\n",
            "[3/25][693/782] Loss_D: 2.0298 Loss_G: 1.0512\n",
            "[3/25][694/782] Loss_D: 2.2179 Loss_G: 6.6033\n",
            "[3/25][695/782] Loss_D: 0.8737 Loss_G: 3.7797\n",
            "[3/25][696/782] Loss_D: 0.5874 Loss_G: 2.9989\n",
            "[3/25][697/782] Loss_D: 0.8675 Loss_G: 6.7279\n",
            "[3/25][698/782] Loss_D: 1.7824 Loss_G: 1.0052\n",
            "[3/25][699/782] Loss_D: 1.5036 Loss_G: 7.1093\n",
            "[3/25][700/782] Loss_D: 3.3084 Loss_G: 0.7165\n",
            "[3/25][701/782] Loss_D: 1.6605 Loss_G: 4.8902\n",
            "[3/25][702/782] Loss_D: 0.6724 Loss_G: 3.3695\n",
            "[3/25][703/782] Loss_D: 0.7233 Loss_G: 2.7490\n",
            "[3/25][704/782] Loss_D: 0.7091 Loss_G: 3.0411\n",
            "[3/25][705/782] Loss_D: 0.5036 Loss_G: 3.8026\n",
            "[3/25][706/782] Loss_D: 0.6322 Loss_G: 2.6735\n",
            "[3/25][707/782] Loss_D: 0.6685 Loss_G: 4.2426\n",
            "[3/25][708/782] Loss_D: 0.8570 Loss_G: 1.8424\n",
            "[3/25][709/782] Loss_D: 0.9841 Loss_G: 4.6585\n",
            "[3/25][710/782] Loss_D: 0.6279 Loss_G: 3.1185\n",
            "[3/25][711/782] Loss_D: 0.4310 Loss_G: 2.3104\n",
            "[3/25][712/782] Loss_D: 0.4772 Loss_G: 2.6430\n",
            "[3/25][713/782] Loss_D: 0.3100 Loss_G: 3.9901\n",
            "[3/25][714/782] Loss_D: 0.3735 Loss_G: 3.3342\n",
            "[3/25][715/782] Loss_D: 0.3413 Loss_G: 2.5332\n",
            "[3/25][716/782] Loss_D: 0.3846 Loss_G: 3.5506\n",
            "[3/25][717/782] Loss_D: 0.5083 Loss_G: 2.8837\n",
            "[3/25][718/782] Loss_D: 0.6434 Loss_G: 2.3685\n",
            "[3/25][719/782] Loss_D: 0.4102 Loss_G: 4.5047\n",
            "[3/25][720/782] Loss_D: 0.6105 Loss_G: 1.9566\n",
            "[3/25][721/782] Loss_D: 0.5332 Loss_G: 4.1459\n",
            "[3/25][722/782] Loss_D: 0.3996 Loss_G: 3.2851\n",
            "[3/25][723/782] Loss_D: 0.2662 Loss_G: 3.5769\n",
            "[3/25][724/782] Loss_D: 0.2275 Loss_G: 3.5255\n",
            "[3/25][725/782] Loss_D: 0.1563 Loss_G: 3.3424\n",
            "[3/25][726/782] Loss_D: 0.3041 Loss_G: 3.2488\n",
            "[3/25][727/782] Loss_D: 0.2062 Loss_G: 3.3279\n",
            "[3/25][728/782] Loss_D: 0.4138 Loss_G: 4.5117\n",
            "[3/25][729/782] Loss_D: 0.5813 Loss_G: 1.6600\n",
            "[3/25][730/782] Loss_D: 0.4515 Loss_G: 4.2815\n",
            "[3/25][731/782] Loss_D: 0.4255 Loss_G: 2.5895\n",
            "[3/25][732/782] Loss_D: 0.2318 Loss_G: 3.3933\n",
            "[3/25][733/782] Loss_D: 0.2854 Loss_G: 3.8071\n",
            "[3/25][734/782] Loss_D: 0.2613 Loss_G: 4.0246\n",
            "[3/25][735/782] Loss_D: 0.5316 Loss_G: 1.9835\n",
            "[3/25][736/782] Loss_D: 0.7902 Loss_G: 6.4455\n",
            "[3/25][737/782] Loss_D: 1.0767 Loss_G: 2.5020\n",
            "[3/25][738/782] Loss_D: 0.5852 Loss_G: 4.7660\n",
            "[3/25][739/782] Loss_D: 1.1083 Loss_G: 0.7676\n",
            "[3/25][740/782] Loss_D: 1.8928 Loss_G: 8.5147\n",
            "[3/25][741/782] Loss_D: 3.9589 Loss_G: 1.9810\n",
            "[3/25][742/782] Loss_D: 1.1580 Loss_G: 0.4849\n",
            "[3/25][743/782] Loss_D: 2.2313 Loss_G: 5.1485\n",
            "[3/25][744/782] Loss_D: 1.8573 Loss_G: 2.1557\n",
            "[3/25][745/782] Loss_D: 0.7804 Loss_G: 1.7686\n",
            "[3/25][746/782] Loss_D: 0.9955 Loss_G: 3.5737\n",
            "[3/25][747/782] Loss_D: 1.1450 Loss_G: 1.3944\n",
            "[3/25][748/782] Loss_D: 1.1377 Loss_G: 2.7238\n",
            "[3/25][749/782] Loss_D: 0.8320 Loss_G: 2.8881\n",
            "[3/25][750/782] Loss_D: 0.7462 Loss_G: 1.8554\n",
            "[3/25][751/782] Loss_D: 0.4148 Loss_G: 2.5246\n",
            "[3/25][752/782] Loss_D: 0.5094 Loss_G: 3.9091\n",
            "[3/25][753/782] Loss_D: 0.6733 Loss_G: 2.0324\n",
            "[3/25][754/782] Loss_D: 0.3190 Loss_G: 2.6844\n",
            "[3/25][755/782] Loss_D: 0.3402 Loss_G: 3.5051\n",
            "[3/25][756/782] Loss_D: 0.3832 Loss_G: 2.8710\n",
            "[3/25][757/782] Loss_D: 0.2974 Loss_G: 2.7302\n",
            "[3/25][758/782] Loss_D: 0.3728 Loss_G: 3.6205\n",
            "[3/25][759/782] Loss_D: 0.5448 Loss_G: 2.2334\n",
            "[3/25][760/782] Loss_D: 0.3254 Loss_G: 2.9340\n",
            "[3/25][761/782] Loss_D: 0.4728 Loss_G: 2.9570\n",
            "[3/25][762/782] Loss_D: 0.2309 Loss_G: 3.3909\n",
            "[3/25][763/782] Loss_D: 0.2406 Loss_G: 3.1846\n",
            "[3/25][764/782] Loss_D: 0.3500 Loss_G: 2.8263\n",
            "[3/25][765/782] Loss_D: 0.3780 Loss_G: 2.5254\n",
            "[3/25][766/782] Loss_D: 0.3092 Loss_G: 3.8911\n",
            "[3/25][767/782] Loss_D: 0.2280 Loss_G: 3.3211\n",
            "[3/25][768/782] Loss_D: 0.4126 Loss_G: 3.5091\n",
            "[3/25][769/782] Loss_D: 0.4400 Loss_G: 3.5831\n",
            "[3/25][770/782] Loss_D: 0.1778 Loss_G: 3.8663\n",
            "[3/25][771/782] Loss_D: 0.2363 Loss_G: 3.2715\n",
            "[3/25][772/782] Loss_D: 0.1280 Loss_G: 3.6470\n",
            "[3/25][773/782] Loss_D: 0.2378 Loss_G: 2.8358\n",
            "[3/25][774/782] Loss_D: 0.7113 Loss_G: 5.8565\n",
            "[3/25][775/782] Loss_D: 1.1903 Loss_G: 1.9291\n",
            "[3/25][776/782] Loss_D: 0.6547 Loss_G: 3.7471\n",
            "[3/25][777/782] Loss_D: 0.9018 Loss_G: 1.2707\n",
            "[3/25][778/782] Loss_D: 1.5589 Loss_G: 7.6883\n",
            "[3/25][779/782] Loss_D: 1.4161 Loss_G: 2.2956\n",
            "[3/25][780/782] Loss_D: 0.5552 Loss_G: 4.3561\n",
            "[3/25][781/782] Loss_D: 0.4889 Loss_G: 4.1961\n",
            "[4/25][0/782] Loss_D: 0.6112 Loss_G: 2.7878\n",
            "[4/25][1/782] Loss_D: 0.5634 Loss_G: 2.6326\n",
            "[4/25][2/782] Loss_D: 0.6844 Loss_G: 6.2724\n",
            "[4/25][3/782] Loss_D: 0.8282 Loss_G: 2.5310\n",
            "[4/25][4/782] Loss_D: 0.2813 Loss_G: 3.7382\n",
            "[4/25][5/782] Loss_D: 0.2007 Loss_G: 3.8775\n",
            "[4/25][6/782] Loss_D: 0.6081 Loss_G: 3.1776\n",
            "[4/25][7/782] Loss_D: 0.2048 Loss_G: 4.0455\n",
            "[4/25][8/782] Loss_D: 0.4202 Loss_G: 2.6820\n",
            "[4/25][9/782] Loss_D: 0.3709 Loss_G: 5.9599\n",
            "[4/25][10/782] Loss_D: 0.4421 Loss_G: 3.0341\n",
            "[4/25][11/782] Loss_D: 0.1993 Loss_G: 3.7633\n",
            "[4/25][12/782] Loss_D: 0.3682 Loss_G: 5.7985\n",
            "[4/25][13/782] Loss_D: 0.6516 Loss_G: 2.0211\n",
            "[4/25][14/782] Loss_D: 0.7273 Loss_G: 6.7802\n",
            "[4/25][15/782] Loss_D: 1.1187 Loss_G: 2.2548\n",
            "[4/25][16/782] Loss_D: 0.4615 Loss_G: 4.7348\n",
            "[4/25][17/782] Loss_D: 1.1667 Loss_G: 0.3421\n",
            "[4/25][18/782] Loss_D: 2.0624 Loss_G: 9.0635\n",
            "[4/25][19/782] Loss_D: 3.9690 Loss_G: 2.1515\n",
            "[4/25][20/782] Loss_D: 0.9468 Loss_G: 2.5622\n",
            "[4/25][21/782] Loss_D: 0.6169 Loss_G: 3.1011\n",
            "[4/25][22/782] Loss_D: 0.4329 Loss_G: 2.6678\n",
            "[4/25][23/782] Loss_D: 0.7691 Loss_G: 3.3437\n",
            "[4/25][24/782] Loss_D: 0.7477 Loss_G: 1.8031\n",
            "[4/25][25/782] Loss_D: 0.7726 Loss_G: 4.2079\n",
            "[4/25][26/782] Loss_D: 0.6915 Loss_G: 1.9149\n",
            "[4/25][27/782] Loss_D: 0.7201 Loss_G: 3.8206\n",
            "[4/25][28/782] Loss_D: 0.3447 Loss_G: 3.4392\n",
            "[4/25][29/782] Loss_D: 0.3957 Loss_G: 2.8362\n",
            "[4/25][30/782] Loss_D: 0.2800 Loss_G: 3.4312\n",
            "[4/25][31/782] Loss_D: 0.5495 Loss_G: 1.8816\n",
            "[4/25][32/782] Loss_D: 0.6939 Loss_G: 4.8462\n",
            "[4/25][33/782] Loss_D: 0.4176 Loss_G: 3.5051\n",
            "[4/25][34/782] Loss_D: 0.5266 Loss_G: 1.6228\n",
            "[4/25][35/782] Loss_D: 0.5006 Loss_G: 3.9714\n",
            "[4/25][36/782] Loss_D: 0.2745 Loss_G: 3.6901\n",
            "[4/25][37/782] Loss_D: 0.3263 Loss_G: 2.6133\n",
            "[4/25][38/782] Loss_D: 0.2775 Loss_G: 3.5289\n",
            "[4/25][39/782] Loss_D: 0.3793 Loss_G: 2.7145\n",
            "[4/25][40/782] Loss_D: 0.3445 Loss_G: 3.9702\n",
            "[4/25][41/782] Loss_D: 0.4667 Loss_G: 2.7332\n",
            "[4/25][42/782] Loss_D: 0.2695 Loss_G: 3.3671\n",
            "[4/25][43/782] Loss_D: 0.2861 Loss_G: 3.4982\n",
            "[4/25][44/782] Loss_D: 0.2390 Loss_G: 3.4525\n",
            "[4/25][45/782] Loss_D: 0.1218 Loss_G: 4.0342\n",
            "[4/25][46/782] Loss_D: 0.1310 Loss_G: 3.7229\n",
            "[4/25][47/782] Loss_D: 0.2394 Loss_G: 3.2540\n",
            "[4/25][48/782] Loss_D: 0.2259 Loss_G: 3.5294\n",
            "[4/25][49/782] Loss_D: 0.2271 Loss_G: 2.8337\n",
            "[4/25][50/782] Loss_D: 0.2616 Loss_G: 4.3653\n",
            "[4/25][51/782] Loss_D: 0.3705 Loss_G: 3.9040\n",
            "[4/25][52/782] Loss_D: 0.2504 Loss_G: 2.7246\n",
            "[4/25][53/782] Loss_D: 0.1934 Loss_G: 3.7106\n",
            "[4/25][54/782] Loss_D: 0.4471 Loss_G: 3.7932\n",
            "[4/25][55/782] Loss_D: 0.1901 Loss_G: 3.3307\n",
            "[4/25][56/782] Loss_D: 0.2322 Loss_G: 3.0831\n",
            "[4/25][57/782] Loss_D: 0.2004 Loss_G: 3.5940\n",
            "[4/25][58/782] Loss_D: 0.1652 Loss_G: 3.3250\n",
            "[4/25][59/782] Loss_D: 0.3586 Loss_G: 4.6724\n",
            "[4/25][60/782] Loss_D: 0.5428 Loss_G: 1.9376\n",
            "[4/25][61/782] Loss_D: 1.0137 Loss_G: 7.4195\n",
            "[4/25][62/782] Loss_D: 2.1736 Loss_G: 3.3829\n",
            "[4/25][63/782] Loss_D: 0.4037 Loss_G: 4.0482\n",
            "[4/25][64/782] Loss_D: 1.1537 Loss_G: 0.1670\n",
            "[4/25][65/782] Loss_D: 3.3715 Loss_G: 9.1822\n",
            "[4/25][66/782] Loss_D: 3.7422 Loss_G: 3.0544\n",
            "[4/25][67/782] Loss_D: 0.4172 Loss_G: 0.5073\n",
            "[4/25][68/782] Loss_D: 2.5512 Loss_G: 5.4481\n",
            "[4/25][69/782] Loss_D: 2.2279 Loss_G: 0.5089\n",
            "[4/25][70/782] Loss_D: 1.7158 Loss_G: 3.8215\n",
            "[4/25][71/782] Loss_D: 0.9661 Loss_G: 2.1677\n",
            "[4/25][72/782] Loss_D: 0.5540 Loss_G: 1.7382\n",
            "[4/25][73/782] Loss_D: 0.9818 Loss_G: 2.8402\n",
            "[4/25][74/782] Loss_D: 0.9116 Loss_G: 1.7753\n",
            "[4/25][75/782] Loss_D: 0.8754 Loss_G: 2.1122\n",
            "[4/25][76/782] Loss_D: 0.6425 Loss_G: 2.6706\n",
            "[4/25][77/782] Loss_D: 0.4818 Loss_G: 2.6580\n",
            "[4/25][78/782] Loss_D: 0.9269 Loss_G: 3.0881\n",
            "[4/25][79/782] Loss_D: 0.8100 Loss_G: 1.5474\n",
            "[4/25][80/782] Loss_D: 0.9617 Loss_G: 4.6345\n",
            "[4/25][81/782] Loss_D: 0.9761 Loss_G: 1.6015\n",
            "[4/25][82/782] Loss_D: 1.1179 Loss_G: 5.2383\n",
            "[4/25][83/782] Loss_D: 1.3792 Loss_G: 0.8717\n",
            "[4/25][84/782] Loss_D: 1.6723 Loss_G: 5.2398\n",
            "[4/25][85/782] Loss_D: 1.4151 Loss_G: 2.1399\n",
            "[4/25][86/782] Loss_D: 0.7231 Loss_G: 2.8639\n",
            "[4/25][87/782] Loss_D: 0.8085 Loss_G: 4.1307\n",
            "[4/25][88/782] Loss_D: 0.7581 Loss_G: 2.3621\n",
            "[4/25][89/782] Loss_D: 0.2567 Loss_G: 2.5854\n",
            "[4/25][90/782] Loss_D: 0.8938 Loss_G: 2.7861\n",
            "[4/25][91/782] Loss_D: 0.6432 Loss_G: 3.5125\n",
            "[4/25][92/782] Loss_D: 0.4020 Loss_G: 3.3515\n",
            "[4/25][93/782] Loss_D: 0.5634 Loss_G: 1.7943\n",
            "[4/25][94/782] Loss_D: 0.6416 Loss_G: 4.8686\n",
            "[4/25][95/782] Loss_D: 0.3530 Loss_G: 3.8081\n",
            "[4/25][96/782] Loss_D: 0.3340 Loss_G: 2.6065\n",
            "[4/25][97/782] Loss_D: 0.3908 Loss_G: 2.8367\n",
            "[4/25][98/782] Loss_D: 0.2916 Loss_G: 3.4009\n",
            "[4/25][99/782] Loss_D: 0.2134 Loss_G: 3.9541\n",
            "[4/25][100/782] Loss_D: 0.2871 Loss_G: 3.2251\n",
            "[4/25][101/782] Loss_D: 0.3513 Loss_G: 3.2284\n",
            "[4/25][102/782] Loss_D: 0.3302 Loss_G: 4.8676\n",
            "[4/25][103/782] Loss_D: 0.2928 Loss_G: 3.7155\n",
            "[4/25][104/782] Loss_D: 0.2538 Loss_G: 3.7907\n",
            "[4/25][105/782] Loss_D: 0.2557 Loss_G: 3.1381\n",
            "[4/25][106/782] Loss_D: 0.1731 Loss_G: 3.5724\n",
            "[4/25][107/782] Loss_D: 0.1593 Loss_G: 3.7494\n",
            "[4/25][108/782] Loss_D: 0.3066 Loss_G: 3.0408\n",
            "[4/25][109/782] Loss_D: 0.4295 Loss_G: 4.3909\n",
            "[4/25][110/782] Loss_D: 0.3075 Loss_G: 3.7860\n",
            "[4/25][111/782] Loss_D: 0.3245 Loss_G: 3.1717\n",
            "[4/25][112/782] Loss_D: 0.1525 Loss_G: 3.4361\n",
            "[4/25][113/782] Loss_D: 0.2574 Loss_G: 3.4908\n",
            "[4/25][114/782] Loss_D: 0.5398 Loss_G: 5.5420\n",
            "[4/25][115/782] Loss_D: 0.4216 Loss_G: 3.8714\n",
            "[4/25][116/782] Loss_D: 0.2592 Loss_G: 3.8905\n",
            "[4/25][117/782] Loss_D: 0.0849 Loss_G: 4.2052\n",
            "[4/25][118/782] Loss_D: 0.2129 Loss_G: 3.1589\n",
            "[4/25][119/782] Loss_D: 0.1692 Loss_G: 3.5642\n",
            "[4/25][120/782] Loss_D: 0.1308 Loss_G: 3.9061\n",
            "[4/25][121/782] Loss_D: 0.2904 Loss_G: 5.2334\n",
            "[4/25][122/782] Loss_D: 0.3301 Loss_G: 4.0059\n",
            "[4/25][123/782] Loss_D: 0.1233 Loss_G: 2.9998\n",
            "[4/25][124/782] Loss_D: 0.4023 Loss_G: 5.7174\n",
            "[4/25][125/782] Loss_D: 0.6946 Loss_G: 2.2657\n",
            "[4/25][126/782] Loss_D: 0.5745 Loss_G: 5.5233\n",
            "[4/25][127/782] Loss_D: 0.8083 Loss_G: 2.2607\n",
            "[4/25][128/782] Loss_D: 0.5611 Loss_G: 6.9349\n",
            "[4/25][129/782] Loss_D: 2.3846 Loss_G: 0.1096\n",
            "[4/25][130/782] Loss_D: 2.7345 Loss_G: 7.6390\n",
            "[4/25][131/782] Loss_D: 3.1782 Loss_G: 1.1697\n",
            "[4/25][132/782] Loss_D: 1.0000 Loss_G: 2.5794\n",
            "[4/25][133/782] Loss_D: 0.7432 Loss_G: 2.8441\n",
            "[4/25][134/782] Loss_D: 0.8481 Loss_G: 1.4069\n",
            "[4/25][135/782] Loss_D: 1.0389 Loss_G: 3.7478\n",
            "[4/25][136/782] Loss_D: 1.4412 Loss_G: 0.9388\n",
            "[4/25][137/782] Loss_D: 1.6917 Loss_G: 4.4475\n",
            "[4/25][138/782] Loss_D: 0.9256 Loss_G: 2.3087\n",
            "[4/25][139/782] Loss_D: 0.6526 Loss_G: 3.8357\n",
            "[4/25][140/782] Loss_D: 0.7028 Loss_G: 2.4313\n",
            "[4/25][141/782] Loss_D: 0.8576 Loss_G: 4.2157\n",
            "[4/25][142/782] Loss_D: 0.5758 Loss_G: 2.1479\n",
            "[4/25][143/782] Loss_D: 0.5007 Loss_G: 3.4683\n",
            "[4/25][144/782] Loss_D: 0.3832 Loss_G: 3.1708\n",
            "[4/25][145/782] Loss_D: 0.5176 Loss_G: 3.0895\n",
            "[4/25][146/782] Loss_D: 0.6811 Loss_G: 2.7061\n",
            "[4/25][147/782] Loss_D: 0.5136 Loss_G: 3.4802\n",
            "[4/25][148/782] Loss_D: 0.4685 Loss_G: 2.5891\n",
            "[4/25][149/782] Loss_D: 0.5598 Loss_G: 3.3684\n",
            "[4/25][150/782] Loss_D: 0.3232 Loss_G: 3.1542\n",
            "[4/25][151/782] Loss_D: 0.2848 Loss_G: 4.1771\n",
            "[4/25][152/782] Loss_D: 0.4462 Loss_G: 2.5734\n",
            "[4/25][153/782] Loss_D: 0.2392 Loss_G: 4.0826\n",
            "[4/25][154/782] Loss_D: 0.2838 Loss_G: 3.7733\n",
            "[4/25][155/782] Loss_D: 0.2760 Loss_G: 2.8928\n",
            "[4/25][156/782] Loss_D: 0.2581 Loss_G: 3.6927\n",
            "[4/25][157/782] Loss_D: 0.1692 Loss_G: 3.8638\n",
            "[4/25][158/782] Loss_D: 0.3634 Loss_G: 4.4357\n",
            "[4/25][159/782] Loss_D: 0.2062 Loss_G: 3.4709\n",
            "[4/25][160/782] Loss_D: 0.1753 Loss_G: 3.1893\n",
            "[4/25][161/782] Loss_D: 0.2465 Loss_G: 3.9521\n",
            "[4/25][162/782] Loss_D: 0.2983 Loss_G: 2.3598\n",
            "[4/25][163/782] Loss_D: 0.5358 Loss_G: 5.3040\n",
            "[4/25][164/782] Loss_D: 0.3476 Loss_G: 2.9206\n",
            "[4/25][165/782] Loss_D: 0.1245 Loss_G: 3.1066\n",
            "[4/25][166/782] Loss_D: 0.3662 Loss_G: 5.4061\n",
            "[4/25][167/782] Loss_D: 0.3909 Loss_G: 2.4815\n",
            "[4/25][168/782] Loss_D: 0.4111 Loss_G: 4.6962\n",
            "[4/25][169/782] Loss_D: 0.3131 Loss_G: 3.4653\n",
            "[4/25][170/782] Loss_D: 0.1604 Loss_G: 2.9877\n",
            "[4/25][171/782] Loss_D: 0.3918 Loss_G: 5.0781\n",
            "[4/25][172/782] Loss_D: 0.3449 Loss_G: 2.8552\n",
            "[4/25][173/782] Loss_D: 0.2842 Loss_G: 2.7946\n",
            "[4/25][174/782] Loss_D: 0.3078 Loss_G: 5.6549\n",
            "[4/25][175/782] Loss_D: 0.2898 Loss_G: 3.5876\n",
            "[4/25][176/782] Loss_D: 0.2146 Loss_G: 2.3547\n",
            "[4/25][177/782] Loss_D: 0.7408 Loss_G: 8.0428\n",
            "[4/25][178/782] Loss_D: 0.9739 Loss_G: 0.8419\n",
            "[4/25][179/782] Loss_D: 1.3867 Loss_G: 9.9265\n",
            "[4/25][180/782] Loss_D: 4.9776 Loss_G: 1.0889\n",
            "[4/25][181/782] Loss_D: 1.4829 Loss_G: 4.4092\n",
            "[4/25][182/782] Loss_D: 1.7405 Loss_G: 0.4186\n",
            "[4/25][183/782] Loss_D: 1.7944 Loss_G: 4.6946\n",
            "[4/25][184/782] Loss_D: 0.8195 Loss_G: 2.4134\n",
            "[4/25][185/782] Loss_D: 0.3425 Loss_G: 3.4456\n",
            "[4/25][186/782] Loss_D: 0.5281 Loss_G: 4.0386\n",
            "[4/25][187/782] Loss_D: 0.6189 Loss_G: 1.8333\n",
            "[4/25][188/782] Loss_D: 0.7290 Loss_G: 5.3548\n",
            "[4/25][189/782] Loss_D: 0.9649 Loss_G: 1.8326\n",
            "[4/25][190/782] Loss_D: 0.7278 Loss_G: 5.4440\n",
            "[4/25][191/782] Loss_D: 0.7656 Loss_G: 2.1936\n",
            "[4/25][192/782] Loss_D: 1.1043 Loss_G: 6.2762\n",
            "[4/25][193/782] Loss_D: 2.3014 Loss_G: 1.3733\n",
            "[4/25][194/782] Loss_D: 1.6635 Loss_G: 6.7778\n",
            "[4/25][195/782] Loss_D: 2.1553 Loss_G: 0.6560\n",
            "[4/25][196/782] Loss_D: 1.2099 Loss_G: 5.2968\n",
            "[4/25][197/782] Loss_D: 0.3168 Loss_G: 4.3988\n",
            "[4/25][198/782] Loss_D: 0.4750 Loss_G: 2.1406\n",
            "[4/25][199/782] Loss_D: 0.4022 Loss_G: 3.3904\n",
            "[4/25][200/782] Loss_D: 0.5670 Loss_G: 2.8677\n",
            "[4/25][201/782] Loss_D: 0.6350 Loss_G: 4.1261\n",
            "[4/25][202/782] Loss_D: 0.5477 Loss_G: 2.1394\n",
            "[4/25][203/782] Loss_D: 0.7397 Loss_G: 4.6952\n",
            "[4/25][204/782] Loss_D: 0.9248 Loss_G: 1.6405\n",
            "[4/25][205/782] Loss_D: 0.6240 Loss_G: 3.9858\n",
            "[4/25][206/782] Loss_D: 0.3595 Loss_G: 4.0119\n",
            "[4/25][207/782] Loss_D: 0.4963 Loss_G: 2.3862\n",
            "[4/25][208/782] Loss_D: 0.5151 Loss_G: 2.7969\n",
            "[4/25][209/782] Loss_D: 0.3962 Loss_G: 3.5219\n",
            "[4/25][210/782] Loss_D: 0.4022 Loss_G: 2.6643\n",
            "[4/25][211/782] Loss_D: 0.3421 Loss_G: 3.0529\n",
            "[4/25][212/782] Loss_D: 0.3267 Loss_G: 4.0367\n",
            "[4/25][213/782] Loss_D: 0.6186 Loss_G: 1.7355\n",
            "[4/25][214/782] Loss_D: 0.6856 Loss_G: 4.4270\n",
            "[4/25][215/782] Loss_D: 0.5148 Loss_G: 2.6518\n",
            "[4/25][216/782] Loss_D: 0.3195 Loss_G: 3.0007\n",
            "[4/25][217/782] Loss_D: 0.4338 Loss_G: 3.0075\n",
            "[4/25][218/782] Loss_D: 0.3929 Loss_G: 2.5949\n",
            "[4/25][219/782] Loss_D: 0.3819 Loss_G: 3.3416\n",
            "[4/25][220/782] Loss_D: 0.3641 Loss_G: 3.7566\n",
            "[4/25][221/782] Loss_D: 0.2711 Loss_G: 3.3782\n",
            "[4/25][222/782] Loss_D: 0.2532 Loss_G: 2.6523\n",
            "[4/25][223/782] Loss_D: 0.2575 Loss_G: 3.4714\n",
            "[4/25][224/782] Loss_D: 0.2404 Loss_G: 3.6122\n",
            "[4/25][225/782] Loss_D: 0.2909 Loss_G: 2.9169\n",
            "[4/25][226/782] Loss_D: 0.2459 Loss_G: 3.4020\n",
            "[4/25][227/782] Loss_D: 0.3146 Loss_G: 2.4967\n",
            "[4/25][228/782] Loss_D: 0.3927 Loss_G: 4.0635\n",
            "[4/25][229/782] Loss_D: 0.2044 Loss_G: 3.6841\n",
            "[4/25][230/782] Loss_D: 0.1631 Loss_G: 3.1681\n",
            "[4/25][231/782] Loss_D: 0.2390 Loss_G: 2.8940\n",
            "[4/25][232/782] Loss_D: 0.1072 Loss_G: 3.7463\n",
            "[4/25][233/782] Loss_D: 0.1468 Loss_G: 3.7740\n",
            "[4/25][234/782] Loss_D: 0.2785 Loss_G: 3.7680\n",
            "[4/25][235/782] Loss_D: 0.1810 Loss_G: 3.5388\n",
            "[4/25][236/782] Loss_D: 0.1746 Loss_G: 3.3487\n",
            "[4/25][237/782] Loss_D: 0.1389 Loss_G: 3.9312\n",
            "[4/25][238/782] Loss_D: 0.1368 Loss_G: 4.0193\n",
            "[4/25][239/782] Loss_D: 0.1632 Loss_G: 3.5831\n",
            "[4/25][240/782] Loss_D: 0.1972 Loss_G: 3.5578\n",
            "[4/25][241/782] Loss_D: 0.1336 Loss_G: 4.3563\n",
            "[4/25][242/782] Loss_D: 0.0957 Loss_G: 4.4755\n",
            "[4/25][243/782] Loss_D: 0.1882 Loss_G: 2.7446\n",
            "[4/25][244/782] Loss_D: 0.2031 Loss_G: 3.9315\n",
            "[4/25][245/782] Loss_D: 0.1323 Loss_G: 4.1114\n",
            "[4/25][246/782] Loss_D: 0.1194 Loss_G: 3.5228\n",
            "[4/25][247/782] Loss_D: 0.1663 Loss_G: 3.7838\n",
            "[4/25][248/782] Loss_D: 0.1141 Loss_G: 4.1379\n",
            "[4/25][249/782] Loss_D: 0.0937 Loss_G: 4.1678\n",
            "[4/25][250/782] Loss_D: 0.1200 Loss_G: 3.3815\n",
            "[4/25][251/782] Loss_D: 0.0401 Loss_G: 4.2713\n",
            "[4/25][252/782] Loss_D: 0.1011 Loss_G: 4.0685\n",
            "[4/25][253/782] Loss_D: 0.1970 Loss_G: 5.7182\n",
            "[4/25][254/782] Loss_D: 0.2735 Loss_G: 3.4659\n",
            "[4/25][255/782] Loss_D: 0.1726 Loss_G: 4.0251\n",
            "[4/25][256/782] Loss_D: 0.1281 Loss_G: 4.0378\n",
            "[4/25][257/782] Loss_D: 0.1090 Loss_G: 4.3487\n",
            "[4/25][258/782] Loss_D: 0.0974 Loss_G: 4.3334\n",
            "[4/25][259/782] Loss_D: 0.1256 Loss_G: 3.3126\n",
            "[4/25][260/782] Loss_D: 0.1358 Loss_G: 4.0670\n",
            "[4/25][261/782] Loss_D: 0.0648 Loss_G: 4.3756\n",
            "[4/25][262/782] Loss_D: 0.0614 Loss_G: 4.1706\n",
            "[4/25][263/782] Loss_D: 0.0781 Loss_G: 4.0924\n",
            "[4/25][264/782] Loss_D: 0.1456 Loss_G: 4.1428\n",
            "[4/25][265/782] Loss_D: 0.1147 Loss_G: 4.3184\n",
            "[4/25][266/782] Loss_D: 0.0890 Loss_G: 4.2029\n",
            "[4/25][267/782] Loss_D: 0.0491 Loss_G: 4.2061\n",
            "[4/25][268/782] Loss_D: 0.2225 Loss_G: 2.8533\n",
            "[4/25][269/782] Loss_D: 0.0777 Loss_G: 4.0179\n",
            "[4/25][270/782] Loss_D: 0.1526 Loss_G: 5.7535\n",
            "[4/25][271/782] Loss_D: 0.2424 Loss_G: 4.7503\n",
            "[4/25][272/782] Loss_D: 0.1480 Loss_G: 4.3308\n",
            "[4/25][273/782] Loss_D: 0.1237 Loss_G: 3.5733\n",
            "[4/25][274/782] Loss_D: 0.0722 Loss_G: 3.7925\n",
            "[4/25][275/782] Loss_D: 0.1011 Loss_G: 5.2393\n",
            "[4/25][276/782] Loss_D: 0.0305 Loss_G: 5.9732\n",
            "[4/25][277/782] Loss_D: 0.1233 Loss_G: 4.3092\n",
            "[4/25][278/782] Loss_D: 0.0558 Loss_G: 5.5587\n",
            "[4/25][279/782] Loss_D: 0.1000 Loss_G: 3.6376\n",
            "[4/25][280/782] Loss_D: 0.2191 Loss_G: 4.8595\n",
            "[4/25][281/782] Loss_D: 0.0993 Loss_G: 4.6799\n",
            "[4/25][282/782] Loss_D: 0.1080 Loss_G: 3.7104\n",
            "[4/25][283/782] Loss_D: 0.0713 Loss_G: 3.8346\n",
            "[4/25][284/782] Loss_D: 0.1012 Loss_G: 4.5621\n",
            "[4/25][285/782] Loss_D: 0.0582 Loss_G: 4.9436\n",
            "[4/25][286/782] Loss_D: 0.1218 Loss_G: 3.4562\n",
            "[4/25][287/782] Loss_D: 0.0874 Loss_G: 3.8971\n",
            "[4/25][288/782] Loss_D: 0.0655 Loss_G: 4.4667\n",
            "[4/25][289/782] Loss_D: 0.1723 Loss_G: 6.0439\n",
            "[4/25][290/782] Loss_D: 0.2727 Loss_G: 3.6477\n",
            "[4/25][291/782] Loss_D: 0.0981 Loss_G: 3.3540\n",
            "[4/25][292/782] Loss_D: 0.3953 Loss_G: 9.5044\n",
            "[4/25][293/782] Loss_D: 2.7576 Loss_G: 2.2698\n",
            "[4/25][294/782] Loss_D: 1.2599 Loss_G: 5.3321\n",
            "[4/25][295/782] Loss_D: 2.6856 Loss_G: 0.0274\n",
            "[4/25][296/782] Loss_D: 5.2244 Loss_G: 8.6850\n",
            "[4/25][297/782] Loss_D: 4.3607 Loss_G: 1.6324\n",
            "[4/25][298/782] Loss_D: 1.0856 Loss_G: 1.9678\n",
            "[4/25][299/782] Loss_D: 1.1494 Loss_G: 3.6834\n",
            "[4/25][300/782] Loss_D: 1.3664 Loss_G: 1.0958\n",
            "[4/25][301/782] Loss_D: 1.3537 Loss_G: 4.3967\n",
            "[4/25][302/782] Loss_D: 1.2397 Loss_G: 1.7969\n",
            "[4/25][303/782] Loss_D: 0.8987 Loss_G: 2.0485\n",
            "[4/25][304/782] Loss_D: 0.7685 Loss_G: 3.4464\n",
            "[4/25][305/782] Loss_D: 0.8881 Loss_G: 1.4633\n",
            "[4/25][306/782] Loss_D: 1.3340 Loss_G: 4.8295\n",
            "[4/25][307/782] Loss_D: 0.9281 Loss_G: 2.0942\n",
            "[4/25][308/782] Loss_D: 0.9067 Loss_G: 1.2092\n",
            "[4/25][309/782] Loss_D: 0.9693 Loss_G: 5.0803\n",
            "[4/25][310/782] Loss_D: 1.1515 Loss_G: 1.6869\n",
            "[4/25][311/782] Loss_D: 0.6925 Loss_G: 2.6284\n",
            "[4/25][312/782] Loss_D: 0.5366 Loss_G: 3.8441\n",
            "[4/25][313/782] Loss_D: 0.7115 Loss_G: 2.1568\n",
            "[4/25][314/782] Loss_D: 0.9440 Loss_G: 3.6276\n",
            "[4/25][315/782] Loss_D: 1.2188 Loss_G: 0.8040\n",
            "[4/25][316/782] Loss_D: 1.9588 Loss_G: 5.1657\n",
            "[4/25][317/782] Loss_D: 1.5037 Loss_G: 2.0362\n",
            "[4/25][318/782] Loss_D: 0.6137 Loss_G: 2.7559\n",
            "[4/25][319/782] Loss_D: 0.4871 Loss_G: 3.4695\n",
            "[4/25][320/782] Loss_D: 0.6037 Loss_G: 2.3609\n",
            "[4/25][321/782] Loss_D: 0.8675 Loss_G: 3.6122\n",
            "[4/25][322/782] Loss_D: 0.6345 Loss_G: 2.0432\n",
            "[4/25][323/782] Loss_D: 1.0397 Loss_G: 4.0409\n",
            "[4/25][324/782] Loss_D: 1.0504 Loss_G: 1.1580\n",
            "[4/25][325/782] Loss_D: 0.9156 Loss_G: 4.8399\n",
            "[4/25][326/782] Loss_D: 0.8720 Loss_G: 2.0153\n",
            "[4/25][327/782] Loss_D: 0.7869 Loss_G: 3.6016\n",
            "[4/25][328/782] Loss_D: 0.4118 Loss_G: 3.1595\n",
            "[4/25][329/782] Loss_D: 0.6812 Loss_G: 2.6888\n",
            "[4/25][330/782] Loss_D: 0.5982 Loss_G: 2.8076\n",
            "[4/25][331/782] Loss_D: 0.8303 Loss_G: 6.0462\n",
            "[4/25][332/782] Loss_D: 1.8614 Loss_G: 0.2974\n",
            "[4/25][333/782] Loss_D: 2.5082 Loss_G: 6.6368\n",
            "[4/25][334/782] Loss_D: 2.1037 Loss_G: 0.5095\n",
            "[4/25][335/782] Loss_D: 1.5175 Loss_G: 3.9371\n",
            "[4/25][336/782] Loss_D: 0.4755 Loss_G: 3.6810\n",
            "[4/25][337/782] Loss_D: 1.0687 Loss_G: 1.1899\n",
            "[4/25][338/782] Loss_D: 1.8137 Loss_G: 4.4499\n",
            "[4/25][339/782] Loss_D: 2.1705 Loss_G: 1.0989\n",
            "[4/25][340/782] Loss_D: 1.7463 Loss_G: 4.8344\n",
            "[4/25][341/782] Loss_D: 1.2750 Loss_G: 2.0374\n",
            "[4/25][342/782] Loss_D: 0.6184 Loss_G: 2.2933\n",
            "[4/25][343/782] Loss_D: 0.7838 Loss_G: 3.9076\n",
            "[4/25][344/782] Loss_D: 0.6281 Loss_G: 2.8534\n",
            "[4/25][345/782] Loss_D: 0.8389 Loss_G: 2.1155\n",
            "[4/25][346/782] Loss_D: 0.9593 Loss_G: 3.0614\n",
            "[4/25][347/782] Loss_D: 0.8134 Loss_G: 2.0887\n",
            "[4/25][348/782] Loss_D: 0.7921 Loss_G: 3.6898\n",
            "[4/25][349/782] Loss_D: 0.7633 Loss_G: 2.0657\n",
            "[4/25][350/782] Loss_D: 0.4895 Loss_G: 3.0943\n",
            "[4/25][351/782] Loss_D: 0.5008 Loss_G: 2.7659\n",
            "[4/25][352/782] Loss_D: 0.5539 Loss_G: 5.1585\n",
            "[4/25][353/782] Loss_D: 0.7581 Loss_G: 1.6611\n",
            "[4/25][354/782] Loss_D: 1.1060 Loss_G: 6.8203\n",
            "[4/25][355/782] Loss_D: 1.4228 Loss_G: 1.7738\n",
            "[4/25][356/782] Loss_D: 0.9431 Loss_G: 6.3598\n",
            "[4/25][357/782] Loss_D: 1.7877 Loss_G: 0.4888\n",
            "[4/25][358/782] Loss_D: 1.8232 Loss_G: 5.7955\n",
            "[4/25][359/782] Loss_D: 1.2978 Loss_G: 1.8455\n",
            "[4/25][360/782] Loss_D: 0.7843 Loss_G: 2.9433\n",
            "[4/25][361/782] Loss_D: 1.0502 Loss_G: 3.0024\n",
            "[4/25][362/782] Loss_D: 1.0457 Loss_G: 2.3719\n",
            "[4/25][363/782] Loss_D: 0.7190 Loss_G: 2.5664\n",
            "[4/25][364/782] Loss_D: 1.1250 Loss_G: 4.8388\n",
            "[4/25][365/782] Loss_D: 1.8778 Loss_G: 0.3811\n",
            "[4/25][366/782] Loss_D: 2.2228 Loss_G: 7.3756\n",
            "[4/25][367/782] Loss_D: 2.5889 Loss_G: 2.3527\n",
            "[4/25][368/782] Loss_D: 0.9229 Loss_G: 4.1816\n",
            "[4/25][369/782] Loss_D: 0.3947 Loss_G: 3.8869\n",
            "[4/25][370/782] Loss_D: 0.7390 Loss_G: 2.8171\n",
            "[4/25][371/782] Loss_D: 0.6670 Loss_G: 4.2268\n",
            "[4/25][372/782] Loss_D: 0.5250 Loss_G: 2.7383\n",
            "[4/25][373/782] Loss_D: 0.7557 Loss_G: 4.8233\n",
            "[4/25][374/782] Loss_D: 1.1182 Loss_G: 1.3277\n",
            "[4/25][375/782] Loss_D: 1.1404 Loss_G: 5.1164\n",
            "[4/25][376/782] Loss_D: 0.7279 Loss_G: 2.7696\n",
            "[4/25][377/782] Loss_D: 0.4890 Loss_G: 3.1797\n",
            "[4/25][378/782] Loss_D: 0.8180 Loss_G: 2.7101\n",
            "[4/25][379/782] Loss_D: 0.3198 Loss_G: 4.5335\n",
            "[4/25][380/782] Loss_D: 0.3392 Loss_G: 3.2185\n",
            "[4/25][381/782] Loss_D: 0.3001 Loss_G: 4.1419\n",
            "[4/25][382/782] Loss_D: 0.4358 Loss_G: 3.0938\n",
            "[4/25][383/782] Loss_D: 0.5704 Loss_G: 3.6883\n",
            "[4/25][384/782] Loss_D: 0.5337 Loss_G: 1.7670\n",
            "[4/25][385/782] Loss_D: 0.6443 Loss_G: 5.0966\n",
            "[4/25][386/782] Loss_D: 0.8913 Loss_G: 1.9785\n",
            "[4/25][387/782] Loss_D: 0.7833 Loss_G: 4.8998\n",
            "[4/25][388/782] Loss_D: 0.8846 Loss_G: 1.8626\n",
            "[4/25][389/782] Loss_D: 0.7034 Loss_G: 5.1056\n",
            "[4/25][390/782] Loss_D: 0.5090 Loss_G: 2.3442\n",
            "[4/25][391/782] Loss_D: 0.4095 Loss_G: 3.5994\n",
            "[4/25][392/782] Loss_D: 0.2607 Loss_G: 3.5596\n",
            "[4/25][393/782] Loss_D: 0.5587 Loss_G: 3.3904\n",
            "[4/25][394/782] Loss_D: 0.2882 Loss_G: 3.7620\n",
            "[4/25][395/782] Loss_D: 0.4453 Loss_G: 2.1047\n",
            "[4/25][396/782] Loss_D: 0.5369 Loss_G: 5.8808\n",
            "[4/25][397/782] Loss_D: 0.5958 Loss_G: 3.0085\n",
            "[4/25][398/782] Loss_D: 0.3045 Loss_G: 2.7664\n",
            "[4/25][399/782] Loss_D: 0.3550 Loss_G: 2.5229\n",
            "[4/25][400/782] Loss_D: 0.5107 Loss_G: 5.6473\n",
            "[4/25][401/782] Loss_D: 0.4148 Loss_G: 3.4220\n",
            "[4/25][402/782] Loss_D: 0.2525 Loss_G: 2.7953\n",
            "[4/25][403/782] Loss_D: 0.3010 Loss_G: 4.2705\n",
            "[4/25][404/782] Loss_D: 0.1551 Loss_G: 3.9691\n",
            "[4/25][405/782] Loss_D: 0.1958 Loss_G: 3.0356\n",
            "[4/25][406/782] Loss_D: 0.2548 Loss_G: 3.6952\n",
            "[4/25][407/782] Loss_D: 0.2892 Loss_G: 2.6066\n",
            "[4/25][408/782] Loss_D: 0.3201 Loss_G: 3.2700\n",
            "[4/25][409/782] Loss_D: 0.5604 Loss_G: 6.2365\n",
            "[4/25][410/782] Loss_D: 1.0398 Loss_G: 1.3379\n",
            "[4/25][411/782] Loss_D: 0.7949 Loss_G: 5.9918\n",
            "[4/25][412/782] Loss_D: 0.6748 Loss_G: 1.8475\n",
            "[4/25][413/782] Loss_D: 0.6476 Loss_G: 6.0576\n",
            "[4/25][414/782] Loss_D: 0.5818 Loss_G: 2.4120\n",
            "[4/25][415/782] Loss_D: 0.2414 Loss_G: 3.4109\n",
            "[4/25][416/782] Loss_D: 0.3578 Loss_G: 5.2053\n",
            "[4/25][417/782] Loss_D: 0.4080 Loss_G: 2.6487\n",
            "[4/25][418/782] Loss_D: 0.3791 Loss_G: 2.9079\n",
            "[4/25][419/782] Loss_D: 0.1874 Loss_G: 4.0227\n",
            "[4/25][420/782] Loss_D: 0.2652 Loss_G: 3.1353\n",
            "[4/25][421/782] Loss_D: 0.5332 Loss_G: 5.3685\n",
            "[4/25][422/782] Loss_D: 0.5099 Loss_G: 2.2699\n",
            "[4/25][423/782] Loss_D: 0.2965 Loss_G: 3.7393\n",
            "[4/25][424/782] Loss_D: 0.1471 Loss_G: 4.1434\n",
            "[4/25][425/782] Loss_D: 0.4161 Loss_G: 1.8520\n",
            "[4/25][426/782] Loss_D: 0.3135 Loss_G: 3.7601\n",
            "[4/25][427/782] Loss_D: 0.2350 Loss_G: 3.3318\n",
            "[4/25][428/782] Loss_D: 0.1857 Loss_G: 2.9738\n",
            "[4/25][429/782] Loss_D: 0.5913 Loss_G: 7.5827\n",
            "[4/25][430/782] Loss_D: 1.2012 Loss_G: 2.5161\n",
            "[4/25][431/782] Loss_D: 0.4865 Loss_G: 6.1117\n",
            "[4/25][432/782] Loss_D: 2.6369 Loss_G: 0.0977\n",
            "[4/25][433/782] Loss_D: 3.1255 Loss_G: 7.7018\n",
            "[4/25][434/782] Loss_D: 3.1304 Loss_G: 0.6512\n",
            "[4/25][435/782] Loss_D: 1.2247 Loss_G: 2.3008\n",
            "[4/25][436/782] Loss_D: 0.6641 Loss_G: 3.3507\n",
            "[4/25][437/782] Loss_D: 1.1142 Loss_G: 0.7957\n",
            "[4/25][438/782] Loss_D: 1.8053 Loss_G: 4.3208\n",
            "[4/25][439/782] Loss_D: 1.8984 Loss_G: 1.2675\n",
            "[4/25][440/782] Loss_D: 1.5024 Loss_G: 2.1954\n",
            "[4/25][441/782] Loss_D: 1.0761 Loss_G: 2.7558\n",
            "[4/25][442/782] Loss_D: 1.5200 Loss_G: 1.2805\n",
            "[4/25][443/782] Loss_D: 1.5460 Loss_G: 3.5093\n",
            "[4/25][444/782] Loss_D: 1.4759 Loss_G: 1.1995\n",
            "[4/25][445/782] Loss_D: 1.2596 Loss_G: 3.2292\n",
            "[4/25][446/782] Loss_D: 0.9369 Loss_G: 1.8611\n",
            "[4/25][447/782] Loss_D: 1.1389 Loss_G: 2.2267\n",
            "[4/25][448/782] Loss_D: 1.2230 Loss_G: 2.3824\n",
            "[4/25][449/782] Loss_D: 0.8752 Loss_G: 1.8209\n",
            "[4/25][450/782] Loss_D: 0.5952 Loss_G: 2.4113\n",
            "[4/25][451/782] Loss_D: 0.5731 Loss_G: 3.5748\n",
            "[4/25][452/782] Loss_D: 0.8890 Loss_G: 2.1898\n",
            "[4/25][453/782] Loss_D: 0.9162 Loss_G: 2.9567\n",
            "[4/25][454/782] Loss_D: 0.8324 Loss_G: 1.7894\n",
            "[4/25][455/782] Loss_D: 0.4758 Loss_G: 3.7815\n",
            "[4/25][456/782] Loss_D: 0.3630 Loss_G: 3.6345\n",
            "[4/25][457/782] Loss_D: 0.6559 Loss_G: 2.0615\n",
            "[4/25][458/782] Loss_D: 0.4131 Loss_G: 3.4987\n",
            "[4/25][459/782] Loss_D: 0.4193 Loss_G: 3.0217\n",
            "[4/25][460/782] Loss_D: 0.2802 Loss_G: 3.4957\n",
            "[4/25][461/782] Loss_D: 0.4134 Loss_G: 3.4008\n",
            "[4/25][462/782] Loss_D: 0.8028 Loss_G: 1.9173\n",
            "[4/25][463/782] Loss_D: 0.8564 Loss_G: 2.9320\n",
            "[4/25][464/782] Loss_D: 0.4410 Loss_G: 3.1152\n",
            "[4/25][465/782] Loss_D: 0.6746 Loss_G: 2.2814\n",
            "[4/25][466/782] Loss_D: 0.4872 Loss_G: 3.5832\n",
            "[4/25][467/782] Loss_D: 0.1542 Loss_G: 4.0411\n",
            "[4/25][468/782] Loss_D: 0.2757 Loss_G: 3.9128\n",
            "[4/25][469/782] Loss_D: 0.4987 Loss_G: 1.9159\n",
            "[4/25][470/782] Loss_D: 0.2924 Loss_G: 4.4058\n",
            "[4/25][471/782] Loss_D: 0.2321 Loss_G: 3.7342\n",
            "[4/25][472/782] Loss_D: 0.3028 Loss_G: 2.5914\n",
            "[4/25][473/782] Loss_D: 0.6481 Loss_G: 6.7706\n",
            "[4/25][474/782] Loss_D: 1.2136 Loss_G: 2.8438\n",
            "[4/25][475/782] Loss_D: 0.2994 Loss_G: 3.2076\n",
            "[4/25][476/782] Loss_D: 0.3729 Loss_G: 2.3625\n",
            "[4/25][477/782] Loss_D: 0.4417 Loss_G: 5.5401\n",
            "[4/25][478/782] Loss_D: 0.6405 Loss_G: 1.8581\n",
            "[4/25][479/782] Loss_D: 0.5367 Loss_G: 4.7937\n",
            "[4/25][480/782] Loss_D: 0.4881 Loss_G: 2.2680\n",
            "[4/25][481/782] Loss_D: 0.4073 Loss_G: 3.4555\n",
            "[4/25][482/782] Loss_D: 0.4029 Loss_G: 3.0056\n",
            "[4/25][483/782] Loss_D: 0.3753 Loss_G: 4.6807\n",
            "[4/25][484/782] Loss_D: 0.8005 Loss_G: 1.6240\n",
            "[4/25][485/782] Loss_D: 0.7201 Loss_G: 5.4925\n",
            "[4/25][486/782] Loss_D: 0.3297 Loss_G: 3.4172\n",
            "[4/25][487/782] Loss_D: 0.1512 Loss_G: 3.0797\n",
            "[4/25][488/782] Loss_D: 0.1704 Loss_G: 3.8444\n",
            "[4/25][489/782] Loss_D: 0.1899 Loss_G: 3.8706\n",
            "[4/25][490/782] Loss_D: 0.1336 Loss_G: 3.8370\n",
            "[4/25][491/782] Loss_D: 0.2758 Loss_G: 2.5376\n",
            "[4/25][492/782] Loss_D: 0.3791 Loss_G: 4.7983\n",
            "[4/25][493/782] Loss_D: 0.5584 Loss_G: 1.8015\n",
            "[4/25][494/782] Loss_D: 0.6324 Loss_G: 5.9613\n",
            "[4/25][495/782] Loss_D: 0.7430 Loss_G: 2.8204\n",
            "[4/25][496/782] Loss_D: 0.6616 Loss_G: 6.4747\n",
            "[4/25][497/782] Loss_D: 3.7259 Loss_G: 0.3367\n",
            "[4/25][498/782] Loss_D: 1.9292 Loss_G: 4.4032\n",
            "[4/25][499/782] Loss_D: 0.8267 Loss_G: 1.9213\n",
            "[4/25][500/782] Loss_D: 0.5666 Loss_G: 1.9384\n",
            "[4/25][501/782] Loss_D: 0.8842 Loss_G: 3.9277\n",
            "[4/25][502/782] Loss_D: 0.9779 Loss_G: 1.1258\n",
            "[4/25][503/782] Loss_D: 1.1355 Loss_G: 5.3554\n",
            "[4/25][504/782] Loss_D: 0.9736 Loss_G: 1.4140\n",
            "[4/25][505/782] Loss_D: 0.4584 Loss_G: 2.7692\n",
            "[4/25][506/782] Loss_D: 0.4650 Loss_G: 3.1965\n",
            "[4/25][507/782] Loss_D: 0.3686 Loss_G: 2.9300\n",
            "[4/25][508/782] Loss_D: 0.4035 Loss_G: 2.7633\n",
            "[4/25][509/782] Loss_D: 0.4902 Loss_G: 3.2175\n",
            "[4/25][510/782] Loss_D: 0.4794 Loss_G: 4.0098\n",
            "[4/25][511/782] Loss_D: 0.7894 Loss_G: 0.9273\n",
            "[4/25][512/782] Loss_D: 0.8600 Loss_G: 6.4303\n",
            "[4/25][513/782] Loss_D: 0.7237 Loss_G: 2.7246\n",
            "[4/25][514/782] Loss_D: 0.2578 Loss_G: 2.6798\n",
            "[4/25][515/782] Loss_D: 0.4605 Loss_G: 4.4561\n",
            "[4/25][516/782] Loss_D: 0.2980 Loss_G: 3.5978\n",
            "[4/25][517/782] Loss_D: 0.1630 Loss_G: 3.4661\n",
            "[4/25][518/782] Loss_D: 0.3121 Loss_G: 4.3055\n",
            "[4/25][519/782] Loss_D: 0.4086 Loss_G: 2.8831\n",
            "[4/25][520/782] Loss_D: 0.7066 Loss_G: 6.1729\n",
            "[4/25][521/782] Loss_D: 0.6755 Loss_G: 2.9525\n",
            "[4/25][522/782] Loss_D: 0.4252 Loss_G: 5.4868\n",
            "[4/25][523/782] Loss_D: 0.7638 Loss_G: 2.4407\n",
            "[4/25][524/782] Loss_D: 0.7847 Loss_G: 7.5273\n",
            "[4/25][525/782] Loss_D: 2.9342 Loss_G: 0.8024\n",
            "[4/25][526/782] Loss_D: 1.6100 Loss_G: 4.8452\n",
            "[4/25][527/782] Loss_D: 0.5653 Loss_G: 3.5263\n",
            "[4/25][528/782] Loss_D: 0.4882 Loss_G: 3.7452\n",
            "[4/25][529/782] Loss_D: 0.2844 Loss_G: 3.8275\n",
            "[4/25][530/782] Loss_D: 0.5759 Loss_G: 2.3926\n",
            "[4/25][531/782] Loss_D: 0.7666 Loss_G: 5.3036\n",
            "[4/25][532/782] Loss_D: 1.4068 Loss_G: 1.1123\n",
            "[4/25][533/782] Loss_D: 1.3630 Loss_G: 5.6065\n",
            "[4/25][534/782] Loss_D: 0.7308 Loss_G: 2.6467\n",
            "[4/25][535/782] Loss_D: 0.4404 Loss_G: 2.8876\n",
            "[4/25][536/782] Loss_D: 0.2850 Loss_G: 3.7209\n",
            "[4/25][537/782] Loss_D: 0.3917 Loss_G: 4.2053\n",
            "[4/25][538/782] Loss_D: 0.5680 Loss_G: 2.1780\n",
            "[4/25][539/782] Loss_D: 0.4773 Loss_G: 4.5582\n",
            "[4/25][540/782] Loss_D: 0.2799 Loss_G: 3.8746\n",
            "[4/25][541/782] Loss_D: 0.4015 Loss_G: 2.0771\n",
            "[4/25][542/782] Loss_D: 0.4434 Loss_G: 5.5074\n",
            "[4/25][543/782] Loss_D: 0.4174 Loss_G: 2.9779\n",
            "[4/25][544/782] Loss_D: 0.3818 Loss_G: 2.3336\n",
            "[4/25][545/782] Loss_D: 0.3192 Loss_G: 3.9090\n",
            "[4/25][546/782] Loss_D: 0.2941 Loss_G: 3.4127\n",
            "[4/25][547/782] Loss_D: 0.2948 Loss_G: 4.5630\n",
            "[4/25][548/782] Loss_D: 0.3294 Loss_G: 2.7893\n",
            "[4/25][549/782] Loss_D: 0.3046 Loss_G: 3.4287\n",
            "[4/25][550/782] Loss_D: 0.2964 Loss_G: 3.1365\n",
            "[4/25][551/782] Loss_D: 0.3366 Loss_G: 4.9473\n",
            "[4/25][552/782] Loss_D: 0.3540 Loss_G: 2.9488\n",
            "[4/25][553/782] Loss_D: 0.1285 Loss_G: 3.5965\n",
            "[4/25][554/782] Loss_D: 0.2369 Loss_G: 4.8659\n",
            "[4/25][555/782] Loss_D: 0.2898 Loss_G: 3.3488\n",
            "[4/25][556/782] Loss_D: 0.2301 Loss_G: 2.7784\n",
            "[4/25][557/782] Loss_D: 0.1427 Loss_G: 3.6811\n",
            "[4/25][558/782] Loss_D: 0.2508 Loss_G: 4.8364\n",
            "[4/25][559/782] Loss_D: 0.3987 Loss_G: 3.1459\n",
            "[4/25][560/782] Loss_D: 0.1979 Loss_G: 3.0655\n",
            "[4/25][561/782] Loss_D: 0.1249 Loss_G: 4.0346\n",
            "[4/25][562/782] Loss_D: 0.2065 Loss_G: 3.0843\n",
            "[4/25][563/782] Loss_D: 0.1057 Loss_G: 3.5833\n",
            "[4/25][564/782] Loss_D: 0.1650 Loss_G: 4.1120\n",
            "[4/25][565/782] Loss_D: 0.1881 Loss_G: 3.9171\n",
            "[4/25][566/782] Loss_D: 0.1071 Loss_G: 4.1293\n",
            "[4/25][567/782] Loss_D: 0.0852 Loss_G: 3.7150\n",
            "[4/25][568/782] Loss_D: 0.2757 Loss_G: 4.3657\n",
            "[4/25][569/782] Loss_D: 0.2575 Loss_G: 3.0260\n",
            "[4/25][570/782] Loss_D: 0.1885 Loss_G: 3.6047\n",
            "[4/25][571/782] Loss_D: 0.1608 Loss_G: 4.6267\n",
            "[4/25][572/782] Loss_D: 0.1792 Loss_G: 3.6714\n",
            "[4/25][573/782] Loss_D: 0.1462 Loss_G: 3.3221\n",
            "[4/25][574/782] Loss_D: 0.1464 Loss_G: 3.8350\n",
            "[4/25][575/782] Loss_D: 0.1463 Loss_G: 3.8442\n",
            "[4/25][576/782] Loss_D: 0.1789 Loss_G: 3.0995\n",
            "[4/25][577/782] Loss_D: 0.1008 Loss_G: 3.6676\n",
            "[4/25][578/782] Loss_D: 0.1235 Loss_G: 4.0481\n",
            "[4/25][579/782] Loss_D: 0.0935 Loss_G: 4.2949\n",
            "[4/25][580/782] Loss_D: 0.1086 Loss_G: 3.7691\n",
            "[4/25][581/782] Loss_D: 0.1509 Loss_G: 3.6062\n",
            "[4/25][582/782] Loss_D: 0.1055 Loss_G: 3.9300\n",
            "[4/25][583/782] Loss_D: 0.0710 Loss_G: 4.3574\n",
            "[4/25][584/782] Loss_D: 0.2167 Loss_G: 2.6891\n",
            "[4/25][585/782] Loss_D: 0.1752 Loss_G: 4.3027\n",
            "[4/25][586/782] Loss_D: 0.1217 Loss_G: 4.3113\n",
            "[4/25][587/782] Loss_D: 0.0631 Loss_G: 4.4086\n",
            "[4/25][588/782] Loss_D: 0.0880 Loss_G: 4.1909\n",
            "[4/25][589/782] Loss_D: 0.0678 Loss_G: 3.7415\n",
            "[4/25][590/782] Loss_D: 0.1242 Loss_G: 4.5370\n",
            "[4/25][591/782] Loss_D: 0.0696 Loss_G: 4.7917\n",
            "[4/25][592/782] Loss_D: 0.1389 Loss_G: 3.9518\n",
            "[4/25][593/782] Loss_D: 0.1066 Loss_G: 3.8998\n",
            "[4/25][594/782] Loss_D: 0.1126 Loss_G: 3.3175\n",
            "[4/25][595/782] Loss_D: 0.0922 Loss_G: 4.4355\n",
            "[4/25][596/782] Loss_D: 0.0526 Loss_G: 4.7073\n",
            "[4/25][597/782] Loss_D: 0.2639 Loss_G: 6.7270\n",
            "[4/25][598/782] Loss_D: 1.1812 Loss_G: 1.3005\n",
            "[4/25][599/782] Loss_D: 1.2683 Loss_G: 11.5758\n",
            "[4/25][600/782] Loss_D: 6.6596 Loss_G: 4.0995\n",
            "[4/25][601/782] Loss_D: 0.7334 Loss_G: 0.1180\n",
            "[4/25][602/782] Loss_D: 3.4216 Loss_G: 4.3920\n",
            "[4/25][603/782] Loss_D: 0.7335 Loss_G: 3.2681\n",
            "[4/25][604/782] Loss_D: 0.9534 Loss_G: 1.3803\n",
            "[4/25][605/782] Loss_D: 1.0852 Loss_G: 2.4469\n",
            "[4/25][606/782] Loss_D: 1.2827 Loss_G: 1.9311\n",
            "[4/25][607/782] Loss_D: 1.1327 Loss_G: 3.1078\n",
            "[4/25][608/782] Loss_D: 1.4746 Loss_G: 0.7861\n",
            "[4/25][609/782] Loss_D: 1.3897 Loss_G: 3.4032\n",
            "[4/25][610/782] Loss_D: 1.0922 Loss_G: 1.7043\n",
            "[4/25][611/782] Loss_D: 0.9697 Loss_G: 2.5219\n",
            "[4/25][612/782] Loss_D: 0.7837 Loss_G: 2.0393\n",
            "[4/25][613/782] Loss_D: 0.6039 Loss_G: 2.3902\n",
            "[4/25][614/782] Loss_D: 0.5140 Loss_G: 2.6983\n",
            "[4/25][615/782] Loss_D: 0.7525 Loss_G: 1.3913\n",
            "[4/25][616/782] Loss_D: 0.8033 Loss_G: 3.4409\n",
            "[4/25][617/782] Loss_D: 0.7220 Loss_G: 2.4110\n",
            "[4/25][618/782] Loss_D: 0.5869 Loss_G: 1.8742\n",
            "[4/25][619/782] Loss_D: 0.7517 Loss_G: 3.2886\n",
            "[4/25][620/782] Loss_D: 0.4381 Loss_G: 3.0926\n",
            "[4/25][621/782] Loss_D: 0.5609 Loss_G: 1.8007\n",
            "[4/25][622/782] Loss_D: 0.7935 Loss_G: 5.2962\n",
            "[4/25][623/782] Loss_D: 0.8897 Loss_G: 1.8828\n",
            "[4/25][624/782] Loss_D: 0.8609 Loss_G: 5.2846\n",
            "[4/25][625/782] Loss_D: 0.5609 Loss_G: 1.4660\n",
            "[4/25][626/782] Loss_D: 1.2322 Loss_G: 7.5590\n",
            "[4/25][627/782] Loss_D: 2.6233 Loss_G: 1.0644\n",
            "[4/25][628/782] Loss_D: 1.2670 Loss_G: 5.3308\n",
            "[4/25][629/782] Loss_D: 2.1808 Loss_G: 0.7412\n",
            "[4/25][630/782] Loss_D: 1.2759 Loss_G: 1.8681\n",
            "[4/25][631/782] Loss_D: 1.1571 Loss_G: 3.0931\n",
            "[4/25][632/782] Loss_D: 1.0918 Loss_G: 1.2364\n",
            "[4/25][633/782] Loss_D: 1.2049 Loss_G: 2.6492\n",
            "[4/25][634/782] Loss_D: 1.0537 Loss_G: 2.7272\n",
            "[4/25][635/782] Loss_D: 0.6691 Loss_G: 2.1438\n",
            "[4/25][636/782] Loss_D: 0.6937 Loss_G: 1.9426\n",
            "[4/25][637/782] Loss_D: 1.0082 Loss_G: 4.2356\n",
            "[4/25][638/782] Loss_D: 1.9276 Loss_G: 0.4000\n",
            "[4/25][639/782] Loss_D: 2.0181 Loss_G: 4.7986\n",
            "[4/25][640/782] Loss_D: 1.5626 Loss_G: 1.5635\n",
            "[4/25][641/782] Loss_D: 0.8113 Loss_G: 1.5906\n",
            "[4/25][642/782] Loss_D: 1.2967 Loss_G: 4.9436\n",
            "[4/25][643/782] Loss_D: 0.5708 Loss_G: 3.3614\n",
            "[4/25][644/782] Loss_D: 0.5988 Loss_G: 2.0104\n",
            "[4/25][645/782] Loss_D: 0.7596 Loss_G: 3.1474\n",
            "[4/25][646/782] Loss_D: 0.4675 Loss_G: 3.6279\n",
            "[4/25][647/782] Loss_D: 0.5679 Loss_G: 2.3447\n",
            "[4/25][648/782] Loss_D: 0.8018 Loss_G: 3.5497\n",
            "[4/25][649/782] Loss_D: 0.3391 Loss_G: 3.6364\n",
            "[4/25][650/782] Loss_D: 0.4251 Loss_G: 2.3683\n",
            "[4/25][651/782] Loss_D: 0.5604 Loss_G: 4.5012\n",
            "[4/25][652/782] Loss_D: 0.3158 Loss_G: 3.9619\n",
            "[4/25][653/782] Loss_D: 0.5866 Loss_G: 1.6552\n",
            "[4/25][654/782] Loss_D: 0.8463 Loss_G: 6.1542\n",
            "[4/25][655/782] Loss_D: 1.2117 Loss_G: 1.7915\n",
            "[4/25][656/782] Loss_D: 0.5741 Loss_G: 5.0219\n",
            "[4/25][657/782] Loss_D: 0.7833 Loss_G: 1.5872\n",
            "[4/25][658/782] Loss_D: 1.0303 Loss_G: 6.0886\n",
            "[4/25][659/782] Loss_D: 0.4698 Loss_G: 3.6962\n",
            "[4/25][660/782] Loss_D: 0.2455 Loss_G: 3.2024\n",
            "[4/25][661/782] Loss_D: 0.2712 Loss_G: 5.0452\n",
            "[4/25][662/782] Loss_D: 0.5834 Loss_G: 2.1786\n",
            "[4/25][663/782] Loss_D: 0.7792 Loss_G: 6.9334\n",
            "[4/25][664/782] Loss_D: 1.0609 Loss_G: 2.2535\n",
            "[4/25][665/782] Loss_D: 0.5916 Loss_G: 4.3616\n",
            "[4/25][666/782] Loss_D: 0.3897 Loss_G: 2.7076\n",
            "[4/25][667/782] Loss_D: 0.4498 Loss_G: 4.9647\n",
            "[4/25][668/782] Loss_D: 0.5086 Loss_G: 2.2968\n",
            "[4/25][669/782] Loss_D: 0.3271 Loss_G: 5.6327\n",
            "[4/25][670/782] Loss_D: 0.1608 Loss_G: 4.6025\n",
            "[4/25][671/782] Loss_D: 0.1991 Loss_G: 2.9866\n",
            "[4/25][672/782] Loss_D: 0.2940 Loss_G: 4.5945\n",
            "[4/25][673/782] Loss_D: 0.2278 Loss_G: 4.1351\n",
            "[4/25][674/782] Loss_D: 0.1597 Loss_G: 3.7144\n",
            "[4/25][675/782] Loss_D: 0.3973 Loss_G: 2.4236\n",
            "[4/25][676/782] Loss_D: 0.3989 Loss_G: 3.9223\n",
            "[4/25][677/782] Loss_D: 0.3365 Loss_G: 2.9772\n",
            "[4/25][678/782] Loss_D: 0.2738 Loss_G: 5.1803\n",
            "[4/25][679/782] Loss_D: 0.2700 Loss_G: 3.7282\n",
            "[4/25][680/782] Loss_D: 0.2577 Loss_G: 3.9979\n",
            "[4/25][681/782] Loss_D: 0.2546 Loss_G: 3.0887\n",
            "[4/25][682/782] Loss_D: 0.2076 Loss_G: 4.0960\n",
            "[4/25][683/782] Loss_D: 0.2965 Loss_G: 5.3935\n",
            "[4/25][684/782] Loss_D: 0.3379 Loss_G: 3.0710\n",
            "[4/25][685/782] Loss_D: 0.1428 Loss_G: 3.0911\n",
            "[4/25][686/782] Loss_D: 0.1429 Loss_G: 3.4237\n",
            "[4/25][687/782] Loss_D: 0.5202 Loss_G: 7.5293\n",
            "[4/25][688/782] Loss_D: 1.5064 Loss_G: 2.3349\n",
            "[4/25][689/782] Loss_D: 0.9628 Loss_G: 4.6559\n",
            "[4/25][690/782] Loss_D: 2.0573 Loss_G: 0.1982\n",
            "[4/25][691/782] Loss_D: 2.4506 Loss_G: 5.1411\n",
            "[4/25][692/782] Loss_D: 1.2526 Loss_G: 2.4849\n",
            "[4/25][693/782] Loss_D: 0.5586 Loss_G: 2.3345\n",
            "[4/25][694/782] Loss_D: 0.7660 Loss_G: 4.0976\n",
            "[4/25][695/782] Loss_D: 0.9414 Loss_G: 1.5901\n",
            "[4/25][696/782] Loss_D: 0.8590 Loss_G: 2.7461\n",
            "[4/25][697/782] Loss_D: 0.8208 Loss_G: 2.7788\n",
            "[4/25][698/782] Loss_D: 0.9419 Loss_G: 2.7631\n",
            "[4/25][699/782] Loss_D: 0.6492 Loss_G: 1.9816\n",
            "[4/25][700/782] Loss_D: 0.9380 Loss_G: 5.5553\n",
            "[4/25][701/782] Loss_D: 1.5415 Loss_G: 1.2111\n",
            "[4/25][702/782] Loss_D: 1.0637 Loss_G: 4.3300\n",
            "[4/25][703/782] Loss_D: 0.6726 Loss_G: 2.5902\n",
            "[4/25][704/782] Loss_D: 0.6127 Loss_G: 3.4240\n",
            "[4/25][705/782] Loss_D: 0.8694 Loss_G: 1.3203\n",
            "[4/25][706/782] Loss_D: 1.4207 Loss_G: 6.1720\n",
            "[4/25][707/782] Loss_D: 1.0074 Loss_G: 2.6221\n",
            "[4/25][708/782] Loss_D: 0.7374 Loss_G: 3.9188\n",
            "[4/25][709/782] Loss_D: 0.2499 Loss_G: 3.5818\n",
            "[4/25][710/782] Loss_D: 0.5309 Loss_G: 2.4636\n",
            "[4/25][711/782] Loss_D: 0.7955 Loss_G: 4.6934\n",
            "[4/25][712/782] Loss_D: 0.7679 Loss_G: 0.6751\n",
            "[4/25][713/782] Loss_D: 1.8370 Loss_G: 7.2899\n",
            "[4/25][714/782] Loss_D: 2.5450 Loss_G: 1.0698\n",
            "[4/25][715/782] Loss_D: 1.2780 Loss_G: 3.7447\n",
            "[4/25][716/782] Loss_D: 0.9953 Loss_G: 1.5807\n",
            "[4/25][717/782] Loss_D: 0.8708 Loss_G: 4.3621\n",
            "[4/25][718/782] Loss_D: 1.0504 Loss_G: 1.8779\n",
            "[4/25][719/782] Loss_D: 1.0455 Loss_G: 5.0738\n",
            "[4/25][720/782] Loss_D: 0.5062 Loss_G: 3.2737\n",
            "[4/25][721/782] Loss_D: 0.5037 Loss_G: 2.1385\n",
            "[4/25][722/782] Loss_D: 0.7947 Loss_G: 5.0285\n",
            "[4/25][723/782] Loss_D: 0.7230 Loss_G: 2.1387\n",
            "[4/25][724/782] Loss_D: 1.1034 Loss_G: 5.3924\n",
            "[4/25][725/782] Loss_D: 0.5438 Loss_G: 3.0350\n",
            "[4/25][726/782] Loss_D: 0.4293 Loss_G: 3.7301\n",
            "[4/25][727/782] Loss_D: 0.2766 Loss_G: 4.0286\n",
            "[4/25][728/782] Loss_D: 0.4290 Loss_G: 3.4897\n",
            "[4/25][729/782] Loss_D: 0.1158 Loss_G: 4.0428\n",
            "[4/25][730/782] Loss_D: 0.2639 Loss_G: 2.7485\n",
            "[4/25][731/782] Loss_D: 1.2336 Loss_G: 8.5244\n",
            "[4/25][732/782] Loss_D: 2.9959 Loss_G: 2.6023\n",
            "[4/25][733/782] Loss_D: 0.6878 Loss_G: 3.5159\n",
            "[4/25][734/782] Loss_D: 0.7782 Loss_G: 1.0012\n",
            "[4/25][735/782] Loss_D: 1.7394 Loss_G: 6.8997\n",
            "[4/25][736/782] Loss_D: 1.9141 Loss_G: 1.6036\n",
            "[4/25][737/782] Loss_D: 0.6872 Loss_G: 3.4684\n",
            "[4/25][738/782] Loss_D: 1.6414 Loss_G: 3.1185\n",
            "[4/25][739/782] Loss_D: 1.7382 Loss_G: 1.1754\n",
            "[4/25][740/782] Loss_D: 1.3135 Loss_G: 6.3958\n",
            "[4/25][741/782] Loss_D: 0.9187 Loss_G: 3.0918\n",
            "[4/25][742/782] Loss_D: 0.4292 Loss_G: 2.5673\n",
            "[4/25][743/782] Loss_D: 0.3438 Loss_G: 3.7833\n",
            "[4/25][744/782] Loss_D: 0.4790 Loss_G: 3.0237\n",
            "[4/25][745/782] Loss_D: 0.5386 Loss_G: 4.1570\n",
            "[4/25][746/782] Loss_D: 0.7373 Loss_G: 1.8733\n",
            "[4/25][747/782] Loss_D: 1.2714 Loss_G: 7.4545\n",
            "[4/25][748/782] Loss_D: 1.5021 Loss_G: 3.0973\n",
            "[4/25][749/782] Loss_D: 0.2337 Loss_G: 2.6217\n",
            "[4/25][750/782] Loss_D: 0.4845 Loss_G: 4.5222\n",
            "[4/25][751/782] Loss_D: 0.8605 Loss_G: 1.2287\n",
            "[4/25][752/782] Loss_D: 1.2425 Loss_G: 5.5170\n",
            "[4/25][753/782] Loss_D: 0.2805 Loss_G: 5.3184\n"
          ]
        }
      ]
    }
  ]
}